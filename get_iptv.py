import requests
import pandas as pd
import re
import os
import time
import logging
import json
import stat
import platform
from itertools import cycle
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# ======================== æ ¸å¿ƒé…ç½®åŒº =========================
# åŸºç¡€åŠŸèƒ½é…ç½®
SOURCE_URLS = [
    "https://raw.githubusercontent.com/zwc456baby/iptv_alive/master/live.txt",
    "https://live.zbds.top/tv/iptv6.txt",
    "https://live.zbds.top/tv/iptv4.txt",
]
DEFAULT_TEMPLATE = "demo.txt"  # é»˜è®¤åˆ†ç±»æ¨¡æ¿
BACKUP_TEMPLATE = "demo_backup.txt"  # å¤‡ä»½æ¨¡æ¿
MAX_INTERFACES_PER_CHANNEL = 5  # å•é¢‘é“æœ€å¤šä¿ç•™æ¥å£æ•°
SPEED_TEST_TIMEOUT = 8  # æµ‹é€Ÿè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_SPEED_TEST_WORKERS = 15  # æµ‹é€Ÿå¹¶å‘çº¿ç¨‹æ•°
MAX_FETCH_WORKERS = 5  # æºæŠ“å–å¹¶å‘çº¿ç¨‹æ•°

# è¾“å‡ºé…ç½®ï¼ˆå›ºå®šæ–‡ä»¶åï¼‰
TXT_OUTPUT = "iptv.txt"
M3U_OUTPUT = "iptv.m3u"
CATEGORY_MARKER = "#genre#"  # æ¨¡æ¿ä¸­åˆ†ç±»æ ‡è®°
CACHE_FILE = ".iptv_valid_cache.json"  # æºæœ‰æ•ˆæ€§ç¼“å­˜æ–‡ä»¶
CACHE_EXPIRE = 3600  # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
MAX_CACHE_SIZE = 100  # æœ€å¤§ç¼“å­˜æ•°é‡ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰

# æŠ“å–ä¼˜åŒ–é…ç½®
MAX_REDIRECTS = 3  # æœ€å¤§é‡å®šå‘æ¬¡æ•°
REQ_INTERVAL = [0.2, 0.3, 0.4, 0.5]  # æŠ“å–è¯·æ±‚é—´éš”ï¼ˆéšæœºå¾ªç¯ï¼‰
MIN_CONTENT_LEN = 100  # æœ‰æ•ˆæºå†…å®¹æœ€å°é•¿åº¦ï¼ˆå­—ç¬¦ï¼‰
TEST_URL = "https://www.baidu.com"  # ç½‘ç»œæ£€æµ‹URL

# ç³»ç»Ÿå…¼å®¹æ€§é…ç½®
SYSTEM = platform.system()
IS_WINDOWS = SYSTEM == "Windows"
IS_LINUX = SYSTEM == "Linux"
IS_MAC = SYSTEM == "Darwin"

# é¢œè‰²è¾“å‡ºé…ç½®ï¼ˆWindowsç»ˆç«¯å…¼å®¹ï¼‰
if IS_WINDOWS:
    COLOR_GREEN = ""
    COLOR_RED = ""
    COLOR_YELLOW = ""
    COLOR_BLUE = ""
    COLOR_RESET = ""
else:
    COLOR_GREEN = "\033[92m"
    COLOR_RED = "\033[91m"
    COLOR_YELLOW = "\033[93m"
    COLOR_BLUE = "\033[94m"
    COLOR_RESET = "\033[0m"

# çº¿ç¨‹å®‰å…¨é”
CACHE_LOCK = Lock()  # ç¼“å­˜æ“ä½œé”
PRINT_LOCK = Lock()  # æ§åˆ¶å°è¾“å‡ºé”
# =========================================================================

# æ­£åˆ™è¡¨è¾¾å¼å®šä¹‰
IPV4_PAT = re.compile(r'^https?://(\d{1,3}\.){3}\d{1,3}')
IPV6_PAT = re.compile(r'^https?://\[([a-fA-F0-9:]+)\]')
URL_PAT = re.compile(r'^https?://')
SPACE_CLEAN_PAT = re.compile(r'\s+')

# æ—¥å¿—åˆå§‹åŒ–ï¼ˆåˆ†çº§è®°å½•ï¼Œä¾¿äºæ’æŸ¥ï¼‰
logging.basicConfig(
    filename="iptv_tool.log",
    level=logging.INFO,
    encoding="utf-8",
    format="%(asctime)s - %(levelname)s - %(module)s:%(lineno)d - %(message)s"
)


def print_sep(title: str = "", length: int = 70) -> None:
    """æ‰“å°å¸¦æ ‡é¢˜çš„åˆ†éš”çº¿ï¼Œçº¿ç¨‹å®‰å…¨"""
    with PRINT_LOCK:
        sep = "=" * length
        if title:
            print(f"\n{sep}\nğŸ“Œ {COLOR_BLUE}{title}{COLOR_RESET}\n{sep}")
        else:
            print(sep)


def safe_print(msg: str) -> None:
    """çº¿ç¨‹å®‰å…¨çš„æ§åˆ¶å°è¾“å‡º"""
    with PRINT_LOCK:
        print(msg)


def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ï¼šå»é™¤å¤šä½™ç©ºæ ¼ã€æ¢è¡Œç¬¦"""
    return SPACE_CLEAN_PAT.sub("", str(text).strip())


def check_network() -> bool:
    """æ£€æµ‹ç½‘ç»œè¿æ¥çŠ¶æ€ï¼Œé€‚é…å¤šç³»ç»Ÿ"""
    safe_print(f"{COLOR_BLUE}ğŸ” æ­£åœ¨æ£€æµ‹ç½‘ç»œè¿æ¥...{COLOR_RESET}")
    try:
        timeout = 3 if not IS_WINDOWS else 5
        resp = requests.get(TEST_URL, timeout=timeout)
        if resp.status_code == 200:
            safe_print(f"{COLOR_GREEN}âœ… ç½‘ç»œè¿æ¥æ­£å¸¸ï¼ˆ{SYSTEM}ç³»ç»Ÿï¼‰{COLOR_RESET}")
            return True
        else:
            safe_print(f"{COLOR_RED}âŒ ç½‘ç»œæ£€æµ‹å¤±è´¥ï¼šHTTPçŠ¶æ€ç  {resp.status_code}{COLOR_RESET}")
            return False
    except Exception as e:
        safe_print(f"{COLOR_RED}âŒ ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼š{str(e)}{COLOR_RESET}")
        return False


def set_file_permissions(file_path: str) -> None:
    """è®¾ç½®æ–‡ä»¶æƒé™ï¼Œé€‚é…å¤šç³»ç»Ÿ"""
    if IS_WINDOWS:
        return
    try:
        os.chmod(file_path, stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IROTH)
        logging.info(f"è®¾ç½®æ–‡ä»¶æƒé™ï¼š{file_path}")
    except Exception as e:
        safe_print(f"{COLOR_YELLOW}âš ï¸ è®¾ç½®æ–‡ä»¶æƒé™å¤±è´¥ï¼š{str(e)}{COLOR_RESET}")
        logging.warning(f"æ–‡ä»¶æƒé™è®¾ç½®å¤±è´¥ï¼š{file_path} - {str(e)}")


def generate_default_template() -> bool:
    """ç”Ÿæˆé»˜è®¤åˆ†ç±»æ¨¡æ¿ï¼ˆå½“æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨æ—¶ï¼‰"""
    default_cats = [
        {"name": "å¤®è§†é¢‘é“", "channels": ["CCTV1", "CCTV2", "CCTV3", "CCTV5", "CCTV6", "CCTV8", "CCTV13"]},
        {"name": "å«è§†é¢‘é“", "channels": ["æ¹–å—å«è§†", "æµ™æ±Ÿå«è§†", "ä¸œæ–¹å«è§†", "æ±Ÿè‹å«è§†", "åŒ—äº¬å«è§†", "å®‰å¾½å«è§†"]},
        {"name": "åœ°æ–¹é¢‘é“", "channels": ["å¹¿ä¸œå«è§†", "å±±ä¸œå«è§†", "å››å·å«è§†", "æ¹–åŒ—å«è§†", "æ²³å—å«è§†"]}
    ]
    try:
        with open(DEFAULT_TEMPLATE, 'w', encoding='utf-8') as f:
            f.write(f"# IPTVåˆ†ç±»æ¨¡æ¿ï¼ˆè‡ªåŠ¨ç”Ÿæˆäº {time.strftime('%Y-%m-%d %H:%M:%S')}ï¼‰\n")
            f.write(f"# ç³»ç»Ÿï¼š{SYSTEM} | æ ¼å¼ï¼š{CATEGORY_MARKER} åˆ†ç±»å æ¢è¡Œ é¢‘é“å\n\n")
            for cat in default_cats:
                f.write(f"{CATEGORY_MARKER} {cat['name']}\n")
                for ch in cat["channels"]:
                    f.write(f"{ch}\n")
                f.write("\n")
        set_file_permissions(DEFAULT_TEMPLATE)
        safe_print(f"{COLOR_GREEN}âœ… é»˜è®¤æ¨¡æ¿ç”ŸæˆæˆåŠŸï¼š{os.path.abspath(DEFAULT_TEMPLATE)}{COLOR_RESET}")
        return True
    except Exception as e:
        safe_print(f"{COLOR_RED}âŒ ç”Ÿæˆé»˜è®¤æ¨¡æ¿å¤±è´¥ï¼š{str(e)}{COLOR_RESET}")
        logging.error(f"æ¨¡æ¿ç”Ÿæˆå¤±è´¥ï¼š{str(e)}")
        return False


def read_template(template_path: str = DEFAULT_TEMPLATE) -> tuple[list[dict], list[str]] | tuple[None, None]:
    """è¯»å–åˆ†ç±»æ¨¡æ¿ï¼Œæ”¯æŒæŒ‡å®šè·¯å¾„ã€è‡ªåŠ¨å¤‡ä»½å’Œç”Ÿæˆ"""
    if not os.path.exists(template_path):
        safe_print(f"{COLOR_YELLOW}âš ï¸ æ¨¡æ¿ã€Œ{template_path}ã€ä¸å­˜åœ¨ï¼Œç”Ÿæˆé»˜è®¤æ¨¡æ¿...{COLOR_RESET}")
        if not generate_default_template():
            return None, None

    # è‡ªåŠ¨å¤‡ä»½æ¨¡æ¿
    try:
        with open(template_path, 'r', encoding='utf-8') as f_src, open(BACKUP_TEMPLATE, 'w', encoding='utf-8') as f_dst:
            f_dst.write(f"# æ¨¡æ¿å¤‡ä»½ï¼ˆ{time.strftime('%Y-%m-%d %H:%M:%S')}ï¼‰\n# æºæ¨¡æ¿ï¼š{template_path}\n")
            f_dst.write(f_src.read())
        set_file_permissions(BACKUP_TEMPLATE)
    except Exception as e:
        safe_print(f"{COLOR_YELLOW}âš ï¸ æ¨¡æ¿å¤‡ä»½å¤±è´¥ï¼š{str(e)}ï¼Œä¸å½±å“æµç¨‹{COLOR_RESET}")
        logging.warning(f"æ¨¡æ¿å¤‡ä»½å¤±è´¥ï¼š{str(e)}")

    categories = []
    current_cat = None
    all_channels = []

    try:
        with open(template_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                if line.startswith("#") and not line.startswith(CATEGORY_MARKER):
                    continue

                # å¤„ç†åˆ†ç±»è¡Œ
                if line.startswith(CATEGORY_MARKER):
                    cat_name = clean_text(line.lstrip(CATEGORY_MARKER))
                    if not cat_name:
                        safe_print(f"{COLOR_YELLOW}âš ï¸ ç¬¬{line_num}è¡Œï¼šåˆ†ç±»åä¸ºç©ºï¼Œå¿½ç•¥{COLOR_RESET}")
                        current_cat = None
                        continue
                    existing = next((c for c in categories if c["name"] == cat_name), None)
                    if existing:
                        current_cat = cat_name
                    else:
                        categories.append({"name": cat_name, "channels": []})
                        current_cat = cat_name
                    continue

                # å¤„ç†é¢‘é“è¡Œ
                if current_cat is None:
                    safe_print(f"{COLOR_YELLOW}âš ï¸ ç¬¬{line_num}è¡Œï¼šé¢‘é“æœªåˆ†ç±»ï¼Œå½’å…¥ã€Œæœªåˆ†ç±»ã€{COLOR_RESET}")
                    if not any(c["name"] == "æœªåˆ†ç±»" for c in categories):
                        categories.append({"name": "æœªåˆ†ç±»", "channels": []})
                    current_cat = "æœªåˆ†ç±»"

                ch_name = clean_text(line.split(",")[0])
                if not ch_name:
                    safe_print(f"{COLOR_YELLOW}âš ï¸ ç¬¬{line_num}è¡Œï¼šé¢‘é“åä¸ºç©ºï¼Œå¿½ç•¥{COLOR_RESET}")
                    continue
                if ch_name not in all_channels:
                    all_channels.append(ch_name)
                    for cat in categories:
                        if cat["name"] == current_cat:
                            cat["channels"].append(ch_name)
                            break

    except Exception as e:
        safe_print(f"{COLOR_RED}âŒ è¯»å–æ¨¡æ¿å¤±è´¥ï¼š{str(e)}{COLOR_RESET}")
        logging.error(f"æ¨¡æ¿è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None, None

    # è¾“å‡ºæ¨¡æ¿ç»Ÿè®¡
    total_ch = sum(len(c["channels"]) for c in categories)
    safe_print(f"{COLOR_GREEN}âœ… æ¨¡æ¿è¯»å–å®Œæˆ | åˆ†ç±»æ•°ï¼š{len(categories)} | æ€»é¢‘é“æ•°ï¼š{total_ch} | è·¯å¾„ï¼š{os.path.abspath(template_path)}{COLOR_RESET}")
    safe_print("  " + "-" * 70)
    for i, cat in enumerate(categories, 1):
        safe_print(f"  {i:2d}. {cat['name']:<25} é¢‘é“æ•°ï¼š{len(cat['channels']):2d}")
    safe_print("  " + "-" * 70)
    return categories, all_channels


def load_valid_cache() -> dict:
    """åŠ è½½ç¼“å­˜ï¼Œè‡ªåŠ¨æ¸…ç†è¿‡æœŸ/è¶…é‡é¡¹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with CACHE_LOCK:
        if not os.path.exists(CACHE_FILE):
            return {}
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                cache = json.load(f)
            # è¿‡æ»¤è¿‡æœŸç¼“å­˜
            current_time = time.time()
            valid_cache = {
                url: info for url, info in cache.items()
                if current_time - info["timestamp"] < CACHE_EXPIRE
            }
            # æ¸…ç†è¶…é‡ç¼“å­˜
            if len(valid_cache) > MAX_CACHE_SIZE:
                sorted_cache = sorted(valid_cache.items(), key=lambda x: x[1]["timestamp"], reverse=True)
                valid_cache = dict(sorted_cache[:MAX_CACHE_SIZE])
                safe_print(f"{COLOR_YELLOW}âš ï¸ ç¼“å­˜è¶…é‡ï¼Œä¿ç•™æœ€æ–°{MAX_CACHE_SIZE}ä¸ª{COLOR_RESET}")
            logging.info(f"åŠ è½½ç¼“å­˜ï¼š{len(valid_cache)}ä¸ªæœ‰æ•ˆé¡¹")
            return valid_cache
        except Exception as e:
            safe_print(f"{COLOR_YELLOW}âš ï¸ åŠ è½½ç¼“å­˜å¤±è´¥ï¼š{str(e)}ï¼Œé‡æ–°ç”Ÿæˆ{COLOR_RESET}")
            logging.error(f"ç¼“å­˜åŠ è½½å¤±è´¥ï¼š{str(e)}")
            return {}


def save_valid_cache(cache: dict) -> bool:
    """ä¿å­˜ç¼“å­˜ï¼Œè‡ªåŠ¨æ§åˆ¶å¤§å°ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    with CACHE_LOCK:
        if len(cache) > MAX_CACHE_SIZE:
            sorted_cache = sorted(cache.items(), key=lambda x: x[1]["timestamp"], reverse=True)
            cache = dict(sorted_cache[:MAX_CACHE_SIZE])
        try:
            with open(CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(cache, f, ensure_ascii=False, indent=2)
            set_file_permissions(CACHE_FILE)
            logging.info(f"ä¿å­˜ç¼“å­˜ï¼š{len(cache)}ä¸ªé¡¹")
            return True
        except Exception as e:
            safe_print(f"{COLOR_YELLOW}âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥ï¼š{str(e)}ï¼Œä¸å½±å“æµç¨‹{COLOR_RESET}")
            logging.error(f"ç¼“å­˜ä¿å­˜å¤±è´¥ï¼š{str(e)}")
            return False


def is_valid_url(url: str) -> bool:
    """éªŒè¯URLæ˜¯å¦ä¸ºHTTP/HTTPSæ ¼å¼"""
    return URL_PAT.match(url) is not None


def fetch_single(url: str, cache: dict) -> str | None:
    """æŠ“å–å•ä¸ªæºï¼Œç»“åˆç¼“å­˜ä¼˜åŒ–ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    # æ£€æŸ¥ç¼“å­˜
    current_time = time.time()
    with CACHE_LOCK:
        if url in cache:
            cache_info = cache[url]
            if current_time - cache_info["timestamp"] < CACHE_EXPIRE:
                if cache_info["valid"]:
                    safe_print(f"{COLOR_BLUE}ğŸ” ç¼“å­˜å‘½ä¸­ï¼š{url[:50]}{'...' if len(url)>50 else ''}ï¼ˆæœ‰æ•ˆï¼‰{COLOR_RESET}")
                    return cache_info["content"]
                else:
                    safe_print(f"{COLOR_YELLOW}ğŸ” ç¼“å­˜å‘½ä¸­ï¼š{url[:50]}{'...' if len(url)>50 else ''}ï¼ˆå¤±æ•ˆï¼Œè·³è¿‡ï¼‰{COLOR_RESET}")
                    return None

    safe_print(f"{COLOR_BLUE}ğŸ” æŠ“å–ï¼š{url[:50]}{'...' if len(url)>50 else ''}{COLOR_RESET}")
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/124.0.0.0 Safari/537.36",
            "Accept": "*/*",
            "Connection": "keep-alive"
        }
        # é€‚é…ç³»ç»Ÿè¶…æ—¶
        connect_timeout = 5 if not IS_WINDOWS else 8
        read_timeout = SPEED_TEST_TIMEOUT if not IS_WINDOWS else SPEED_TEST_TIMEOUT + 2
        resp = requests.get(
            url,
            timeout=(connect_timeout, read_timeout),
            headers=headers,
            allow_redirects=True,
            max_redirects=MAX_REDIRECTS,
            stream=False
        )
        resp.raise_for_status()

        # å¤„ç†ç¼–ç 
        if not resp.encoding or resp.encoding.lower() == "iso-8859-1":
            resp.encoding = resp.apparent_encoding
        content = resp.text

        # æ ¡éªŒå†…å®¹æœ‰æ•ˆæ€§
        if len(content) < MIN_CONTENT_LEN:
            safe_print(f"{COLOR_YELLOW}âš ï¸ å†…å®¹è¿‡çŸ­ï¼ˆ{len(content)}å­—ç¬¦ï¼‰ï¼Œæ— æ•ˆ{COLOR_RESET}")
            with CACHE_LOCK:
                cache[url] = {"valid": False, "timestamp": current_time}
            return None
        if not (URL_PAT.search(content) or "#EXTM3U" in content[:100]):
            safe_print(f"{COLOR_YELLOW}âš ï¸ æ— ç›´æ’­æºä¿¡æ¯ï¼Œæ— æ•ˆ{COLOR_RESET}")
            with CACHE_LOCK:
                cache[url] = {"valid": False, "timestamp": current_time}
            return None

        # ç¼“å­˜æœ‰æ•ˆå†…å®¹
        safe_print(f"{COLOR_GREEN}âœ… æŠ“å–æˆåŠŸ | é•¿åº¦ï¼š{len(content):,}å­—ç¬¦{COLOR_RESET}")
        with CACHE_LOCK:
            cache[url] = {"valid": True, "content": content, "timestamp": current_time}
        return content

    except requests.exceptions.ConnectTimeout:
        msg = "è¿æ¥è¶…æ—¶"
    except requests.exceptions.ReadTimeout:
        msg = f"è¯»å–è¶…æ—¶ï¼ˆ>{read_timeout}ç§’ï¼‰"
    except requests.exceptions.TooManyRedirects:
        msg = f"é‡å®šå‘è¶…{MAX_REDIRECTS}æ¬¡"
    except requests.exceptions.ConnectionError:
        msg = "ç½‘ç»œè¿æ¥å¤±è´¥"
    except requests.exceptions.HTTPError as e:
