#!/usr/bin/env python3
import requests
import pandas as pd
import re
import os
import time
import subprocess
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse

class IPTVManager:
    def __init__(self):
        # é…ç½®æ–‡ä»¶
        self.SOURCE_URLS = [
    "https://raw.githubusercontent.com/zwc456baby/iptv_alive/master/live.txt",
    "https://raw.githubusercontent.com/iptv-org/iptv/gh-pages/countries/cn.m3u",
    "https://ghfast.top/raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt",
    "https://gh-proxy.com/https://raw.githubusercontent.com/wwb521/live/main/tv.m3u",
    "https://gh-proxy.com/https://raw.githubusercontent.com/zeee-u/lzh06/main/fl.m3u",
    "https://raw.githubusercontent.com/Guovin/iptv-database/master/result.txt",  
    "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
    "https://raw.githubusercontent.com/suxuang/myIPTV/main/ipv4.m3u",
    "https://raw.githubusercontent.com/vbskycn/iptv/master/tv/iptv4.txt",
    "http://47.120.41.246:8899/zb.txt",
    "https://live.zbds.top/tv/iptv4.txt",
        ]
        
        self.REQUEST_CONFIG = {
            'timeout': 15,
            'headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
        }
        
        self.CHANNEL_CONFIG = {
            'max_sources_per_channel': 8,
            'speed_test_timeout': 5,
        }
        
        self.FILE_CONFIG = {
            'template_file': 'demo.txt',
            'output_txt': 'iptv.txt',
            'output_m3u': 'iptv.m3u',
            'temp_dir': 'temp',
        }
        
        # åˆå§‹åŒ–ä¼šè¯å’Œç›®å½•
        self.session = requests.Session()
        self.session.headers.update(self.REQUEST_CONFIG['headers'])
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        if not os.path.exists(self.FILE_CONFIG['temp_dir']):
            os.makedirs(self.FILE_CONFIG['temp_dir'])
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.ipv4_pattern = re.compile(r'^https?://(\d{1,3}\.){3}\d{1,3}')
        self.ipv6_pattern = re.compile(r'^https?://\[([a-fA-F0-9:]+)\]')
        self.extinf_pattern = re.compile(r'#EXTINF:.*?tvg-name="([^"]+)".*?,(.+)')
        self.category_pattern = re.compile(r'^(.*?),#genre#$')
        self.url_pattern = re.compile(r'https?://[^\s,]+')
        
        # çŠ¶æ€å˜é‡
        self.ffmpeg_available = False
        self.processed_count = 0
        self.total_count = 0

    def check_dependencies(self):
        """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
        try:
            import requests
            import pandas
            print("âœ… åŸºç¡€ä¾èµ–æ£€æŸ¥é€šè¿‡")
        except ImportError as e:
            print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
            print("è¯·è¿è¡Œ: pip install requests pandas")
            return False
            
        # æ£€æŸ¥FFmpeg
        try:
            subprocess.run(['ffmpeg', '-version'], capture_output=True, timeout=5)
            print("âœ… FFmpegå¯ç”¨")
            self.ffmpeg_available = True
        except:
            print("âš ï¸  FFmpegæœªå®‰è£…ï¼Œå°†ä½¿ç”¨HTTPæµ‹é€Ÿ")
            self.ffmpeg_available = False
            
        return True

    def validate_url(self, url):
        """éªŒè¯URLæ ¼å¼"""
        try:
            result = urlparse(url)
            return all([result.scheme in ['http', 'https'], result.netloc])
        except:
            return False

    def fetch_streams_from_url(self, url):
        """ä»URLè·å–æµæ•°æ®"""
        print(f"ğŸ“¡ æ­£åœ¨çˆ¬å–æº: {url}")
        try:
            response = self.session.get(url, timeout=self.REQUEST_CONFIG['timeout'])
            response.encoding = 'utf-8'
            if response.status_code == 200:
                content_length = len(response.text)
                print(f"âœ… æˆåŠŸè·å–æ•°æ®: {url} ({content_length} å­—ç¬¦)")
                return response.text
            else:
                print(f"âŒ è·å–æ•°æ®å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code} - {url}")
        except Exception as e:
            print(f"âŒ è¯·æ±‚é”™è¯¯: {e} - {url}")
        return None

    def fetch_all_streams(self):
        """è·å–æ‰€æœ‰æºçš„æµæ•°æ®"""
        print("ğŸš€ å¼€å§‹æ™ºèƒ½å¤šæºæŠ“å–...")
        all_streams = []
        successful_sources = 0
        
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_url = {executor.submit(self.fetch_streams_from_url, url): url for url in self.SOURCE_URLS}
            
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    if content := future.result():
                        all_streams.append(content)
                        successful_sources += 1
                except Exception as e:
                    print(f"âŒ å¤„ç† {url} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        print(f"âœ… æˆåŠŸè·å– {successful_sources}/{len(self.SOURCE_URLS)} ä¸ªæºçš„æ•°æ®")
        return "\n".join(all_streams)

    def parse_m3u(self, content):
        """è§£æM3Uæ ¼å¼"""
        streams = []
        current_program = None
        current_group = None
        
        for line in content.splitlines():
            line = line.strip()
            if not line:
                continue
                
            if line.startswith("#EXTINF"):
                current_program = "æœªçŸ¥é¢‘é“"
                current_group = "é»˜è®¤åˆ†ç»„"
                
                # æå–é¢‘é“åç§°
                if match := re.search(r'tvg-name="([^"]+)"', line):
                    current_program = match.group(1).strip()
                elif match := re.search(r'#EXTINF:.*?,(.+)', line):
                    current_program = match.group(1).strip()
                
                # æå–åˆ†ç»„ä¿¡æ¯
                if match := re.search(r'group-title="([^"]+)"', line):
                    current_group = match.group(1).strip()
                    
            elif line.startswith(('http://', 'https://')):
                if current_program and self.validate_url(line):
                    streams.append({
                        "program_name": current_program,
                        "stream_url": line,
                        "group": current_group
                    })
                current_program = None
                current_group = None
        
        return streams

    def parse_txt(self, content):
        """è§£æTXTæ ¼å¼"""
        streams = []
        
        for line in content.splitlines():
            line = line.strip()
            if not line or line.startswith('#') or '#genre#' in line:
                continue
            
            # å¤šç§åˆ†éš”ç¬¦æ”¯æŒï¼šé€—å·ã€ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ç­‰
            if ',' in line:
                parts = line.split(',', 1)
                if len(parts) == 2:
                    program_name = parts[0].strip()
                    # ä»ç¬¬äºŒéƒ¨åˆ†æå–URL
                    url_match = self.url_pattern.search(parts[1])
                    if url_match:
                        stream_url = url_match.group()
                        if self.validate_url(stream_url):
                            streams.append({
                                "program_name": program_name,
                                "stream_url": stream_url,
                                "group": "é»˜è®¤åˆ†ç»„"
                            })
            else:
                # å°è¯•ä»è¡Œä¸­æå–URL
                url_match = self.url_pattern.search(line)
                if url_match:
                    stream_url = url_match.group()
                    program_name = line.replace(stream_url, '').strip()
                    if program_name and self.validate_url(stream_url):
                        streams.append({
                            "program_name": program_name,
                            "stream_url": stream_url,
                            "group": "é»˜è®¤åˆ†ç»„"
                        })
        
        return streams

    def organize_streams(self, content):
        """æ•´ç†æµæ•°æ®"""
        if not content:
            print("âŒ æ²¡æœ‰å†…å®¹å¯å¤„ç†")
            return pd.DataFrame()
            
        print("ğŸ” è§£ææµæ•°æ®...")
        
        # è‡ªåŠ¨æ£€æµ‹æ ¼å¼å¹¶è§£æ
        if content.startswith("#EXTM3U"):
            streams = self.parse_m3u(content)
        else:
            streams = self.parse_txt(content)
        
        if not streams:
            print("âŒ æœªèƒ½è§£æå‡ºä»»ä½•æµæ•°æ®")
            return pd.DataFrame()
            
        df = pd.DataFrame(streams)
        
        # æ•°æ®æ¸…ç†
        initial_count = len(df)
        df = df.dropna()
        df = df[df['program_name'].str.len() > 0]
        df = df[df['stream_url'].str.startswith(('http://', 'https://'))]
        
        # å»é‡
        df = df.drop_duplicates(subset=['program_name', 'stream_url'])
        
        print(f"ğŸ“Š æ•°æ®æ¸…ç†: {initial_count} -> {len(df)} ä¸ªæµ")
        return df

    def load_template(self):
        """åŠ è½½é¢‘é“æ¨¡æ¿"""
        template_file = self.FILE_CONFIG['template_file']
        if not os.path.exists(template_file):
            print(f"âŒ æ¨¡æ¿æ–‡ä»¶ {template_file} ä¸å­˜åœ¨")
            return None
            
        print(f"ğŸ“‹ åŠ è½½æ¨¡æ¿æ–‡ä»¶: {template_file}")
        categories = {}
        current_category = None
        
        try:
            with open(template_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                        
                    # æ£€æµ‹åˆ†ç±»è¡Œ
                    if match := self.category_pattern.match(line):
                        current_category = match.group(1).strip()
                        categories[current_category] = []
                    elif current_category and line and not line.startswith('#'):
                        # é¢‘é“è¡Œ
                        if ',' in line:
                            channel_name = line.split(',')[0].strip()
                        else:
                            channel_name = line.strip()
                        if channel_name:
                            categories[current_category].append(channel_name)
        except Exception as e:
            print(f"âŒ è¯»å–æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return None
        
        if not categories:
            print("âŒ æ¨¡æ¿æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„é¢‘é“åˆ†ç±»")
            return None
            
        print(f"ğŸ“ æ¨¡æ¿åˆ†ç±»: {list(categories.keys())}")
        total_channels = sum(len(channels) for channels in categories.values())
        print(f"ğŸ“º æ¨¡æ¿é¢‘é“æ€»æ•°: {total_channels}")
        
        return categories

    def similarity_score(self, str1, str2):
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦åˆ†æ•°"""
        if not str1 or not str2:
            return 0
            
        str1_clean = re.sub(r'[^\w]', '', str1.lower())
        str2_clean = re.sub(r'[^\w]', '', str2.lower())
        
        # å®Œå…¨åŒ¹é…
        if str1_clean == str2_clean:
            return 100
        
        # åŒ…å«å…³ç³»ï¼ˆåŒå‘ï¼‰
        if str1_clean in str2_clean:
            return 90
        if str2_clean in str1_clean:
            return 85
        
        # å…±åŒå­—ç¬¦æ¯”ä¾‹
        common_chars = len(set(str1_clean) & set(str2_clean))
        total_chars = len(set(str1_clean) | set(str2_clean))
        
        if total_chars > 0:
            similarity = (common_chars / total_chars) * 80
            return int(similarity)
        
        return 0

    def speed_test_ffmpeg(self, stream_url):
        """ä½¿ç”¨FFmpegè¿›è¡Œæµåª’ä½“æµ‹é€Ÿ"""
        if not self.ffmpeg_available:
            return False, float('inf')
            
        temp_file = os.path.join(self.FILE_CONFIG['temp_dir'], f'test_{abs(hash(stream_url))}.ts')
        
        try:
            # ä½¿ç”¨FFmpegæµ‹è¯•æµåª’ä½“å¯è®¿é—®æ€§
            cmd = [
                'ffmpeg',
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                '-timeout', '3000000',  # 3ç§’è¶…æ—¶ï¼ˆå¾®ç§’ï¼‰
                '-i', stream_url,
                '-t', '2',  # åªæµ‹è¯•2ç§’
                '-c', 'copy',
                '-f', 'mpegts',
                '-max_muxing_queue_size', '1024',
                temp_file
            ]
            
            start_time = time.time()
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=5  # æ€»è¶…æ—¶æ—¶é—´
            )
            end_time = time.time()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
            
            if result.returncode == 0:
                speed = end_time - start_time
                return True, speed
            else:
                return False, float('inf')
                
        except (subprocess.TimeoutExpired, Exception):
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
            return False, float('inf')

    def speed_test_simple(self, stream_url):
        """ç®€å•çš„HTTPæµ‹é€Ÿ"""
        try:
            start_time = time.time()
            response = self.session.head(
                stream_url, 
                timeout=self.CHANNEL_CONFIG['speed_test_timeout'],
                allow_redirects=True
            )
            end_time = time.time()
            
            if response.status_code in [200, 302, 301, 307]:
                return True, end_time - start_time
            else:
                return False, float('inf')
        except Exception:
            return False, float('inf')

    def filter_and_sort_sources(self, sources_df, template_channels):
        """æ ¹æ®æ¨¡æ¿è¿‡æ»¤å’Œæ’åºæº"""
        print("ğŸ¯ å¼€å§‹é¢‘é“åŒ¹é…å’Œæºç­›é€‰...")
        
        # åˆ›å»ºé¢‘é“æ˜ å°„ï¼ˆæ¨¡ç³ŠåŒ¹é…ï¼‰
        channel_mapping = {}
        match_results = []
        
        for template_channel in template_channels:
            best_match = None
            best_score = 0
            best_source_channel = None
            
            # åœ¨æºæ•°æ®ä¸­å¯»æ‰¾æœ€ä½³åŒ¹é…
            for source_channel in sources_df['program_name'].unique():
                score = self.similarity_score(template_channel, source_channel)
                if score > best_score and score > 50:  # ç›¸ä¼¼åº¦é˜ˆå€¼æé«˜åˆ°50
                    best_score = score
                    best_match = template_channel
                    best_source_channel = source_channel
            
            if best_match and best_source_channel:
                channel_mapping[best_source_channel] = best_match
                match_results.append((best_match, best_source_channel, best_score))
        
        # æ‰“å°åŒ¹é…ç»“æœ
        for template_channel, source_channel, score in sorted(match_results, key=lambda x: x[2], reverse=True)[:10]:
            print(f"  âœ… åŒ¹é…: {template_channel} <- {source_channel} (åˆ†æ•°: {score})")
        
        if len(match_results) > 10:
            print(f"  ... è¿˜æœ‰ {len(match_results) - 10} ä¸ªåŒ¹é…")
        
        # è¿‡æ»¤æ•°æ®ï¼Œåªä¿ç•™åŒ¹é…çš„é¢‘é“
        matched_mask = sources_df['program_name'].isin(channel_mapping.keys())
        filtered_df = sources_df[matched_mask].copy()
        
        # å°†æºé¢‘é“åç§°æ˜ å°„å›æ¨¡æ¿é¢‘é“åç§°
        filtered_df['program_name'] = filtered_df['program_name'].map(channel_mapping)
        
        print(f"âœ… é¢‘é“åŒ¹é…å®Œæˆ: {len(filtered_df)} ä¸ªæµåŒ¹é…åˆ° {len(set(channel_mapping.values()))} ä¸ªæ¨¡æ¿é¢‘é“")
        return filtered_df

    def speed_test_sources(self, sources_df):
        """å¯¹æºè¿›è¡Œæµ‹é€Ÿ"""
        print("â±ï¸  å¼€å§‹æ™ºèƒ½æµ‹é€Ÿ...")
        
        if sources_df.empty:
            print("âŒ æ²¡æœ‰éœ€è¦æµ‹é€Ÿçš„æº")
            return pd.DataFrame()
            
        results = []
        total_sources = len(sources_df)
        self.total_count = total_sources
        self.processed_count = 0
        
        def test_single_source(row):
            program_name = row['program_name']
            stream_url = row['stream_url']
            
            self.processed_count += 1
            current = self.processed_count
            total = self.total_count
            
            print(f"  ğŸ” æµ‹è¯• {current}/{total}: {program_name[:25]:<25}...", end=' ')
            
            # æ ¹æ®URLç±»å‹é€‰æ‹©æµ‹é€Ÿæ–¹æ³•
            if any(ext in stream_url.lower() for ext in ['.m3u8', '.ts', '.flv', '.mp4']):
                # æµåª’ä½“æ ¼å¼ï¼Œä¼˜å…ˆä½¿ç”¨FFmpeg
                if self.ffmpeg_available:
                    accessible, speed = self.speed_test_ffmpeg(stream_url)
                else:
                    accessible, speed = self.speed_test_simple(stream_url)
            else:
                # å…¶ä»–æ ¼å¼ä½¿ç”¨ç®€å•æµ‹é€Ÿ
                accessible, speed = self.speed_test_simple(stream_url)
            
            if accessible:
                print(f"âœ… ({(speed):.2f}s)")
            else:
                print("âŒ")
            
            return {
                'program_name': program_name,
                'stream_url': stream_url,
                'accessible': accessible,
                'speed': speed
            }
        
        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘æµ‹é€Ÿï¼ˆé™åˆ¶å¹¶å‘æ•°ï¼‰
        with ThreadPoolExecutor(max_workers=6) as executor:
            futures = [executor.submit(test_single_source, row) for _, row in sources_df.iterrows()]
            
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=10)
                    results.append(result)
                except Exception as e:
                    print(f"    âŒ æµ‹é€Ÿå¼‚å¸¸: {e}")
        
        # è½¬æ¢ä¸ºDataFrame
        result_df = pd.DataFrame(results)
        
        # è¿‡æ»¤ä¸å¯è®¿é—®çš„æº
        accessible_df = result_df[result_df['accessible']].copy()
        
        print(f"ğŸ“Š æµ‹é€Ÿå®Œæˆ: {len(accessible_df)}/{total_sources} ä¸ªæºå¯ç”¨")
        
        return accessible_df

    def generate_final_data(self, speed_tested_df, template_categories):
        """ç”Ÿæˆæœ€ç»ˆæ•°æ®"""
        print("ğŸ¨ ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶...")
        
        final_data = {}
        total_sources = 0
        
        for category, channels in template_categories.items():
            final_data[category] = {}
            
            for channel in channels:
                # è·å–è¯¥é¢‘é“çš„æ‰€æœ‰æº
                channel_sources = speed_tested_df[speed_tested_df['program_name'] == channel]
                
                if not channel_sources.empty:
                    # æŒ‰é€Ÿåº¦æ’åºå¹¶å–å‰Nä¸ª
                    sorted_sources = channel_sources.sort_values('speed').head(
                        self.CHANNEL_CONFIG['max_sources_per_channel']
                    )
                    final_data[category][channel] = sorted_sources[['stream_url', 'speed']].to_dict('records')
                    source_count = len(sorted_sources)
                    total_sources += source_count
                    print(f"  âœ… {category}-{channel}: {source_count}ä¸ªæº")
                else:
                    final_data[category][channel] = []
                    print(f"  âŒ {category}-{channel}: æ— å¯ç”¨æº")
        
        print(f"ğŸ“¦ æ€»å…±æ”¶é›†åˆ° {total_sources} ä¸ªæœ‰æ•ˆæº")
        return final_data

    def save_output_files(self, final_data):
        """ä¿å­˜è¾“å‡ºæ–‡ä»¶"""
        print("ğŸ’¾ ä¿å­˜æ–‡ä»¶...")
        
        # ä¿å­˜TXTæ ¼å¼
        try:
            with open(self.FILE_CONFIG['output_txt'], 'w', encoding='utf-8') as f:
                for category, channels in final_data.items():
                    f.write(f"{category},#genre#\n")
                    
                    for channel, sources in channels.items():
                        for source in sources:
                            f.write(f"{channel},{source['stream_url']}\n")
                    
                    f.write("\n")
            print(f"âœ… TXTæ–‡ä»¶å·²ä¿å­˜: {os.path.abspath(self.FILE_CONFIG['output_txt'])}")
        except Exception as e:
            print(f"âŒ ä¿å­˜TXTæ–‡ä»¶å¤±è´¥: {e}")
            return False
        
        # ä¿å­˜M3Uæ ¼å¼
        try:
            with open(self.FILE_CONFIG['output_m3u'], 'w', encoding='utf-8') as f:
                f.write("#EXTM3U\n")
                
                for category, channels in final_data.items():
                    for channel, sources in channels.items():
                        for source in sources:
                            f.write(f'#EXTINF:-1 tvg-name="{channel}" group-title="{category}",{channel}\n')
                            f.write(f"{source['stream_url']}\n")
            print(f"âœ… M3Uæ–‡ä»¶å·²ä¿å­˜: {os.path.abspath(self.FILE_CONFIG['output_m3u'])}")
        except Exception as e:
            print(f"âŒ ä¿å­˜M3Uæ–‡ä»¶å¤±è´¥: {e}")
            return False
            
        return True

    def print_statistics(self, final_data):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“ˆ ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
        print("="*50)
        
        total_channels = 0
        total_sources = 0
        categories_with_sources = 0
        
        for category, channels in final_data.items():
            category_channels = 0
            category_sources = 0
            
            for channel, sources in channels.items():
                if sources:
                    category_channels += 1
                    category_sources += len(sources)
            
            if category_channels > 0:
                categories_with_sources += 1
                print(f"  ğŸ“º {category}: {category_channels}é¢‘é“, {category_sources}æº")
                total_channels += category_channels
                total_sources += category_sources
        
        print("-"*50)
        print(f"ğŸ“Š æ€»è®¡: {total_channels}é¢‘é“, {total_sources}æº")
        print(f"ğŸ“ æœ‰æ•ˆåˆ†ç±»: {categories_with_sources}/{len(final_data)}")
        
        # ç»Ÿè®¡æ— æºçš„é¢‘é“
        no_source_channels = []
        for category, channels in final_data.items():
            for channel, sources in channels.items():
                if not sources:
                    no_source_channels.append(f"{category}-{channel}")
        
        if no_source_channels:
            print(f"âš ï¸  æ— æºé¢‘é“: {len(no_source_channels)}ä¸ª")
            if len(no_source_channels) <= 15:
                for channel in no_source_channels:
                    print(f"    âŒ {channel}")

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_dir = self.FILE_CONFIG['temp_dir']
            if os.path.exists(temp_dir):
                for file in os.listdir(temp_dir):
                    file_path = os.path.join(temp_dir, file)
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                print("âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def create_demo_template(self):
        """åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶"""
        demo_content = """å¤®è§†é¢‘é“,#genre#
CCTV-1 ç»¼åˆ
CCTV-2 è´¢ç»
CCTV-3 ç»¼è‰º
CCTV-4 ä¸­æ–‡å›½é™…
CCTV-5 ä½“è‚²
CCTV-6 ç”µå½±
CCTV-7 å›½é˜²å†›äº‹
CCTV-8 ç”µè§†å‰§
CCTV-9 çºªå½•
CCTV-10 ç§‘æ•™
CCTV-11 æˆæ›²
CCTV-12 ç¤¾ä¼šä¸æ³•
CCTV-13 æ–°é—»
CCTV-14 å°‘å„¿
CCTV-15 éŸ³ä¹

å«è§†é¢‘é“,#genre#
æ¹–å—å«è§†
æµ™æ±Ÿå«è§†
æ±Ÿè‹å«è§†
ä¸œæ–¹å«è§†
åŒ—äº¬å«è§†
å¤©æ´¥å«è§†
å±±ä¸œå«è§†
å¹¿ä¸œå«è§†

åœ°æ–¹é¢‘é“,#genre#
åŒ—äº¬æ–°é—»
ä¸Šæµ·æ–°é—»
å¹¿å·ç»¼åˆ
æ·±åœ³å«è§†
"""
        try:
            with open(self.FILE_CONFIG['template_file'], 'w', encoding='utf-8') as f:
                f.write(demo_content)
            print(f"âœ… å·²åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶: {self.FILE_CONFIG['template_file']}")
            print("ğŸ’¡ è¯·ç¼–è¾‘æ­¤æ–‡ä»¶ï¼Œæ·»åŠ æ‚¨éœ€è¦çš„é¢‘é“åˆ—è¡¨")
            return True
        except Exception as e:
            print(f"âŒ åˆ›å»ºæ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("=" * 60)
        print("ğŸ¬ IPTVæ™ºèƒ½ç®¡ç†å·¥å…· - å®Œæ•´ç‰ˆ v1.0")
        print("=" * 60)
        
        # æ£€æŸ¥ä¾èµ–
        if not self.check_dependencies():
            print("âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            return
        
        # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºç¤ºä¾‹
        if not os.path.exists(self.FILE_CONFIG['template_file']):
            print("ğŸ“ æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹æ¨¡æ¿...")
            if not self.create_demo_template():
                return
            print("è¯·ç¼–è¾‘ demo.txt æ–‡ä»¶ï¼Œæ·»åŠ æ‚¨éœ€è¦çš„é¢‘é“ï¼Œç„¶åé‡æ–°è¿è¡Œç¨‹åº")
            return
        
        start_time = time.time()
        
        try:
            # 1. åŠ è½½æ¨¡æ¿
            print("\nğŸ“‹ æ­¥éª¤ 1/7: åŠ è½½é¢‘é“æ¨¡æ¿")
            template_categories = self.load_template()
            if not template_categories:
                return
            
            # 2. è·å–æ‰€æœ‰æºæ•°æ®
            print("\nğŸŒ æ­¥éª¤ 2/7: è·å–æºæ•°æ®")
            content = self.fetch_all_streams()
            if not content:
                print("âŒ æœªèƒ½è·å–ä»»ä½•æºæ•°æ®")
                return
            
            # 3. æ•´ç†æºæ•°æ®
            print("\nğŸ”§ æ­¥éª¤ 3/7: æ•´ç†æºæ•°æ®")
            sources_df = self.organize_streams(content)
            if sources_df.empty:
                print("âŒ æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„æµæ•°æ®")
                return
            
            # 4. è·å–æ‰€æœ‰æ¨¡æ¿é¢‘é“
            all_template_channels = []
            for channels in template_categories.values():
                all_template_channels.extend(channels)
            
            # 5. è¿‡æ»¤å’ŒåŒ¹é…é¢‘é“
            print("\nğŸ¯ æ­¥éª¤ 4/7: é¢‘é“åŒ¹é…")
            filtered_df = self.filter_and_sort_sources(sources_df, all_template_channels)
            if filtered_df.empty:
                print("âŒ æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æ¨¡æ¿é¢‘é“")
                return
            
            # 6. æµ‹é€Ÿ
            print("\nâš¡ æ­¥éª¤ 5/7: æºæµ‹é€Ÿ")
            speed_tested_df = self.speed_test_sources(filtered_df)
            if speed_tested_df.empty:
                print("âŒ æ²¡æœ‰å¯ç”¨çš„æºé€šè¿‡æµ‹é€Ÿ")
                return
            
            # 7. ç”Ÿæˆæœ€ç»ˆæ•°æ®
            print("\nğŸ¨ æ­¥éª¤ 6/7: ç”Ÿæˆæ’­æ”¾åˆ—è¡¨")
            final_data = self.generate_final_data(speed_tested_df, template_categories)
            
            # 8. ä¿å­˜æ–‡ä»¶
            print("\nğŸ’¾ æ­¥éª¤ 7/7: ä¿å­˜æ–‡ä»¶")
            if not self.save_output_files(final_data):
                print("âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥")
                return
            
            # 9. æ‰“å°ç»Ÿè®¡
            self.print_statistics(final_data)
            
            end_time = time.time()
            elapsed_time = end_time - start_time
            
            print("\nğŸ‰ å¤„ç†å®Œæˆ!")
            print(f"â° æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
            print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶ä½ç½®:")
            print(f"   ğŸ“„ {os.path.abspath(self.FILE_CONFIG['output_txt'])}")
            print(f"   ğŸ“„ {os.path.abspath(self.FILE_CONFIG['output_m3u'])}")
            
        except KeyboardInterrupt:
            print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self.cleanup()

def main():
    """ä¸»å‡½æ•°"""
    try:
        manager = IPTVManager()
        manager.run()
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
