import requests
import pandas as pd
import re
import os
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

# ======================== æ ¸å¿ƒé…ç½®åŒºï¼ˆå¯æŒ‰éœ€ä¿®æ”¹ï¼‰========================
SOURCE_URLS = [
    "https://raw.githubusercontent.com/zwc456baby/iptv_alive/master/live.txt",
    "https://live.zbds.top/tv/iptv6.txt",
    "https://live.zbds.top/tv/iptv4.txt",
]
CATEGORY_TEMPLATE_PATH = "demo.txt"  # åˆ†ç±»æ¨¡æ¿è·¯å¾„
MAX_INTERFACES_PER_CHANNEL = 5  # å•é¢‘é“æœ€å¤§æ¥å£æ•°
SPEED_TEST_TIMEOUT = 8  # æµ‹é€Ÿè¶…æ—¶ï¼ˆç§’ï¼‰
MAX_SPEED_TEST_WORKERS = 15  # æµ‹é€Ÿå¹¶å‘æ•°
MAX_FETCH_WORKERS = 5  # æŠ“å–å¹¶å‘æ•°ï¼ˆé¿å…è¯·æ±‚è¿‡è½½ï¼‰
OUTPUT_FILE_PREFIX = "iptv"  # è¾“å‡ºæ–‡ä»¶å‰ç¼€
CATEGORY_MARKER = "#genre#"  # åˆ†ç±»æ¨¡æ¿æ ‡è®°
# =========================================================================

# æ­£åˆ™è¡¨è¾¾å¼ï¼ˆä¼˜åŒ–é€‚é… HTTPSï¼‰
IPV4_PATTERN = re.compile(r'^https?://(\d{1,3}\.){3}\d{1,3}')
IPV6_PATTERN = re.compile(r'^https?://\[([a-fA-F0-9:]+)\]')
URL_PATTERN = re.compile(r'^https?://')
SPACE_CLEAN_PATTERN = re.compile(r'\s+')


def print_separator(title: str = "", length: int = 70) -> None:
    """æ‰“å°åˆ†éš”çº¿ï¼Œä¼˜åŒ–å¯è¯»æ€§"""
    sep = "=" * length
    if title:
        print(f"\n{sep}")
        print(f"ğŸ“Œ {title}")
        print(sep)
    else:
        print(sep)


def clean_text(text: str) -> str:
    """æ¸…ç†æ–‡æœ¬ï¼šå»é™¤å¤šä½™ç©ºæ ¼ã€æ¢è¡Œç¬¦"""
    return SPACE_CLEAN_PATTERN.sub("", str(text).strip())


def read_category_template(template_path: str) -> tuple[list[dict], list[str]] | tuple[None, None]:
    """è¯»å–åˆ†ç±»æ¨¡æ¿ï¼Œè¿”å›(åˆ†ç±»ç»“æ„, å»é‡é¢‘é“åˆ—è¡¨)æˆ–(None, None)"""
    if not os.path.exists(template_path):
        print(f"æ¨¡æ¿æ–‡ä»¶ã€Œ{template_path}ã€ä¸å­˜åœ¨ï¼")
        print(f"æ¨¡æ¿æ ¼å¼ç¤ºä¾‹ï¼š\n  {CATEGORY_MARKER} å¤®è§†é¢‘é“\n  CCTV1\n  CCTV2\n  {CATEGORY_MARKER} å«è§†é¢‘é“\n  æ¹–å—å«è§†")
        return None, None

    categories = []
    current_category = None
    all_channels = []

    try:
        with open(template_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                # è·³è¿‡éåˆ†ç±»æ ‡è®°çš„æ³¨é‡Šè¡Œ
                if line.startswith("#") and not line.startswith(CATEGORY_MARKER):
                    continue

                # å¤„ç†åˆ†ç±»è¡Œï¼ˆåŒ¹é…#genre#æ ‡è®°ï¼‰
                if line.startswith(CATEGORY_MARKER):
                    cat_name = clean_text(line.lstrip(CATEGORY_MARKER))
                    if not cat_name:
                        print(f"ç¬¬{line_num}è¡Œï¼šåˆ†ç±»åæ— æ•ˆï¼Œå¿½ç•¥")
                        current_category = None
                        continue
                    # åˆå¹¶é‡å¤åˆ†ç±»
                    existing = next((c for c in categories if c["category"] == cat_name), None)
                    if existing:
                        current_category = cat_name
                    else:
                        categories.append({"category": cat_name, "channels": []})
                        current_category = cat_name
                    continue

                # å¤„ç†é¢‘é“è¡Œ
                if current_category is None:
                    print(f"ç¬¬{line_num}è¡Œï¼šé¢‘é“æœªåˆ†ç±»ï¼Œå½’å…¥ã€Œæœªåˆ†ç±»ã€")
                    if not any(c["category"] == "æœªåˆ†ç±»" for c in categories):
                        categories.append({"category": "æœªåˆ†ç±»", "channels": []})
                    current_category = "æœªåˆ†ç±»"

                ch_name = clean_text(line.split(",")[0])
                if not ch_name:
                    print(f"ç¬¬{line_num}è¡Œï¼šé¢‘é“åæ— æ•ˆï¼Œå¿½ç•¥")
                    continue
                # å»é‡å¹¶æ·»åŠ åˆ°åˆ†ç±»
                if ch_name not in all_channels:
                    all_channels.append(ch_name)
                    for cat in categories:
                        if cat["category"] == current_category:
                            cat["channels"].append(ch_name)
                            break
    except Exception as e:
        print(f"è¯»å–æ¨¡æ¿å¤±è´¥ï¼š{str(e)}")
        return None, None

    if not categories:
        print("æ¨¡æ¿æ— æœ‰æ•ˆåˆ†ç±»/é¢‘é“")
        return None, None

    # è¾“å‡ºæ¨¡æ¿ç»Ÿè®¡
    total_ch = sum(len(cat["channels"]) for cat in categories)
    print(f"âœ… æ¨¡æ¿è¯»å–å®Œæˆ | åˆ†ç±»æ•°ï¼š{len(categories)} | é¢‘é“æ•°ï¼š{total_ch}")
    print("  " + "-" * 50)
    for idx, cat in enumerate(categories, 1):
        print(f"  {idx:2d}. åˆ†ç±»ï¼š{cat['category']:<20} é¢‘é“æ•°ï¼š{len(cat['channels']):2d}")
    print("  " + "-" * 50)
    return categories, all_channels


def fetch_single_source(url: str) -> str | None:
    """æŠ“å–å•ä¸ªURLçš„ç›´æ’­æºå†…å®¹ï¼ˆä¼˜åŒ–è¶…æ—¶å’Œç¼–ç å¤„ç†ï¼‰"""
    print(f"\nğŸ” æŠ“å–ï¼š{url}")
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/124.0.0.0 Safari/537.36",
            "Accept": "*/*",
            "Connection": "keep-alive"
        }
        resp = requests.get(
            url,
            timeout=(5, SPEED_TEST_TIMEOUT),  # è¿æ¥è¶…æ—¶5sï¼Œè¯»å–è¶…æ—¶æŒ‰é…ç½®
            headers=headers,
            allow_redirects=True,
            stream=False
        )
        resp.raise_for_status()
        # æ™ºèƒ½ç¼–ç å¤„ç†ï¼ˆè§£å†³ä¸­æ–‡ä¹±ç ï¼‰
        if not resp.encoding or resp.encoding.lower() == "iso-8859-1":
            resp.encoding = resp.apparent_encoding
        print(f"âœ… æˆåŠŸ | é•¿åº¦ï¼š{len(resp.text):,} å­—ç¬¦")
        return resp.text
    except requests.exceptions.ConnectTimeout:
        print(f"âŒ å¤±è´¥ï¼šè¿æ¥è¶…æ—¶ï¼ˆè¶…è¿‡5ç§’ï¼‰")
    except requests.exceptions.ReadTimeout:
        print(f"âŒ å¤±è´¥ï¼šè¯»å–è¶…æ—¶ï¼ˆè¶…è¿‡{SPEED_TEST_TIMEOUT}ç§’ï¼‰")
    except requests.exceptions.ConnectionError:
        print(f"âŒ å¤±è´¥ï¼šç½‘ç»œé”™è¯¯ï¼ˆæ— æ³•è¿æ¥ï¼‰")
    except requests.exceptions.HTTPError as e:
        print(f"âŒ å¤±è´¥ï¼šHTTP {e.response.status_code}")
    except Exception as e:
        print(f"âŒ å¤±è´¥ï¼š{str(e)[:50]}")
    return None


def batch_fetch_sources(url_list: list) -> str:
    """æ‰¹é‡æŠ“å–å¤šä¸ªURLçš„ç›´æ’­æºï¼ˆå¹¶å‘æŠ“å–æå‡æ•ˆç‡ï¼‰"""
    if not url_list:
        print("URLåˆ—è¡¨ä¸ºç©º")
        return ""

    total = len(url_list)
    combined_content = []
    print(f"ğŸ“¥ æ‰¹é‡æŠ“å– | æ€»URLæ•°ï¼š{total} | å¹¶å‘æ•°ï¼š{MAX_FETCH_WORKERS}")
    print("-" * 70)

    with ThreadPoolExecutor(max_workers=MAX_FETCH_WORKERS) as executor:
        future_tasks = {executor.submit(fetch_single_source, url): url for url in url_list}
        for future in as_completed(future_tasks):
            url = future_tasks[future]
            content = future.result()
            if content:
                combined_content.append(content)
            else:
                print(f"â­ï¸  è·³è¿‡æ— æ•ˆURLï¼š{url}")
            print("-" * 70)

    success_count = len(combined_content)
    print(f"\nğŸ“Š æŠ“å–ç»Ÿè®¡ | æˆåŠŸï¼š{success_count} ä¸ª | å¤±è´¥ï¼š{total - success_count} ä¸ª")
    return "\n".join(combined_content)


def parse_m3u(content: str) -> list[dict]:
    """è§£æM3Uæ ¼å¼ç›´æ’­æºï¼Œæå–é¢‘é“åå’Œæ’­æ”¾åœ°å€"""
    if not content.strip():
        print("M3Uå†…å®¹ä¸ºç©º")
        return []

    streams = []
    current_program = None
    line_count = 0

    for line in content.splitlines():
        line_count += 1
        line = line.strip()
        # è§£æé¢‘é“åï¼ˆä¼˜å…ˆtvg-nameï¼Œå…¶æ¬¡ä»æè¿°æå–ï¼‰
        if line.startswith("#EXTINF"):
            tvg_match = re.search(r'tvg-name=(["\']?)([^"\']+)\1', line)
            if tvg_match:
                current_program = clean_text(tvg_match.group(2))
            else:
                desc_match = re.search(r',([^,]+)$', line)
                if desc_match:
                    current_program = clean_text(desc_match.group(1))
            continue
        # è§£ææ’­æ”¾åœ°å€ï¼ˆURLè¡Œï¼‰
        if URL_PATTERN.match(line) and current_program:
            streams.append({"program_name": current_program, "stream_url": line})
            current_program = None  # é‡ç½®ï¼Œé¿å…é‡å¤åŒ¹é…

    print(f"ğŸ“Š M3Uè§£æ | æ€»è¡Œæ•°ï¼š{line_count:,} | æå–æºï¼š{len(streams)} ä¸ª")
    return streams


def parse_txt(content: str) -> list[dict]:
    """è§£æTXTæ ¼å¼ç›´æ’­æºï¼ˆé¢‘é“å,URL æ ¼å¼ï¼‰"""
    if not content.strip():
        print("TXTå†…å®¹ä¸ºç©º")
        return []

    streams = []
    line_count = 0
    valid_count = 0

    for line in content.splitlines():
        line_count += 1
        line = line.strip()
        # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
        if not line or line.startswith("#"):
            continue
        # å…¼å®¹ç©ºæ ¼åˆ†éš”ï¼Œç»Ÿä¸€è½¬ä¸ºé€—å·åˆ†éš”
        line = line.replace(" ", ",")
        parts = [p.strip() for p in line.split(",") if p.strip()]
        # éœ€åŒ…å«é¢‘é“åå’ŒURLï¼ˆè‡³å°‘2ä¸ªéƒ¨åˆ†ï¼Œä¸”æœ€åä¸€ä¸ªæ˜¯URLï¼‰
        if len(parts) >= 2 and URL_PATTERN.match(parts[-1]):
            program_name = clean_text(",".join(parts[:-1]))  # æ”¯æŒå«é€—å·çš„é¢‘é“å
            stream_url = parts[-1]
            streams.append({"program_name": program_name, "stream_url": stream_url})
            valid_count += 1
        else:
            print(f"ç¬¬{line_count}è¡Œï¼šæ ¼å¼æ— æ•ˆï¼ˆéœ€ä¸ºã€Œé¢‘é“å,URLã€ï¼‰ï¼Œå¿½ç•¥")

    print(f"ğŸ“Š TXTè§£æ | æ€»è¡Œæ•°ï¼š{line_count:,} | æœ‰æ•ˆè¡Œï¼š{valid_count} | æå–æºï¼š{len(streams)} ä¸ª")
    return streams


def test_stream_latency(stream_url: str, timeout: int) -> int | None:
    """æµ‹è¯•ç›´æ’­æºå»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ï¼Œä¼˜å…ˆHEADè¯·æ±‚ï¼Œå¤±è´¥é™çº§ä¸ºGET"""
    start_time = time.time()
    try:
        for method in [requests.head, requests.get]:
            with method(
                stream_url,
                timeout=timeout,
                allow_redirects=True,
                stream=(method == requests.get)
            ) as resp:
                if resp.status_code in [200, 206]:
                    if method == requests.get:
                        resp.iter_content(1).__next__()  # è¯»1å­—èŠ‚éªŒè¯å¯ç”¨æ€§
                    return int((time.time() - start_time) * 1000)
    except requests.exceptions.Timeout:
        print(f"âš ï¸ æµ‹é€Ÿè¶…æ—¶ï¼š{stream_url[:50]}{'...' if len(stream_url) > 50 else ''}")
    except requests.exceptions.ConnectionError:
        print(f"âš ï¸ æµ‹é€Ÿå¤±è´¥ï¼š{stream_url[:50]}{'...' if len(stream_url) > 50 else ''}ï¼ˆç½‘ç»œä¸å¯è¾¾ï¼‰")
    except Exception as e:
        print(f"âš ï¸ æµ‹é€Ÿé”™è¯¯ï¼š{stream_url[:50]}{'...' if len(stream_url) > 50 else ''}ï¼ˆ{str(e)[:30]}ï¼‰")
    return None


def batch_test_latency(stream_df: pd.DataFrame, max_workers: int, timeout: int) -> pd.DataFrame:
    """æ‰¹é‡æµ‹è¯•ç›´æ’­æºå»¶è¿Ÿï¼Œè¿”å›æŒ‰å»¶è¿Ÿæ’åºçš„æœ‰æ•ˆæºDataFrame"""
    if stream_df.empty:
        print("æ— ç›´æ’­æºå¯æµ‹è¯•å»¶è¿Ÿ")
        return pd.DataFrame(columns=["program_name", "stream_url", "latency_ms"])

    total_stream = len(stream_df)
    valid_results = []
    print(f"âš¡ æ‰¹é‡æµ‹é€Ÿ | æ€»æµæ•°ï¼š{total_stream} | å¹¶å‘æ•°ï¼š{max_workers} | è¶…æ—¶ï¼š{timeout}ç§’")
    print("-" * 100)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_tasks = {
            executor.submit(test_stream_latency, row["stream_url"], timeout): (row["program_name"], row["stream_url"])
            for _, row in stream_df.iterrows()
        }

        for task_idx, future in enumerate(as_completed(future_tasks), 1):
            prog_name, stream_url = future_tasks[future]
            latency = future.result()
            display_url = stream_url[:70] + "..." if len(stream_url) > 70 else stream_url

            if latency is not None:
                valid_results.append({
                    "program_name": prog_name,
                    "stream_url": stream_url,
                    "latency_ms": latency
                })
                print(f"âœ… [{task_idx:3d}/{total_stream}] é¢‘é“ï¼š{prog_name:<20} URLï¼š{display_url:<75} å»¶è¿Ÿï¼š{latency:4d}ms")
            else:
                print(f"âŒ [{task_idx:3d}/{total_stream}] é¢‘é“ï¼š{prog_name:<20} URLï¼š{display_url:<75} çŠ¶æ€ï¼šæ— æ•ˆ")

    # è½¬æ¢ä¸ºDataFrameå¹¶æŒ‰å»¶è¿Ÿå‡åºæ’åº
    latency_df = pd.DataFrame(valid_results)
    if not latency_df.empty:
        latency_df = latency_df.sort_values("latency_ms").reset_index(drop=True)

    # è¾“å‡ºæµ‹é€Ÿç»Ÿè®¡
    print("-" * 100)
    print(f"ğŸ æµ‹é€Ÿå®Œæˆ | æœ‰æ•ˆæµï¼š{len(latency_df)} ä¸ª | æ— æ•ˆæµï¼š{total_stream - len(latency_df)} ä¸ª")
    if len(latency_df) > 0:
        avg_latency = int(latency_df["latency_ms"].mean())
        print(f"ğŸ“Š å»¶è¿Ÿç»Ÿè®¡ | æœ€å¿«ï¼š{latency_df['latency_ms'].min()}ms | æœ€æ…¢ï¼š{latency_df['latency_ms'].max()}ms | å¹³å‡ï¼š{avg_latency}ms")
    return latency_df


def organize_streams(content: str, categories: list[dict], all_channels: list) -> list[dict]:
    """æŒ‰åˆ†ç±»æ¨¡æ¿æ•´ç†ç›´æ’­æºï¼Œè¿”å›åˆ†ç±»åçš„ç»“æ„ï¼ˆå«å‰Nä¸ªä½å»¶è¿Ÿæºï¼‰"""
    print("\nğŸ”§ å¼€å§‹æ•´ç†ç›´æ’­æºï¼ˆ4ä¸ªæ­¥éª¤ï¼‰")
    print("-" * 70)

    # æ­¥éª¤1ï¼šè‡ªåŠ¨è¯†åˆ«æ ¼å¼å¹¶è§£ææºæ•°æ®
    if content.startswith("#EXTM3U") or "#EXTINF" in content[:100]:
        print("ğŸ”§ æ­¥éª¤1/4ï¼šè¯†åˆ«ä¸ºM3Uæ ¼å¼ï¼Œå¼€å§‹è§£æ...")
        parsed_streams = parse_m3u(content)
    else:
        print("ğŸ”§ æ­¥éª¤1/4ï¼šè¯†åˆ«ä¸ºTXTæ ¼å¼ï¼Œå¼€å§‹è§£æ...")
        parsed_streams = parse_txt(content)

    stream_df = pd.DataFrame(parsed_streams)
    if stream_df.empty:
        print("æ•´ç†å¤±è´¥ï¼šè§£æåæ— æœ‰æ•ˆç›´æ’­æµ")
        return []

    # æ­¥éª¤2ï¼šæŒ‰æ¨¡æ¿è¿‡æ»¤é¢‘é“ï¼ˆåªä¿ç•™æ¨¡æ¿ä¸­å­˜åœ¨çš„é¢‘é“ï¼‰
    print(f"\nğŸ”§ æ­¥éª¤2/4ï¼šæŒ‰æ¨¡æ¿è¿‡æ»¤é¢‘é“...")
    if "program_name" not in stream_df.columns:
        print("æ•´ç†å¤±è´¥ï¼šè§£æç»“æœä¸­æ— program_nameå­—æ®µ")
        return []
    stream_df["program_clean"] = stream_df["program_name"].apply(clean_text)
    template_clean = [clean_text(ch) for ch in all_channels]

    # æ¨¡ç³ŠåŒ¹é…ï¼ˆå…¼å®¹é¢‘é“åç»†å¾®å·®å¼‚ï¼Œå¦‚"CCTV1"å’Œ"CCTV-1"ï¼‰
    def fuzzy_match(clean_name):
        return any(tpl in clean_name or clean_name in tpl for tpl in template_clean)

    filtered_df = stream_df[stream_df["program_clean"].apply(fuzzy_match)].copy()
    filtered_df = filtered_df.drop_duplicates(subset=["program_name", "stream_url"]).reset_index(drop=True)

    if filtered_df.empty:
        print("æ•´ç†å¤±è´¥ï¼šæ— åŒ¹é…æ¨¡æ¿çš„é¢‘é“")
        return []
    print(f"  ç»“æœ | åŸå§‹...")
