#!/usr/bin/env python3
"""
IPTVæ™ºèƒ½ç®¡ç†å·¥å…· - ä¼˜åŒ–æµ‹é€Ÿç‰ˆ
åŠŸèƒ½ï¼šæ™ºèƒ½å¤šæºæŠ“å–ã€æ™ºèƒ½æµ‹é€Ÿï¼ˆå…³é—­FFmpegï¼‰ã€æ’­æ”¾åˆ—è¡¨ç”Ÿæˆ
ç‰ˆæœ¬ï¼šv3.2 (ä¼˜åŒ–æµ‹é€Ÿç‰ˆ)
"""

import requests
import pandas as pd
import re
import os
import time
import subprocess
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
import logging
from typing import List, Dict, Any, Optional, Tuple, Union
from pathlib import Path
import shutil

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('IPTVManager')

class Config:
    """é…ç½®ç±» - ä¼˜åŒ–æµ‹é€Ÿç‰ˆ"""
    
    # ==================== æ–‡ä»¶é…ç½®ï¼ˆæ ¹ç›®å½•ï¼‰ ====================
    TEMPLATE_FILE: str = "demo.txt"              # æ¨¡æ¿æ–‡ä»¶ï¼ˆæ ¹ç›®å½•ï¼‰
    OUTPUT_TXT: str = "iptv.txt"                 # è¾“å‡ºTXTæ–‡ä»¶ï¼ˆæ ¹ç›®å½•ï¼‰
    OUTPUT_M3U: str = "iptv.m3u"                 # è¾“å‡ºM3Uæ–‡ä»¶ï¼ˆæ ¹ç›®å½•ï¼‰
    TEMP_DIR: str = "temp"                       # ä¸´æ—¶æ–‡ä»¶ç›®å½•
    
    # ==================== ç½‘ç»œé…ç½® ====================
    REQUEST_TIMEOUT: int = 20                    # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
    REQUEST_RETRIES: int = 3                     # è¯·æ±‚é‡è¯•æ¬¡æ•°
    MAX_WORKERS: int = 5                         # æœ€å¤§å¹¶å‘æ•°
    
    # ==================== æµ‹é€Ÿé…ç½® ====================
    SPEED_TEST_TIMEOUT: int = 8                  # HTTPæµ‹é€Ÿè¶…æ—¶æ—¶é—´(ç§’)
    FFMPEG_TEST_DURATION: int = 5                # FFmpegæµ‹è¯•æ—¶é•¿(ç§’)
    FFMPEG_PROCESS_TIMEOUT: int = 12             # FFmpegè¿›ç¨‹è¶…æ—¶(ç§’)
    
    # ==================== åŒ¹é…é…ç½® ====================
    SIMILARITY_THRESHOLD: int = 60               # ç›¸ä¼¼åº¦é˜ˆå€¼(0-100)
    MAX_SOURCES_PER_CHANNEL: int = 8             # æ¯ä¸ªé¢‘é“æœ€å¤§æºæ•°é‡
    
    # ==================== æ™ºèƒ½æºURLé…ç½® ====================
    SOURCE_URLS: List[str] = [
        # å›½å†…ç¨³å®šæºï¼ˆä¼˜å…ˆï¼‰
            "https://raw.githubusercontent.com/zwc456baby/iptv_alive/master/live.txt",
            "https://raw.githubusercontent.com/iptv-org/iptv/gh-pages/countries/cn.m3u",
            "https://ghfast.top/raw.githubusercontent.com/Supprise0901/TVBox_live/main/live.txt",
            "https://gh-proxy.com/https://raw.githubusercontent.com/wwb521/live/main/tv.m3u",
            "https://gh-proxy.com/https://raw.githubusercontent.com/zeee-u/lzh06/main/fl.m3u",
            "https://raw.githubusercontent.com/Guovin/iptv-database/master/result.txt",  
            "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
            "https://raw.githubusercontent.com/suxuang/myIPTV/main/ipv4.m3u",
            "https://raw.githubusercontent.com/vbskycn/iptv/master/tv/iptv4.txt",
            "http://47.120.41.246:8899/zb.txt",
            "https://live.zbds.top/tv/iptv4.txt",
    ]
    
    # ==================== è¯·æ±‚å¤´é…ç½® ====================
    HEADERS: Dict[str, str] = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': '*/*',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Cache-Control': 'no-cache'
    }
    
    # ==================== æµç±»å‹é…ç½® ====================
    STREAM_TYPES: Dict[str, str] = {
        'm3u8': '.m3u8',
        'ts': '.ts',
        'flv': '.flv',
        'mp4': '.mp4',
        'rtmp': 'rtmp://',
        'rtsp': 'rtsp://'
    }
    
    # ==================== æµ‹é€Ÿæ¨¡å¼é…ç½® ====================
    USE_FFMPEG_TEST: bool = False  # å…³é—­FFmpegæµ‹é€Ÿï¼Œä½¿ç”¨æ™ºèƒ½HTTPæµ‹é€Ÿ


class IPTVManager:
    """IPTVæ™ºèƒ½ç®¡ç†å·¥å…·æ ¸å¿ƒç±» - ä¼˜åŒ–æµ‹é€Ÿç‰ˆ"""
    
    def __init__(self, config: Config = None) -> None:
        """åˆå§‹åŒ–IPTVç®¡ç†å™¨"""
        self.config: Config = config or Config()
        
        # åˆå§‹åŒ–ä¼šè¯
        self.session: requests.Session = requests.Session()
        self.session.headers.update(self.config.HEADERS)
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self.patterns: Dict[str, re.Pattern] = {}
        self._compile_patterns()
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self._setup_directories()
        
        # æ£€æŸ¥FFmpegï¼ˆä»…ç”¨äºä¿¡æ¯æ˜¾ç¤ºï¼‰
        self.ffmpeg_available: bool = self._check_ffmpeg()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats: Dict[str, int] = {
            'sources_fetched': 0,
            'streams_parsed': 0,
            'channels_matched': 0,
            'sources_tested': 0,
            'sources_available': 0
        }
        
        # é¢‘é“æµ‹é€Ÿç»“æœå­˜å‚¨
        self.channel_speed_results: Dict[str, List[Dict]] = {}
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        self._print_config()

    def _print_config(self) -> None:
        """æ‰“å°é…ç½®ä¿¡æ¯"""
        logger.info("=" * 50)
        logger.info("ğŸ› ï¸ IPTVç®¡ç†å™¨é…ç½®ä¿¡æ¯")
        logger.info("=" * 50)
        logger.info(f"ğŸ“ æ¨¡æ¿æ–‡ä»¶: {self.config.TEMPLATE_FILE}")
        logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {self.config.OUTPUT_TXT}, {self.config.OUTPUT_M3U}")
        logger.info(f"ğŸŒ æºæ•°é‡: {len(self.config.SOURCE_URLS)}")
        logger.info(f"âš¡ å¹¶å‘æ•°: {self.config.MAX_WORKERS}")
        logger.info(f"â±ï¸  æµ‹é€Ÿè¶…æ—¶: {self.config.SPEED_TEST_TIMEOUT}ç§’")
        logger.info(f"ğŸ¯ ç›¸ä¼¼åº¦é˜ˆå€¼: {self.config.SIMILARITY_THRESHOLD}")
        logger.info(f"ğŸ“º æ¯é¢‘é“æœ€å¤§æº: {self.config.MAX_SOURCES_PER_CHANNEL}")
        logger.info(f"ğŸ”§ FFmpegæµ‹é€Ÿ: {'å¼€å¯' if self.config.USE_FFMPEG_TEST else 'å…³é—­'}")
        logger.info("=" * 50)

    def _setup_directories(self) -> None:
        """è®¾ç½®å¿…è¦çš„ç›®å½•"""
        try:
            temp_path: Path = Path(self.config.TEMP_DIR)
            temp_path.mkdir(exist_ok=True)
            logger.info("âœ… ç›®å½•åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ ç›®å½•è®¾ç½®å¤±è´¥: {e}")
            raise

    def _compile_patterns(self) -> None:
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        try:
            self.patterns = {
                'extinf': re.compile(r'#EXTINF:.*?tvg-name="([^"]+)".*?,(.+)', re.IGNORECASE),
                'category': re.compile(r'^(.*?),#genre#$', re.IGNORECASE),
                'url': re.compile(r'https?://[^\s,]+', re.IGNORECASE),
                'tvg_name': re.compile(r'tvg-name="([^"]*)"', re.IGNORECASE),
                'tvg_id': re.compile(r'tvg-id="([^"]*)"', re.IGNORECASE),
                'group_title': re.compile(r'group-title="([^"]*)"', re.IGNORECASE),
                'extinf_content': re.compile(r',\s*(.+)$', re.IGNORECASE),
                'channel_code': re.compile(r'([A-Z]+)-?(\d+)', re.IGNORECASE),
                'quality_suffix': re.compile(r'\s+(HD|FHD|4K|8K|é«˜æ¸…|è¶…æ¸…|ç›´æ’­|LIVE|é¢‘é“|TV)', re.IGNORECASE),
                'brackets': re.compile(r'[\[\(\{].*?[\]\)\}]')
            }
            logger.debug("âœ… æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘å¤±è´¥: {e}")
            raise

    def _check_ffmpeg(self) -> bool:
        """æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨ï¼ˆä»…ç”¨äºä¿¡æ¯æ˜¾ç¤ºï¼‰"""
        if not self.config.USE_FFMPEG_TEST:
            return False
            
        try:
            result = subprocess.run(
                ['ffmpeg', '-version'], 
                capture_output=True, 
                timeout=5,
                check=False
            )
            available: bool = result.returncode == 0
            if available:
                logger.info("âœ… FFmpegå¯ç”¨ - å°†ä½¿ç”¨æ™ºèƒ½æµåª’ä½“æµ‹è¯•")
            else:
                logger.warning("âš ï¸ FFmpegæœªå®‰è£…æˆ–ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨HTTPæµ‹é€Ÿ")
            return available
        except Exception as e:
            logger.warning(f"âš ï¸ FFmpegæ£€æŸ¥å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨HTTPæµ‹é€Ÿ")
            return False

    def validate_url(self, url: str) -> bool:
        """éªŒè¯URLæ ¼å¼æ˜¯å¦æ­£ç¡®"""
        if not url or not isinstance(url, str):
            return False
            
        try:
            result = urlparse(url)
            valid_scheme: bool = result.scheme in ['http', 'https', 'rtmp', 'rtsp']
            valid_netloc: bool = bool(result.netloc)
            return all([valid_scheme, valid_netloc])
        except Exception:
            return False

    def fetch_streams_from_url(self, url: str) -> Optional[str]:
        """ä»URLè·å–æµæ•°æ®"""
        if not self.validate_url(url):
            logger.error(f"âŒ æ— æ•ˆçš„URL: {url}")
            return None
            
        logger.info(f"ğŸ“¡ æ­£åœ¨è·å–: {url}")
        
        for attempt in range(self.config.REQUEST_RETRIES):
            try:
                timeout: int = self.config.REQUEST_TIMEOUT + (attempt * 5)
                
                response: requests.Response = self.session.get(
                    url, 
                    timeout=timeout,
                    headers=self.config.HEADERS,
                    stream=True
                )
                response.encoding = 'utf-8'
                
                if response.status_code == 200:
                    content: str = response.text
                    content_length: int = len(content)
                    
                    if content_length < 10:
                        logger.warning(f"âš ï¸ å†…å®¹è¿‡çŸ­: {url} ({content_length} å­—ç¬¦)")
                        continue
                        
                    self.stats['sources_fetched'] += 1
                    logger.info(f"âœ… æˆåŠŸè·å–: {url} ({content_length} å­—ç¬¦)")
                    return content
                    
                elif response.status_code == 429:
                    wait_time: int = (attempt + 1) * 10
                    logger.warning(f"âš ï¸ è¯·æ±‚é¢‘ç¹ï¼Œç­‰å¾… {wait_time} ç§’")
                    time.sleep(wait_time)
                    continue
                    
                elif response.status_code == 403:
                    logger.warning(f"âš ï¸ è®¿é—®è¢«æ‹’ç»: {url}")
                    break
                    
                else:
                    logger.warning(f"âš ï¸ è·å–å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    
            except requests.exceptions.Timeout:
                logger.warning(f"âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{self.config.REQUEST_RETRIES}")
            except requests.exceptions.ConnectionError:
                logger.warning(f"âš ï¸ è¿æ¥é”™è¯¯ï¼Œå°è¯• {attempt + 1}/{self.config.REQUEST_RETRIES}")
            except requests.exceptions.TooManyRedirects:
                logger.warning(f"âš ï¸ é‡å®šå‘è¿‡å¤š: {url}")
                break
            except Exception as e:
                logger.warning(f"âš ï¸ è¯·æ±‚å¼‚å¸¸: {e}")
                
            if attempt < self.config.REQUEST_RETRIES - 1:
                wait_time = (attempt + 1) * 3
                time.sleep(wait_time)
        
        logger.error(f"âŒ æ‰€æœ‰é‡è¯•å¤±è´¥: {url}")
        return None

    def fetch_all_streams(self) -> str:
        """è·å–æ‰€æœ‰æºçš„æµæ•°æ®"""
        logger.info("ğŸš€ å¼€å§‹æ™ºèƒ½å¤šæºæŠ“å–...")
        
        if not self.config.SOURCE_URLS:
            logger.error("âŒ æ²¡æœ‰é…ç½®æºURL")
            return ""
        
        all_streams: List[str] = []
        successful_sources: int = 0
        
        print("ğŸŒ æŠ“å–è¿›åº¦: ", end="", flush=True)
        
        with ThreadPoolExecutor(max_workers=min(self.config.MAX_WORKERS, len(self.config.SOURCE_URLS))) as executor:
            future_to_url = {executor.submit(self.fetch_streams_from_url, url): url for url in self.config.SOURCE_URLS}
            
            for future in as_completed(future_to_url):
                url: str = future_to_url[future]
                try:
                    content: Optional[str] = future.result(timeout=self.config.REQUEST_TIMEOUT + 10)
                    if content:
                        all_streams.append(content)
                        successful_sources += 1
                        print("âœ…", end="", flush=True)
                    else:
                        print("âŒ", end="", flush=True)
                except Exception as e:
                    logger.error(f"å¤„ç† {url} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    print("ğŸ’¥", end="", flush=True)
        
        print()  # æ¢è¡Œ
        logger.info(f"âœ… æˆåŠŸè·å– {successful_sources}/{len(self.config.SOURCE_URLS)} ä¸ªæºçš„æ•°æ®")
        
        return "\n".join(all_streams) if all_streams else ""

    def _extract_program_name(self, extinf_line: str) -> str:
        """ä»EXTINFè¡Œæå–èŠ‚ç›®åç§°"""
        if not extinf_line.startswith('#EXTINF'):
            return "æœªçŸ¥é¢‘é“"
        
        try:
            # ä»tvg-nameå±æ€§æå–
            tvg_match = self.patterns['tvg_name'].search(extinf_line)
            if tvg_match and tvg_match.group(1).strip():
                name: str = tvg_match.group(1).strip()
                if name and name != "æœªçŸ¥é¢‘é“":
                    return name
            
            # ä»é€—å·åçš„å†…å®¹æå–
            content_match = self.patterns['extinf_content'].search(extinf_line)
            if content_match and content_match.group(1).strip():
                name = content_match.group(1).strip()
                # æ¸…ç†åç§°
                name = self.patterns['brackets'].sub('', name)
                name = self.patterns['quality_suffix'].sub('', name)
                name = name.strip()
                if name and name != "æœªçŸ¥é¢‘é“":
                    return name
                        
        except Exception as e:
            logger.debug(f"EXTINFè§£æé”™è¯¯: {extinf_line} - {e}")
        
        return "æœªçŸ¥é¢‘é“"

    def parse_m3u(self, content: str) -> List[Dict[str, str]]:
        """è§£æM3Uæ ¼å¼å†…å®¹"""
        if not content:
            return []
            
        streams: List[Dict[str, str]] = []
        lines: List[str] = content.splitlines()
        current_program: Optional[str] = None
        current_group: str = "é»˜è®¤åˆ†ç»„"
        
        i: int = 0
        while i < len(lines):
            line: str = lines[i].strip()
            
            if not line:
                i += 1
                continue
                
            if line.startswith("#EXTINF"):
                current_program = self._extract_program_name(line)
                
                group_match = self.patterns['group_title'].search(line)
                if group_match:
                    current_group = group_match.group(1).strip() or "é»˜è®¤åˆ†ç»„"
                else:
                    current_group = "é»˜è®¤åˆ†ç»„"
                    
                # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªURLè¡Œ
                j: int = i + 1
                while j < len(lines):
                    next_line: str = lines[j].strip()
                    if next_line and not next_line.startswith('#'):
                        if self.validate_url(next_line):
                            streams.append({
                                "program_name": current_program,
                                "stream_url": next_line,
                                "group": current_group
                            })
                        i = j  # è·³è¿‡URLè¡Œ
                        break
                    j += 1
            elif line.startswith(('http://', 'https://', 'rtmp://', 'rtsp://')):
                if self.validate_url(line):
                    streams.append({
                        "program_name": "æœªçŸ¥é¢‘é“",
                        "stream_url": line,
                        "group": "é»˜è®¤åˆ†ç»„"
                    })
            
            i += 1
        
        return streams

    def parse_txt(self, content: str) -> List[Dict[str, str]]:
        """è§£æTXTæ ¼å¼å†…å®¹"""
        if not content:
            return []
            
        streams: List[Dict[str, str]] = []
        
        for line in content.splitlines():
            line = line.strip()
            if not line or line.startswith('#') or '#genre#' in line:
                continue
            
            # æ”¯æŒå¤šç§åˆ†éš”ç¬¦
            separators = [',', ' ', '\t', '|']
            for sep in separators:
                if sep in line:
                    parts: List[str] = line.split(sep, 1)
                    if len(parts) == 2:
                        program_name: str = parts[0].strip()
                        url_part: str = parts[1].strip()
                        
                        url_match = self.patterns['url'].search(url_part)
                        if url_match:
                            stream_url: str = url_match.group()
                            if self.validate_url(stream_url):
                                streams.append({
                                    "program_name": program_name,
                                    "stream_url": stream_url,
                                    "group": "é»˜è®¤åˆ†ç»„"
                                })
                                break
                    break
            else:
                # æ²¡æœ‰åˆ†éš”ç¬¦ï¼Œå°è¯•ç›´æ¥æå–URL
                url_match = self.patterns['url'].search(line)
                if url_match:
                    stream_url = url_match.group()
                    program_name = line.replace(stream_url, '').strip()
                    if not program_name:
                        program_name = "æœªçŸ¥é¢‘é“"
                    
                    if self.validate_url(stream_url):
                        streams.append({
                            "program_name": program_name,
                            "stream_url": stream_url,
                            "group": "é»˜è®¤åˆ†ç»„"
                        })
        
        return streams

    def organize_streams(self, content: str) -> pd.DataFrame:
        """æ•´ç†æµæ•°æ®"""
        if not content:
            logger.error("âŒ æ²¡æœ‰å†…å®¹å¯å¤„ç†")
            return pd.DataFrame()
            
        logger.info("ğŸ” è§£ææµæ•°æ®...")
        
        try:
            # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
            if content.startswith("#EXTM3U"):
                streams: List[Dict[str, str]] = self.parse_m3u(content)
            else:
                streams = self.parse_txt(content)
            
            if not streams:
                logger.error("âŒ æœªèƒ½è§£æå‡ºä»»ä½•æµæ•°æ®")
                return pd.DataFrame()
                
            df: pd.DataFrame = pd.DataFrame(streams)
            self.stats['streams_parsed'] = len(df)
            
            # æ•°æ®æ¸…ç†
            initial_count: int = len(df)
            
            # ç§»é™¤ç©ºå€¼å’Œæ— æ•ˆæ•°æ®
            df = df.dropna()
            df = df[df['program_name'].str.len() > 0]
            df = df[df['stream_url'].str.len() > 0]
            
            # éªŒè¯URL
            df['url_valid'] = df['stream_url'].apply(self.validate_url)
            df = df[df['url_valid']].drop('url_valid', axis=1)
            
            # å»é‡
            df = df.drop_duplicates(subset=['program_name', 'stream_url'], keep='first')
            
            final_count: int = len(df)
            removed_count: int = initial_count - final_count
            
            logger.info(f"ğŸ“Š æ•°æ®æ¸…ç†å®Œæˆ: {initial_count} -> {final_count} ä¸ªæµ (ç§»é™¤ {removed_count} ä¸ªæ— æ•ˆæ•°æ®)")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®å¤„ç†é”™è¯¯: {e}")
            return pd.DataFrame()

    def load_template(self) -> Optional[Dict[str, List[str]]]:
        """åŠ è½½é¢‘é“æ¨¡æ¿æ–‡ä»¶"""
        template_file: Path = Path(self.config.TEMPLATE_FILE)
        
        if not template_file.exists():
            logger.error(f"âŒ æ¨¡æ¿æ–‡ä»¶ {template_file} ä¸å­˜åœ¨")
            return None
            
        logger.info(f"ğŸ“‹ åŠ è½½æ¨¡æ¿æ–‡ä»¶: {template_file}")
        categories: Dict[str, List[str]] = {}
        current_category: Optional[str] = None
        
        try:
            with open(template_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                        
                    category_match = self.patterns['category'].match(line)
                    if category_match:
                        current_category = category_match.group(1).strip()
                        categories[current_category] = []
                    
                    elif current_category and line and not line.startswith('#'):
                        channel_name: str = line.split(',')[0].strip() if ',' in line else line.strip()
                        if channel_name:
                            categories[current_category].append(channel_name)
        
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return None
        
        if not categories:
            logger.error("âŒ æ¨¡æ¿æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„é¢‘é“åˆ†ç±»")
            return None
            
        total_channels: int = sum(len(channels) for channels in categories.values())
        logger.info(f"ğŸ“ æ¨¡æ¿åˆ†ç±»: {list(categories.keys())}")
        logger.info(f"ğŸ“º æ¨¡æ¿é¢‘é“æ€»æ•°: {total_channels}")
        
        return categories

    def clean_channel_name(self, name: str) -> str:
        """é¢‘é“åç§°æ¸…ç†"""
        if not name:
            return ""
        
        try:
            cleaned: str = name.lower()
            
            # ç§»é™¤è´¨é‡æ ‡è¯†
            cleaned = self.patterns['quality_suffix'].sub(' ', cleaned)
            
            # ç§»é™¤æ‹¬å·å†…å®¹
            cleaned = self.patterns['brackets'].sub('', cleaned)
            
            # æ ‡å‡†åŒ–é¢‘é“ä»£ç 
            code_match = self.patterns['channel_code'].search(cleaned)
            if code_match:
                prefix: str = code_match.group(1).upper()
                number: str = code_match.group(2)
                cleaned = f"{prefix} {number}"
            
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼
            cleaned = re.sub(r'[^\w\u4e00-\u9fa5\s-]', ' ', cleaned)
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            
            return cleaned
            
        except Exception as e:
            logger.debug(f"é¢‘é“åç§°æ¸…ç†é”™è¯¯: {name} - {e}")
            return name.lower() if name else ""

    def similarity_score(self, str1: str, str2: str) -> int:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-100ï¼‰"""
        if not str1 or not str2:
            return 0
            
        try:
            clean_str1: str = self.clean_channel_name(str1)
            clean_str2: str = self.clean_channel_name(str2)
            
            if not clean_str1 or not clean_str2:
                return 0
            
            # å®Œå…¨åŒ¹é…
            if clean_str1 == clean_str2:
                return 100
            
            # åŒ…å«å…³ç³»ï¼ˆåŒå‘ï¼‰
            if clean_str1 in clean_str2:
                return 90
            if clean_str2 in clean_str1:
                return 85
            
            # ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦
            def edit_distance_similarity(s1: str, s2: str) -> float:
                if len(s1) > len(s2):
                    s1, s2 = s2, s1
                distances = range(len(s1) + 1)
                for i2, c2 in enumerate(s2):
                    distances_ = [i2 + 1]
                    for i1, c1 in enumerate(s1):
                        if c1 == c2:
                            distances_.append(distances[i1])
                        else:
                            distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))
                    distances = distances_
                max_len = max(len(s1), len(s2))
                if max_len == 0:
                    return 100.0
                return (1 - distances[-1] / max_len) * 100
            
            edit_score: float = edit_distance_similarity(clean_str1, clean_str2)
            
            # Jaccardç›¸ä¼¼åº¦
            set1 = set(clean_str1)
            set2 = set(clean_str2)
            
            intersection = len(set1 & set2)
            union = len(set1 | set2)
            
            jaccard_similarity: float = (intersection / union) * 100 if union > 0 else 0
            
            # ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
            final_score: float = (edit_score * 0.6 + jaccard_similarity * 0.4)
            
            return int(final_score)
                
        except Exception as e:
            logger.debug(f"ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {str1}, {str2} - {e}")
        
        return 0

    def filter_and_sort_sources(self, sources_df: pd.DataFrame, template_channels: List[str]) -> pd.DataFrame:
        """é¢‘é“åŒ¹é…å’Œæºç­›é€‰"""
        logger.info("ğŸ¯ å¼€å§‹æ™ºèƒ½é¢‘é“åŒ¹é…...")
        
        if sources_df.empty or not template_channels:
            logger.error("âŒ æºæ•°æ®æˆ–æ¨¡æ¿é¢‘é“ä¸ºç©º")
            return pd.DataFrame()
        
        matched_results: List[Dict[str, Any]] = []
        match_stats: Dict[str, int] = {'exact': 0, 'good': 0, 'fair': 0}
        
        print("ğŸ” åŒ¹é…è¿›åº¦: ", end="", flush=True)
        
        for template_channel in template_channels:
            best_match_row = None
            best_score: int = 0
            best_original_name: str = ""
            
            for _, source_row in sources_df.iterrows():
                source_channel: str = source_row['program_name']
                score: int = self.similarity_score(template_channel, source_channel)
                
                if score > best_score and score >= self.config.SIMILARITY_THRESHOLD:
                    best_score = score
                    best_match_row = source_row.copy()
                    best_original_name = source_channel
            
            if best_match_row is not None:
                best_match_row['template_channel'] = template_channel
                best_match_row['match_score'] = best_score
                best_match_row['original_name'] = best_original_name
                
                matched_results.append(best_match_row)
                
                # ç»Ÿè®¡åŒ¹é…è´¨é‡
                if best_score >= 90:
                    match_stats['exact'] += 1
                    print("ğŸ¯", end="", flush=True)
                elif best_score >= 70:
                    match_stats['good'] += 1
                    print("âœ…", end="", flush=True)
                else:
                    match_stats['fair'] += 1
                    print("ğŸ‘", end="", flush=True)
            else:
                print("âŒ", end="", flush=True)
        
        print()  # æ¢è¡Œ
        
        if matched_results:
            result_df: pd.DataFrame = pd.DataFrame(matched_results)
            result_df = result_df.rename(columns={'program_name': 'original_name'})
            result_df = result_df.rename(columns={'template_channel': 'program_name'})
            
            # æŒ‰åŒ¹é…åˆ†æ•°æ’åº
            result_df = result_df.sort_values(['program_name', 'match_score'], ascending=[True, False])
            
            unique_matched_channels: int = result_df['program_name'].nunique()
            self.stats['channels_matched'] = unique_matched_channels
            
            logger.info(f"âœ… é¢‘é“åŒ¹é…å®Œæˆ: {len(matched_results)} ä¸ªæµåŒ¹é…åˆ° {unique_matched_channels} ä¸ªæ¨¡æ¿é¢‘é“")
            logger.info(f"ğŸ“Š åŒ¹é…è´¨é‡: ç²¾ç¡®{match_stats['exact']} è‰¯å¥½{match_stats['good']} ä¸€èˆ¬{match_stats['fair']}")
            
            return result_df
        else:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…çš„é¢‘é“")
            return pd.DataFrame()

    def speed_test_simple(self, stream_url: str) -> Tuple[bool, float]:
        """æ™ºèƒ½HTTPæµ‹é€Ÿ"""
        if not stream_url:
            return False, float('inf')
            
        try:
            start_time: float = time.time()
            response: requests.Response = self.session.head(
                stream_url, 
                timeout=self.config.SPEED_TEST_TIMEOUT,
                allow_redirects=True,
                headers={
                    **self.config.HEADERS,
                    'Range': 'bytes=0-1'
                }
            )
            end_time: float = time.time()
            
            if response.status_code in [200, 206, 302, 301, 307]:
                content_type: str = response.headers.get('Content-Type', '').lower()
                content_length: str = response.headers.get('Content-Length', '')
                
                # æ›´æ™ºèƒ½çš„å†…å®¹ç±»å‹åˆ¤æ–­
                valid_content_types = ['video/', 'audio/', 'application/', 'text/', 'image/']
                valid_content = any(ct in content_type for ct in valid_content_types)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æµåª’ä½“
                is_stream: bool = (
                    'm3u' in content_type or 
                    'm3u' in stream_url.lower() or
                    content_type.startswith('video/') or
                    content_type.startswith('audio/') or
                    int(content_length) > 100 if content_length.isdigit() else False
                )
                
                if valid_content and is_stream:
                    speed: float = end_time - start_time
                    return True, speed
                else:
                    logger.debug(f"âš ï¸ æ— æ•ˆContent-Typeæˆ–å†…å®¹: {content_type} - {stream_url[:50]}...")
                    return False, float('inf')
            else:
                logger.debug(f"âŒ HTTPçŠ¶æ€ç  {response.status_code}: {stream_url[:50]}...")
                return False, float('inf')
                
        except requests.exceptions.Timeout:
            logger.debug(f"â° HTTPæµ‹é€Ÿè¶…æ—¶: {stream_url[:50]}...")
            return False, float('inf')
        except Exception as e:
            logger.debug(f"âš ï¸ HTTPæµ‹é€Ÿå¼‚å¸¸: {e} - {stream_url[:50]}...")
            return False, float('inf')

    def speed_test_sources(self, sources_df: pd.DataFrame) -> pd.DataFrame:
        """æµ‹é€Ÿå®ç° - æ˜¾ç¤ºæ¯ä¸ªé¢‘é“ç»“æœ"""
        logger.info(f"â±ï¸  å¼€å§‹æ™ºèƒ½æµ‹é€Ÿ (HTTPæ¨¡å¼)...")
        
        if sources_df.empty:
            logger.error("âŒ æ²¡æœ‰éœ€è¦æµ‹é€Ÿçš„æº")
            return pd.DataFrame()
            
        results: List[Dict[str, Any]] = []
        total_sources: int = len(sources_df)
        
        print("\nâš¡ é¢‘é“æµ‹é€Ÿç»“æœ:")
        print("-" * 80)
        
        def test_single_source(row: pd.Series) -> Dict[str, Any]:
            try:
                program_name: str = row['program_name']
                stream_url: str = row['stream_url']
                original_name: str = row.get('original_name', '')
                match_score: int = row.get('match_score', 0)
                
                # ä½¿ç”¨æ™ºèƒ½HTTPæµ‹é€Ÿ
                accessible, speed = self.speed_test_simple(stream_url)
                
                result = {
                    'program_name': program_name,
                    'stream_url': stream_url,
                    'accessible': accessible,
                    'speed': speed,
                    'original_name': original_name,
                    'match_score': match_score,
                    'stream_type': self._detect_stream_type(stream_url)
                }
                
                # å®æ—¶æ˜¾ç¤ºæ¯ä¸ªæºçš„æµ‹é€Ÿç»“æœ
                status_icon = "âœ…" if accessible else "âŒ"
                speed_display = f"{speed:.2f}s" if accessible else "è¶…æ—¶"
                match_display = f"(åŒ¹é…:{match_score}%)"
                
                print(f"  {status_icon} {program_name:20} {speed_display:8} {match_display:12} {original_name[:30]}...")
                
                return result
                
            except Exception as e:
                logger.debug(f"æµ‹é€Ÿè¿‡ç¨‹å¼‚å¸¸: {e}")
                print(f"  ğŸ’¥ {program_name:20} é”™è¯¯        {original_name[:30]}...")
                return {
                    'program_name': row.get('program_name', 'æœªçŸ¥'),
                    'stream_url': row.get('stream_url', ''),
                    'accessible': False,
                    'speed': float('inf'),
                    'stream_type': 'error'
                }
        
        with ThreadPoolExecutor(max_workers=self.config.MAX_WORKERS) as executor:
            futures = [executor.submit(test_single_source, row) for _, row in sources_df.iterrows()]
            
            completed: int = 0
            for future in as_completed(futures):
                try:
                    timeout: int = self.config.SPEED_TEST_TIMEOUT + 5
                    result: Dict[str, Any] = future.result(timeout=timeout)
                    results.append(result)
                    completed += 1
                        
                except TimeoutError:
                    print(f"  â° è¶…æ—¶é¢‘é“")
                    results.append({
                        'program_name': 'è¶…æ—¶é¢‘é“',
                        'stream_url': '',
                        'accessible': False,
                        'speed': float('inf'),
                        'stream_type': 'timeout'
                    })
                except Exception as e:
                    print(f"  ğŸ’¥ æµ‹é€Ÿå¼‚å¸¸")
                    logger.debug(f"æµ‹é€Ÿä»»åŠ¡å¼‚å¸¸: {e}")
        
        print("-" * 80)
        
        try:
            result_df: pd.DataFrame = pd.DataFrame(results)
            accessible_df: pd.DataFrame = result_df[result_df['accessible']].copy()
            
            if not accessible_df.empty:
                # æŒ‰é€Ÿåº¦å’ŒåŒ¹é…åˆ†æ•°ç»¼åˆæ’åº
                accessible_df['composite_score'] = (
                    (1 / accessible_df['speed'].clip(lower=0.1)) * 0.7 + 
                    (accessible_df['match_score'] / 100) * 0.3
                )
                accessible_df = accessible_df.sort_values(['program_name', 'composite_score'], ascending=[True, False])
                accessible_df = accessible_df.drop('composite_score', axis=1)
            
            accessible_count: int = len(accessible_df)
            avg_speed: float = accessible_df['speed'].mean() if not accessible_df.empty else 0
            
            self.stats['sources_tested'] = total_sources
            self.stats['sources_available'] = accessible_count
            
            logger.info(f"ğŸ“Š æµ‹é€Ÿå®Œæˆ: {accessible_count}/{total_sources} ä¸ªæºå¯ç”¨")
            logger.info(f"ğŸ“ˆ å¹³å‡å“åº”æ—¶é—´: {avg_speed:.2f} ç§’")
            
            # å­˜å‚¨é¢‘é“æµ‹é€Ÿç»“æœç”¨äºåç»­æ˜¾ç¤º
            for _, row in accessible_df.iterrows():
                channel = row['program_name']
                if channel not in self.channel_speed_results:
                    self.channel_speed_results[channel] = []
                self.channel_speed_results[channel].append({
                    'url': row['stream_url'],
                    'speed': row['speed'],
                    'match_score': row['match_score']
                })
            
            return accessible_df
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æµ‹é€Ÿç»“æœæ—¶å‡ºé”™: {e}")
            return pd.DataFrame()

    def _detect_stream_type(self, stream_url: str) -> str:
        """æ£€æµ‹æµåª’ä½“ç±»å‹"""
        stream_url_lower: str = stream_url.lower()
        
        for stream_type, identifier in self.config.STREAM_TYPES.items():
            if identifier in stream_url_lower:
                return stream_type
        
        return 'unknown'

    def generate_final_data(self, speed_tested_df: pd.DataFrame, template_categories: Dict[str, List[str]]) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæ•°æ®"""
        logger.info("ğŸ¨ ç”Ÿæˆæœ€ç»ˆæ’­æ”¾åˆ—è¡¨...")
        
        final_data: Dict[str, Any] = {}
        total_sources: int = 0
        
        if speed_tested_df.empty or not template_categories:
            logger.error("âŒ æµ‹é€Ÿæ•°æ®æˆ–æ¨¡æ¿åˆ†ç±»ä¸ºç©º")
            return final_data
        
        print("\nğŸ“¦ é¢‘é“æºç»Ÿè®¡:")
        print("-" * 60)
        
        for category, channels in template_categories.items():
            final_data[category] = {}
            
            for channel in channels:
                channel_sources = speed_tested_df[speed_tested_df['program_name'] == channel]
                
                if not channel_sources.empty:
                    # æ¯ä¸ªé¢‘é“é€‰æ‹©æœ€å¤š8ä¸ªæœ€ä½³æº
                    best_sources = channel_sources.head(self.config.MAX_SOURCES_PER_CHANNEL)
                    final_data[category][channel] = best_sources[['stream_url', 'speed', 'match_score']].to_dict('records')
                    total_sources += len(best_sources)
                    
                    source_count: int = len(best_sources)
                    speed_avg: float = sum(s['speed'] for s in final_data[category][channel]) / source_count
                    
                    # æ˜¾ç¤ºæ¯ä¸ªé¢‘é“çš„æºæ•°é‡å’Œè´¨é‡
                    quality_icon = "ğŸš€" if speed_avg < 3 else "âš¡" if speed_avg < 6 else "âœ…"
                    print(f"  {quality_icon} {channel:20} {source_count:2d}ä¸ªæº å¹³å‡{speed_avg:.2f}ç§’")
                    
                else:
                    final_data[category][channel] = []
                    print(f"  âŒ {channel:20} 0ä¸ªæº")
        
        print("-" * 60)
        logger.info(f"ğŸ“¦ æ€»å…±æ”¶é›†åˆ° {total_sources} ä¸ªæœ‰æ•ˆæº")
        
        return final_data

    def save_output_files(self, final_data: Dict[str, Any]) -> bool:
        """ä¿å­˜è¾“å‡ºæ–‡ä»¶åˆ°æ ¹ç›®å½•"""
        logger.info("ğŸ’¾ ä¿å­˜æ–‡ä»¶åˆ°æ ¹ç›®å½•...")
        
        if not final_data:
            logger.error("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return False
        
        success_count: int = 0
        
        # ä¿å­˜TXTæ ¼å¼
        try:
            with open(self.config.OUTPUT_TXT, 'w', encoding='utf-8') as f:
                f.write("# IPTVæ’­æ”¾åˆ—è¡¨ - ç”Ÿæˆæ—¶é—´: " + time.strftime("%Y-%m-%d %H:%M:%S") + "\n")
                f.write("# æ¯ä¸ªé¢‘é“æä¾›å¤šä¸ªå¤‡ç”¨æºï¼Œæœ€å¤š8ä¸ª\n")
                f.write("# æ ¼å¼: é¢‘é“åç§°,ç›´æ’­æµåœ°å€\n\n")
                
                for category, channels in final_data.items():
                    f.write(f"{category},#genre#\n")
                    
                    for channel, sources in channels.items():
                        for source in sources:
                            f.write(f"{channel},{source['stream_url']}\n")
                    
                    f.write("\n")
            
            success_count += 1
            file_size: int = os.path.getsize(self.config.OUTPUT_TXT)
            logger.info(f"âœ… TXTæ–‡ä»¶å·²ä¿å­˜: {self.config.OUTPUT_TXT} ({file_size} å­—èŠ‚)")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜TXTæ–‡ä»¶å¤±è´¥: {e}")
        
        # ä¿å­˜M3Uæ ¼å¼
        try:
            with open(self.config.OUTPUT_M3U, 'w', encoding='utf-8') as f:
                f.write("#EXTM3U\n")
                f.write("#PLAYLIST: IPTVæ™ºèƒ½åˆ—è¡¨\n")
                f.write("#GENERATED: " + time.strftime("%Y-%m-%d %H:%M:%S") + "\n")
                f.write("#SOURCE: å¤šæºæ™ºèƒ½èšåˆ\n")
                f.write("#SPEED_TEST: HTTPæ™ºèƒ½æµ‹é€Ÿ\n")
                
                for category, channels in final_data.items():
                    for channel, sources in channels.items():
                        for idx, source in enumerate(sources, 1):
                            speed_info = f"å“åº”{source['speed']:.1f}ç§’" if source['speed'] < 10 else "å“åº”è¾ƒæ…¢"
                            display_name: str = f"{channel}" if len(sources) == 1 else f"{channel} [æº{idx}-{speed_info}]"
                            f.write(f'#EXTINF:-1 tvg-name="{channel}" group-title="{category}",{display_name}\n')
                            f.write(f"{source['stream_url']}\n")
            
            success_count += 1
            file_size = os.path.getsize(self.config.OUTPUT_M3U)
            logger.info(f"âœ… M3Uæ–‡ä»¶å·²ä¿å­˜: {self.config.OUTPUT_M3U} ({file_size} å­—èŠ‚)")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜M3Uæ–‡ä»¶å¤±è´¥: {e}")
            
        return success_count == 2

    def create_demo_template(self) -> bool:
        """åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶åˆ°æ ¹ç›®å½•"""
        demo_content: str = """# IPTVé¢‘é“æ¨¡æ¿æ–‡ä»¶
# æ ¼å¼: åˆ†ç±»åç§°,#genre#
#       é¢‘é“åç§°1
#       é¢‘é“åç§°2

å¤®è§†é¢‘é“,#genre#
CCTV-1
CCTV-2
CCTV-3
CCTV-4
CCTV-5
CCTV-6
CCTV-7
CCTV-8
CCTV-9
CCTV-10
CCTV-11
CCTV-12
CCTV-13
CCTV-14
CCTV-15

å«è§†é¢‘é“,#genre#
æ¹–å—å«è§†
æµ™æ±Ÿå«è§†
æ±Ÿè‹å«è§†
ä¸œæ–¹å«è§†
åŒ—äº¬å«è§†
å¤©æ´¥å«è§†
å±±ä¸œå«è§†
å¹¿ä¸œå«è§†
æ·±åœ³å«è§†
å®‰å¾½å«è§†

åœ°æ–¹é¢‘é“,#genre#
åŒ—äº¬æ–°é—»
ä¸Šæµ·æ–°é—»
å¹¿å·ç»¼åˆ
é‡åº†å«è§†
æˆéƒ½æ–°é—»
æ·±åœ³æ–°é—»
æ­å·ç»¼åˆ

é«˜æ¸…é¢‘é“,#genre#
CCTV-1 HD
CCTV-5 HD
æ¹–å—å«è§† HD
æµ™æ±Ÿå«è§† HD
æ±Ÿè‹å«è§† HD

å½±è§†é¢‘é“,#genre#
CCTV-6
CCTV-8
æ¹–å—å«è§†ç”µå½±
æµ™æ±Ÿå«è§†å½±è§†
"""
        try:
            with open(self.config.TEMPLATE_FILE, 'w', encoding='utf-8') as f:
                f.write(demo_content)
            logger.info(f"âœ… å·²åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶: {self.config.TEMPLATE_FILE}")
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def print_statistics(self, final_data: Dict[str, Any]) -> None:
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*60)
        print("ğŸ“ˆ è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š")
        print("="*60)
        
        if not final_data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ç»Ÿè®¡")
            return
        
        total_channels: int = 0
        total_sources: int = 0
        category_details: List[Tuple[str, int, int]] = []
        
        for category, channels in final_data.items():
            category_channels: int = 0
            category_sources: int = 0
            
            for channel, sources in channels.items():
                if sources:
                    category_channels += 1
                    category_sources += len(sources)
            
            if category_channels > 0:
                category_details.append((category, category_channels, category_sources))
                total_channels += category_channels
                total_sources += category_sources
        
        # æŒ‰é¢‘é“æ•°é‡æ’åº
        category_details.sort(key=lambda x: x[1], reverse=True)
        
        for category, channel_count, source_count in category_details:
            avg_sources: float = source_count / channel_count if channel_count > 0 else 0
            print(f"  ğŸ“º {category}: {channel_count:2d}é¢‘é“, {source_count:3d}æº (å¹³å‡{avg_sources:.1f}æº/é¢‘é“)")
        
        print("-"*60)
        print(f"ğŸ“Š æ€»è®¡: {total_channels}é¢‘é“, {total_sources}æº")
        print(f"ğŸ¯ é…ç½®: æ¯ä¸ªé¢‘é“æœ€å¤š{self.config.MAX_SOURCES_PER_CHANNEL}ä¸ªæº")
        
        # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
        print("-"*60)
        print(f"ğŸŒ æºæŠ“å–: {self.stats['sources_fetched']}ä¸ªæˆåŠŸ")
        print(f"ğŸ”§ æµè§£æ: {self.stats['streams_parsed']}ä¸ªæµ")
        print(f"ğŸ¯ é¢‘é“åŒ¹é…: {self.stats['channels_matched']}ä¸ªé¢‘é“")
        print(f"âš¡ æºæµ‹é€Ÿ: {self.stats['sources_tested']}ä¸ªæµ‹è¯•, {self.stats['sources_available']}ä¸ªå¯ç”¨")
        print(f"ğŸ”§ æµ‹é€Ÿæ¨¡å¼: HTTPæ™ºèƒ½æµ‹é€Ÿ")

    def cleanup(self) -> None:
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_dir: Path = Path(self.config.TEMP_DIR)
            if temp_dir.exists():
                shutil.rmtree(temp_dir)
                logger.info("âœ… ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.debug(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def run(self) -> None:
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("=" * 60)
        print("ğŸ¬ IPTVæ™ºèƒ½ç®¡ç†å·¥å…· - ä¼˜åŒ–æµ‹é€Ÿç‰ˆ v3.2")
        print("ğŸ”§ å…³é—­FFmpegæµ‹é€Ÿ + æ™ºèƒ½HTTPæµ‹é€Ÿ + è¯¦ç»†ç»“æœæ˜¾ç¤º")
        print("ğŸ“º æ¯ä¸ªé¢‘é“æœ€å¤š8ä¸ªå¤‡ç”¨æº")
        print("=" * 60)
        
        start_time: float = time.time()
        
        try:
            # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶
            template_path: Path = Path(self.config.TEMPLATE_FILE)
            if not template_path.exists():
                print("ğŸ“ æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹æ¨¡æ¿...")
                if self.create_demo_template():
                    print(f"\nğŸ’¡ æ¨¡æ¿æ–‡ä»¶å·²åˆ›å»ºï¼Œè¯·ç¼–è¾‘åé‡æ–°è¿è¡Œ:")
                    print(f"   ğŸ“„ {template_path.absolute()}")
                    input("æŒ‰å›è½¦é”®é€€å‡º...")
                return
            
            # æ‰§è¡Œå¤„ç†æµç¨‹
            template_categories = self.load_template()
            if not template_categories:
                return
            
            content = self.fetch_all_streams()
            if not content:
                return
            
            sources_df = self.organize_streams(content)
            if sources_df.empty:
                return
            
            all_template_channels = []
            for channels in template_categories.values():
                all_template_channels.extend(channels)
            
            filtered_df = self.filter_and_sort_sources(sources_df, all_template_channels)
            if filtered_df.empty:
                return
            
            speed_tested_df = self.speed_test_sources(filtered_df)
            if speed_tested_df.empty:
                return
            
            final_data = self.generate_final_data(speed_tested_df, template_categories)
            
            # ä¿å­˜æ–‡ä»¶
            if not self.save_output_files(final_data):
                return
            
            # æ‰“å°ç»Ÿè®¡
            self.print_statistics(final_data)
            
            end_time: float = time.time()
            elapsed_time: float = end_time - start_time
            
            print("\nğŸ‰ å¤„ç†å®Œæˆ!")
            print(f"â° æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
            print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶ (æ ¹ç›®å½•):")
            print(f"   ğŸ“„ {Path(self.config.OUTPUT_TXT).absolute()}")
            print(f"   ğŸ“„ {Path(self.config.OUTPUT_M3U).absolute()}")
                
        except KeyboardInterrupt:
            print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.cleanup()


def main() -> None:
    """ä¸»å‡½æ•°"""
    try:
        config = Config()
        manager = IPTVManager(config)
        manager.run()
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
