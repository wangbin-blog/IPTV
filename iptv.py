#!/usr/bin/env python3
"""
IPTVæ™ºèƒ½ç®¡ç†å·¥å…· - æ ¸å¿ƒåŠŸèƒ½ç‰ˆæœ¬ (ä¿®å¤å®Œæ•´ç‰ˆ)
åŠŸèƒ½ï¼šå¤šæºæŠ“å–ã€é¢‘é“åŒ¹é…ã€é€Ÿåº¦æµ‹è¯•ã€æ’­æ”¾åˆ—è¡¨ç”Ÿæˆ
ç‰ˆæœ¬ï¼šv2.2 (æ™ºèƒ½æµ‹é€Ÿä¼˜åŒ–ç‰ˆ)
"""

import requests
import pandas as pd
import re
import os
import time
import subprocess
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
import logging
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('IPTVManager')

class IPTVManager:
    """IPTVæ™ºèƒ½ç®¡ç†å·¥å…·æ ¸å¿ƒç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–IPTVç®¡ç†å™¨"""
        # é…ç½®å‚æ•°
        self.source_urls = [
            "https://raw.githubusercontent.com/zwc456baby/iptv_alive/master/live.txt",
            "https://live.zbds.top/tv/iptv6.txt", 
            "https://live.zbds.top/tv/iptv4.txt",
            "http://home.jundie.top:81/top/tvbox.txt",
            "https://mirror.ghproxy.com/https://raw.githubusercontent.com/YanG-1989/m3u/main/Gather.m3u",
        ]
        self.request_timeout = 15
        self.max_sources_per_channel = 5
        self.speed_test_timeout = 10  # ç»Ÿä¸€è¶…æ—¶æ—¶é—´ä¸º10ç§’
        self.similarity_threshold = 50
        self.max_workers = 3  # å‡å°‘å¹¶å‘æ•°é¿å…èµ„æºç«äº‰
        self.template_file = "demo.txt"
        self.output_txt = "iptv.txt"
        self.output_m3u = "iptv.m3u"
        self.temp_dir = "temp"
        
        # åˆå§‹åŒ–ä¼šè¯
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self._setup_directories()
        
        # ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self._compile_patterns()
        
        # æ£€æŸ¥FFmpeg
        self.ffmpeg_available = self._check_ffmpeg()

    def _setup_directories(self) -> None:
        """è®¾ç½®å¿…è¦çš„ç›®å½•"""
        try:
            temp_path = Path(self.temp_dir)
            temp_path.mkdir(exist_ok=True)
            logger.info("âœ… ç›®å½•åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ ç›®å½•è®¾ç½®å¤±è´¥: {e}")
            raise

    def _compile_patterns(self) -> None:
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        self.patterns = {
            'extinf': re.compile(r'#EXTINF:.*?tvg-name="([^"]+)".*?,(.+)'),
            'category': re.compile(r'^(.*?),#genre#$'),
            'url': re.compile(r'https?://[^\s,]+'),
            'tvg_name': re.compile(r'tvg-name="([^"]*)"'),
            'tvg_id': re.compile(r'tvg-id="([^"]*)"'),
            'group_title': re.compile(r'group-title="([^"]*)"'),
            'extinf_content': re.compile(r',\s*(.+)$')
        }

    def _check_ffmpeg(self) -> bool:
        """æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                ['ffmpeg', '-version'], 
                capture_output=True, 
                timeout=5,
                check=False
            )
            if result.returncode == 0:
                logger.info("âœ… FFmpegå¯ç”¨")
                return True
            else:
                logger.warning("âš ï¸ FFmpegæœªå®‰è£…ï¼Œå°†ä½¿ç”¨HTTPæµ‹é€Ÿ")
                return False
        except:
            logger.warning("âš ï¸ FFmpegæœªå®‰è£…ï¼Œå°†ä½¿ç”¨HTTPæµ‹é€Ÿ")
            return False

    def validate_url(self, url: str) -> bool:
        """éªŒè¯URLæ ¼å¼æ˜¯å¦æ­£ç¡®"""
        if not url or not isinstance(url, str):
            return False
            
        try:
            result = urlparse(url)
            valid_scheme = result.scheme in ['http', 'https']
            valid_netloc = bool(result.netloc)
            return all([valid_scheme, valid_netloc])
        except:
            return False

    def fetch_streams_from_url(self, url: str, retries: int = 2) -> Optional[str]:
        """ä»URLè·å–æµæ•°æ®"""
        if not self.validate_url(url):
            logger.error(f"âŒ æ— æ•ˆçš„URL: {url}")
            return None
            
        logger.info(f"ğŸ“¡ æ­£åœ¨è·å–: {url}")
        
        for attempt in range(retries):
            try:
                response = self.session.get(
                    url, 
                    timeout=self.request_timeout,
                    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
                )
                response.encoding = 'utf-8'
                
                if response.status_code == 200:
                    content = response.text
                    content_length = len(content)
                    logger.info(f"âœ… æˆåŠŸè·å–: {url} ({content_length} å­—ç¬¦)")
                    return content
                    
                elif response.status_code == 429:
                    wait_time = (attempt + 1) * 5
                    logger.warning(f"âš ï¸ è¯·æ±‚é¢‘ç¹ï¼Œç­‰å¾… {wait_time} ç§’")
                    time.sleep(wait_time)
                    continue
                    
                else:
                    logger.warning(f"âš ï¸ è·å–å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    
            except requests.exceptions.Timeout:
                logger.warning(f"âš ï¸ è¯·æ±‚è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{retries}")
            except requests.exceptions.ConnectionError:
                logger.warning(f"âš ï¸ è¿æ¥é”™è¯¯ï¼Œå°è¯• {attempt + 1}/{retries}")
            except Exception as e:
                logger.warning(f"âš ï¸ è¯·æ±‚å¼‚å¸¸: {e}")
                
            if attempt < retries - 1:
                time.sleep(2)
        
        logger.error(f"âŒ æ‰€æœ‰é‡è¯•å¤±è´¥: {url}")
        return None

    def fetch_all_streams(self) -> str:
        """è·å–æ‰€æœ‰æºçš„æµæ•°æ®"""
        logger.info("ğŸš€ å¼€å§‹å¤šæºæŠ“å–...")
        
        if not self.source_urls:
            logger.error("âŒ æ²¡æœ‰é…ç½®æºURL")
            return ""
        
        all_streams = []
        successful_sources = 0
        
        print("ğŸŒ æŠ“å–è¿›åº¦: ", end="")
        
        with ThreadPoolExecutor(max_workers=min(3, len(self.source_urls))) as executor:
            future_to_url = {executor.submit(self.fetch_streams_from_url, url): url for url in self.source_urls}
            
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    content = future.result()
                    if content:
                        all_streams.append(content)
                        successful_sources += 1
                        print("âœ…", end="")
                    else:
                        print("âŒ", end="")
                except Exception as e:
                    logger.error(f"å¤„ç† {url} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    print("âŒ", end="")
        
        print()  # æ¢è¡Œ
        logger.info(f"âœ… æˆåŠŸè·å– {successful_sources}/{len(self.source_urls)} ä¸ªæºçš„æ•°æ®")
        return "\n".join(all_streams) if all_streams else ""

    def _extract_program_name(self, extinf_line: str) -> str:
        """ä»EXTINFè¡Œæå–èŠ‚ç›®åç§°"""
        if not extinf_line.startswith('#EXTINF'):
            return "æœªçŸ¥é¢‘é“"
        
        try:
            # ä»tvg-nameå±æ€§æå–
            tvg_match = self.patterns['tvg_name'].search(extinf_line)
            if tvg_match and tvg_match.group(1).strip():
                name = tvg_match.group(1).strip()
                if name and name != "æœªçŸ¥é¢‘é“":
                    return name
            
            # ä»é€—å·åçš„å†…å®¹æå–
            content_match = self.patterns['extinf_content'].search(extinf_line)
            if content_match and content_match.group(1).strip():
                name = content_match.group(1).strip()
                name = re.sub(r'\[.*?\]|\(.*?\)', '', name).strip()
                if name and name != "æœªçŸ¥é¢‘é“":
                    return name
                        
        except Exception as e:
            logger.debug(f"EXTINFè§£æé”™è¯¯: {extinf_line} - {e}")
        
        return "æœªçŸ¥é¢‘é“"

    def parse_m3u(self, content: str) -> List[Dict[str, str]]:
        """è§£æM3Uæ ¼å¼å†…å®¹"""
        if not content:
            return []
            
        streams = []
        lines = content.splitlines()
        current_program = None
        current_group = "é»˜è®¤åˆ†ç»„"
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            if not line:
                i += 1
                continue
                
            if line.startswith("#EXTINF"):
                current_program = self._extract_program_name(line)
                
                group_match = self.patterns['group_title'].search(line)
                if group_match:
                    current_group = group_match.group(1).strip()
                else:
                    current_group = "é»˜è®¤åˆ†ç»„"
                    
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    if self.validate_url(next_line):
                        streams.append({
                            "program_name": current_program,
                            "stream_url": next_line,
                            "group": current_group
                        })
                        i += 1
            elif line.startswith(('http://', 'https://')):
                if self.validate_url(line):
                    streams.append({
                        "program_name": "æœªçŸ¥é¢‘é“",
                        "stream_url": line,
                        "group": "é»˜è®¤åˆ†ç»„"
                    })
            
            i += 1
        
        return streams

    def parse_txt(self, content: str) -> List[Dict[str, str]]:
        """è§£æTXTæ ¼å¼å†…å®¹"""
        if not content:
            return []
            
        streams = []
        
        for line in content.splitlines():
            line = line.strip()
            if not line or line.startswith('#') or '#genre#' in line:
                continue
            
            if ',' in line:
                parts = line.split(',', 1)
                if len(parts) == 2:
                    program_name = parts[0].strip()
                    url_part = parts[1].strip()
                    
                    url_match = self.patterns['url'].search(url_part)
                    if url_match:
                        stream_url = url_match.group()
                        if self.validate_url(stream_url):
                            streams.append({
                                "program_name": program_name,
                                "stream_url": stream_url,
                                "group": "é»˜è®¤åˆ†ç»„"
                            })
            else:
                url_match = self.patterns['url'].search(line)
                if url_match:
                    stream_url = url_match.group()
                    program_name = line.replace(stream_url, '').strip()
                    if not program_name:
                        program_name = "æœªçŸ¥é¢‘é“"
                    
                    if self.validate_url(stream_url):
                        streams.append({
                            "program_name": program_name,
                            "stream_url": stream_url,
                            "group": "é»˜è®¤åˆ†ç»„"
                        })
        
        return streams

    def organize_streams(self, content: str) -> pd.DataFrame:
        """æ•´ç†æµæ•°æ®ï¼Œå»é™¤é‡å¤å’Œæ— æ•ˆæ•°æ®"""
        if not content:
            logger.error("âŒ æ²¡æœ‰å†…å®¹å¯å¤„ç†")
            return pd.DataFrame()
            
        logger.info("ğŸ” è§£ææµæ•°æ®...")
        
        try:
            if content.startswith("#EXTM3U"):
                streams = self.parse_m3u(content)
            else:
                streams = self.parse_txt(content)
            
            if not streams:
                logger.error("âŒ æœªèƒ½è§£æå‡ºä»»ä½•æµæ•°æ®")
                return pd.DataFrame()
                
            df = pd.DataFrame(streams)
            
            # æ•°æ®æ¸…ç†
            initial_count = len(df)
            
            # ç§»é™¤ç©ºå€¼å’Œæ— æ•ˆæ•°æ®
            df = df.dropna()
            df = df[df['program_name'].str.len() > 0]
            df = df[df['stream_url'].str.startswith(('http://', 'https://'))]
            
            # éªŒè¯URL
            df['url_valid'] = df['stream_url'].apply(self.validate_url)
            df = df[df['url_valid']].drop('url_valid', axis=1)
            
            # å»é‡
            df = df.drop_duplicates(subset=['program_name', 'stream_url'])
            
            final_count = len(df)
            logger.info(f"ğŸ“Š æ•°æ®æ¸…ç†: {initial_count} -> {final_count} ä¸ªæµ")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®å¤„ç†é”™è¯¯: {e}")
            return pd.DataFrame()

    def load_template(self) -> Optional[Dict[str, List[str]]]:
        """åŠ è½½é¢‘é“æ¨¡æ¿æ–‡ä»¶"""
        template_file = Path(self.template_file)
        
        if not template_file.exists():
            logger.error(f"âŒ æ¨¡æ¿æ–‡ä»¶ {template_file} ä¸å­˜åœ¨")
            return None
            
        logger.info(f"ğŸ“‹ åŠ è½½æ¨¡æ¿æ–‡ä»¶: {template_file}")
        categories = {}
        current_category = None
        
        try:
            with open(template_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                        
                    category_match = self.patterns['category'].match(line)
                    if category_match:
                        current_category = category_match.group(1).strip()
                        categories[current_category] = []
                    
                    elif current_category and line and not line.startswith('#'):
                        channel_name = line.split(',')[0].strip() if ',' in line else line.strip()
                        if channel_name:
                            categories[current_category].append(channel_name)
        
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return None
        
        if not categories:
            logger.error("âŒ æ¨¡æ¿æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„é¢‘é“åˆ†ç±»")
            return None
            
        total_channels = sum(len(channels) for channels in categories.values())
        logger.info(f"ğŸ“ æ¨¡æ¿åˆ†ç±»: {list(categories.keys())}")
        logger.info(f"ğŸ“º æ¨¡æ¿é¢‘é“æ€»æ•°: {total_channels}")
        
        return categories

    def clean_channel_name(self, name: str) -> str:
        """é¢‘é“åç§°æ¸…ç†"""
        if not name:
            return ""
        
        try:
            cleaned = re.sub(r'[^\w\u4e00-\u9fa5\s-]', '', name.lower())
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            cleaned = re.sub(r'\s+(hd|fhd|4k|ç›´æ’­|é¢‘é“|tv|television)$', '', cleaned)
            return cleaned
        except:
            return name.lower() if name else ""

    def similarity_score(self, str1: str, str2: str) -> int:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-100ï¼‰"""
        if not str1 or not str2:
            return 0
            
        try:
            clean_str1 = self.clean_channel_name(str1)
            clean_str2 = self.clean_channel_name(str2)
            
            if not clean_str1 or not clean_str2:
                return 0
            
            # å®Œå…¨åŒ¹é…
            if clean_str1 == clean_str2:
                return 100
            
            # åŒ…å«å…³ç³»
            if clean_str1 in clean_str2:
                return 90
            if clean_str2 in clean_str1:
                return 85
            
            # Jaccardç›¸ä¼¼åº¦
            set1 = set(clean_str1)
            set2 = set(clean_str2)
            
            intersection = len(set1 & set2)
            union = len(set1 | set2)
            
            if union > 0:
                jaccard_similarity = intersection / union
                return int(jaccard_similarity * 80)
                
        except Exception as e:
            logger.debug(f"ç›¸ä¼¼åº¦è®¡ç®—é”™è¯¯: {str1}, {str2} - {e}")
        
        return 0

    def filter_and_sort_sources(self, sources_df: pd.DataFrame, template_channels: List[str]) -> pd.DataFrame:
        """é¢‘é“åŒ¹é…å’Œæºç­›é€‰"""
        logger.info("ğŸ¯ å¼€å§‹é¢‘é“åŒ¹é…...")
        
        if sources_df.empty or not template_channels:
            logger.error("âŒ æºæ•°æ®æˆ–æ¨¡æ¿é¢‘é“ä¸ºç©º")
            return pd.DataFrame()
        
        matched_results = []
        
        print("ğŸ” åŒ¹é…è¿›åº¦: ", end="")
        
        for template_channel in template_channels:
            best_match_row = None
            best_score = 0
            
            for _, source_row in sources_df.iterrows():
                source_channel = source_row['program_name']
                score = self.similarity_score(template_channel, source_channel)
                
                if score > best_score and score >= self.similarity_threshold:
                    best_score = score
                    best_match_row = source_row.copy()
                    best_match_row['template_channel'] = template_channel
                    best_match_row['match_score'] = score
            
            if best_match_row is not None:
                matched_results.append(best_match_row)
                print("âœ…", end="")
            else:
                print("âŒ", end="")
        
        print()  # æ¢è¡Œ
        
        if matched_results:
            result_df = pd.DataFrame(matched_results)
            result_df = result_df.rename(columns={'program_name': 'original_name'})
            result_df = result_df.rename(columns={'template_channel': 'program_name'})
            
            unique_matched_channels = result_df['program_name'].nunique()
            logger.info(f"âœ… é¢‘é“åŒ¹é…å®Œæˆ: {len(matched_results)} ä¸ªæµåŒ¹é…åˆ° {unique_matched_channels} ä¸ªæ¨¡æ¿é¢‘é“")
            
            return result_df
        else:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…çš„é¢‘é“")
            return pd.DataFrame()

    def speed_test_ffmpeg(self, stream_url: str) -> Tuple[bool, float]:
        """ä½¿ç”¨FFmpegè¿›è¡Œæµåª’ä½“æµ‹é€Ÿ - 10ç§’å“åº”10ç§’è¶…æ—¶"""
        if not self.ffmpeg_available or not stream_url:
            return False, float('inf')
            
        temp_file = Path(self.temp_dir) / f'test_{abs(hash(stream_url))}.ts'
        
        try:
            cmd = [
                'ffmpeg',
                '-y',
                '-timeout', '10000000',  # 10ç§’è¶…æ—¶ï¼ˆå¾®ç§’ï¼‰
                '-rw_timeout', '10000000',  # è¯»å†™è¶…æ—¶10ç§’
                '-i', stream_url,
                '-t', '10',  # æµ‹è¯•10ç§’å†…å®¹
                '-c', 'copy',
                '-f', 'mpegts',
                '-max_muxing_queue_size', '1024',  # å¢åŠ é˜Ÿåˆ—å¤§å°
                str(temp_file)
            ]
            
            start_time = time.time()
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                timeout=15,  # æ€»è¿›ç¨‹è¶…æ—¶15ç§’
                check=False
            )
            end_time = time.time()
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file.exists():
                try:
                    temp_file.unlink()
                except:
                    pass
            
            if result.returncode == 0:
                speed = end_time - start_time
                logger.info(f"âœ… FFmpegæµ‹é€ŸæˆåŠŸ: {speed:.2f}ç§’ - {stream_url[:50]}...")
                return True, speed
            else:
                logger.debug(f"âŒ FFmpegæµ‹é€Ÿå¤±è´¥: {result.stderr[:100]}...")
                return False, float('inf')
                
        except subprocess.TimeoutExpired:
            logger.debug(f"â° FFmpegæµ‹é€Ÿè¶…æ—¶: {stream_url[:50]}...")
            if temp_file.exists():
                try:
                    temp_file.unlink()
                except:
                    pass
            return False, float('inf')
        except Exception as e:
            logger.debug(f"âš ï¸ FFmpegæµ‹é€Ÿå¼‚å¸¸: {e} - {stream_url[:50]}...")
            if temp_file.exists():
                try:
                    temp_file.unlink()
                except:
                    pass
            return False, float('inf')

    def speed_test_simple(self, stream_url: str) -> Tuple[bool, float]:
        """ç®€å•çš„HTTPæµ‹é€Ÿ - 10ç§’è¶…æ—¶"""
        if not stream_url:
            return False, float('inf')
            
        try:
            start_time = time.time()
            response = self.session.head(
                stream_url, 
                timeout=10,  # 10ç§’è¶…æ—¶
                allow_redirects=True,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': '*/*',
                    'Connection': 'close'
                }
            )
            end_time = time.time()
            
            if response.status_code in [200, 302, 301, 307]:
                speed = end_time - start_time
                logger.info(f"âœ… HTTPæµ‹é€ŸæˆåŠŸ: {speed:.2f}ç§’ - {stream_url[:50]}...")
                return True, speed
            else:
                logger.debug(f"âŒ HTTPçŠ¶æ€ç  {response.status_code}: {stream_url[:50]}...")
                return False, float('inf')
        except requests.exceptions.Timeout:
            logger.debug(f"â° HTTPæµ‹é€Ÿè¶…æ—¶: {stream_url[:50]}...")
            return False, float('inf')
        except Exception as e:
            logger.debug(f"âš ï¸ HTTPæµ‹é€Ÿå¼‚å¸¸: {e} - {stream_url[:50]}...")
            return False, float('inf')

    def speed_test_sources(self, sources_df: pd.DataFrame) -> pd.DataFrame:
        """æµ‹é€Ÿå®ç° - ä¼˜åŒ–è¶…æ—¶å¤„ç†"""
        logger.info("â±ï¸  å¼€å§‹æµ‹é€Ÿ (FFmpeg:10ç§’æµ‹è¯•+10ç§’è¶…æ—¶, HTTP:10ç§’è¶…æ—¶)...")
        
        if sources_df.empty:
            logger.error("âŒ æ²¡æœ‰éœ€è¦æµ‹é€Ÿçš„æº")
            return pd.DataFrame()
            
        results = []
        total_sources = len(sources_df)
        
        print("âš¡ æµ‹é€Ÿè¿›åº¦: ", end="")
        
        def test_single_source(row):
            try:
                program_name = row['program_name']
                stream_url = row['stream_url']
                
                # æ ¹æ®æµç±»å‹é€‰æ‹©æµ‹é€Ÿæ–¹å¼
                if any(ext in stream_url.lower() for ext in ['.m3u8', '.ts', '.flv', '.mp4', 'rtmp', 'rtsp']):
                    if self.ffmpeg_available:
                        accessible, speed = self.speed_test_ffmpeg(stream_url)
                    else:
                        accessible, speed = self.speed_test_simple(stream_url)
                else:
                    accessible, speed = self.speed_test_simple(stream_url)
                
                return {
                    'program_name': program_name,
                    'stream_url': stream_url,
                    'accessible': accessible,
                    'speed': speed,
                    'original_name': row.get('original_name', ''),
                    'match_score': row.get('match_score', 0)
                }
            except Exception as e:
                logger.debug(f"æµ‹é€Ÿè¿‡ç¨‹å¼‚å¸¸: {e}")
                return {
                    'program_name': row.get('program_name', 'æœªçŸ¥'),
                    'stream_url': row.get('stream_url', ''),
                    'accessible': False,
                    'speed': float('inf')
                }
        
        # å‡å°‘å¹¶å‘æ•°ä»¥é¿å…èµ„æºç«äº‰
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(test_single_source, row) for _, row in sources_df.iterrows()]
            
            completed = 0
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=25)  # å•ä¸ªæµ‹é€Ÿæœ€å¤§25ç§’è¶…æ—¶
                    results.append(result)
                    completed += 1
                    
                    if result['accessible']:
                        print("âœ…", end="")
                    else:
                        print("âŒ", end="")
                        
                    # æ¯å®Œæˆ10ä¸ªæµ‹é€Ÿæ˜¾ç¤ºè¿›åº¦
                    if completed % 10 == 0:
                        print(f"({completed}/{total_sources})", end="")
                        
                except TimeoutError:
                    print("â°", end="")
                    results.append({
                        'program_name': 'è¶…æ—¶é¢‘é“',
                        'stream_url': '',
                        'accessible': False,
                        'speed': float('inf')
                    })
                except Exception as e:
                    print("ğŸ’¥", end="")
                    logger.debug(f"æµ‹é€Ÿä»»åŠ¡å¼‚å¸¸: {e}")
        
        print()  # æ¢è¡Œ
        
        try:
            result_df = pd.DataFrame(results)
            accessible_df = result_df[result_df['accessible']].copy()
            accessible_df = accessible_df.sort_values(['program_name', 'speed'])
            
            accessible_count = len(accessible_df)
            avg_speed = accessible_df['speed'].mean() if not accessible_df.empty else 0
            
            logger.info(f"ğŸ“Š æµ‹é€Ÿå®Œæˆ: {accessible_count}/{total_sources} ä¸ªæºå¯ç”¨")
            logger.info(f"ğŸ“ˆ å¹³å‡å“åº”æ—¶é—´: {avg_speed:.2f} ç§’")
            
            return accessible_df
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æµ‹é€Ÿç»“æœæ—¶å‡ºé”™: {e}")
            return pd.DataFrame()

    def generate_final_data(self, speed_tested_df: pd.DataFrame, template_categories: Dict[str, List[str]]) -> Dict[str, Any]:
        """ç”Ÿæˆæœ€ç»ˆæ•°æ®"""
        logger.info("ğŸ¨ ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶...")
        
        final_data = {}
        total_sources = 0
        
        if speed_tested_df.empty or not template_categories:
            logger.error("âŒ æµ‹é€Ÿæ•°æ®æˆ–æ¨¡æ¿åˆ†ç±»ä¸ºç©º")
            return final_data
        
        print("ğŸ“¦ ç”Ÿæˆè¿›åº¦: ", end="")
        
        for category, channels in template_categories.items():
            final_data[category] = {}
            
            for channel in channels:
                channel_sources = speed_tested_df[speed_tested_df['program_name'] == channel]
                
                if not channel_sources.empty:
                    sorted_sources = channel_sources.head(self.max_sources_per_channel)
                    final_data[category][channel] = sorted_sources[['stream_url', 'speed']].to_dict('records')
                    total_sources += len(sorted_sources)
                    print("âœ…", end="")
                else:
                    final_data[category][channel] = []
                    print("âŒ", end="")
        
        print()  # æ¢è¡Œ
        logger.info(f"ğŸ“¦ æ€»å…±æ”¶é›†åˆ° {total_sources} ä¸ªæœ‰æ•ˆæº")
        return final_data

    def save_output_files(self, final_data: Dict[str, Any]) -> bool:
        """ä¿å­˜è¾“å‡ºæ–‡ä»¶"""
        logger.info("ğŸ’¾ ä¿å­˜æ–‡ä»¶...")
        
        if not final_data:
            logger.error("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return False
        
        success_count = 0
        
        # ä¿å­˜TXTæ ¼å¼
        try:
            with open(self.output_txt, 'w', encoding='utf-8') as f:
                for category, channels in final_data.items():
                    f.write(f"{category},#genre#\n")
                    
                    for channel, sources in channels.items():
                        for source in sources:
                            f.write(f"{channel},{source['stream_url']}\n")
                    
                    f.write("\n")
            
            success_count += 1
            logger.info(f"âœ… TXTæ–‡ä»¶å·²ä¿å­˜: {self.output_txt}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜TXTæ–‡ä»¶å¤±è´¥: {e}")
        
        # ä¿å­˜M3Uæ ¼å¼
        try:
            with open(self.output_m3u, 'w', encoding='utf-8') as f:
                f.write("#EXTM3U\n")
                
                for category, channels in final_data.items():
                    for channel, sources in channels.items():
                        for source in sources:
                            f.write(f'#EXTINF:-1 tvg-name="{channel}" group-title="{category}",{channel}\n')
                            f.write(f"{source['stream_url']}\n")
            
            success_count += 1
            logger.info(f"âœ… M3Uæ–‡ä»¶å·²ä¿å­˜: {self.output_m3u}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜M3Uæ–‡ä»¶å¤±è´¥: {e}")
            
        return success_count == 2

    def create_demo_template(self) -> bool:
        """åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶"""
        demo_content = """å¤®è§†é¢‘é“,#genre#
CCTV-1 ç»¼åˆ
CCTV-2 è´¢ç»
CCTV-3 ç»¼è‰º
CCTV-4 ä¸­æ–‡å›½é™…
CCTV-5 ä½“è‚²
CCTV-6 ç”µå½±
CCTV-7 å›½é˜²å†›äº‹
CCTV-8 ç”µè§†å‰§
CCTV-9 çºªå½•
CCTV-10 ç§‘æ•™
CCTV-11 æˆæ›²
CCTV-12 ç¤¾ä¼šä¸æ³•
CCTV-13 æ–°é—»
CCTV-14 å°‘å„¿
CCTV-15 éŸ³ä¹

å«è§†é¢‘é“,#genre#
æ¹–å—å«è§†
æµ™æ±Ÿå«è§†
æ±Ÿè‹å«è§†
ä¸œæ–¹å«è§†
åŒ—äº¬å«è§†
å¤©æ´¥å«è§†
å±±ä¸œå«è§†
å¹¿ä¸œå«è§†
æ·±åœ³å«è§†

åœ°æ–¹é¢‘é“,#genre#
åŒ—äº¬æ–°é—»
ä¸Šæµ·æ–°é—»
å¹¿å·ç»¼åˆ
é‡åº†å«è§†
æˆéƒ½æ–°é—»
"""
        try:
            with open(self.template_file, 'w', encoding='utf-8') as f:
                f.write(demo_content)
            logger.info(f"âœ… å·²åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶: {self.template_file}")
            return True
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return False

    def print_statistics(self, final_data: Dict[str, Any]):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“ˆ ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
        print("="*50)
        
        if not final_data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ç»Ÿè®¡")
            return
        
        total_channels = 0
        total_sources = 0
        
        for category, channels in final_data.items():
            category_channels = 0
            category_sources = 0
            
            for channel, sources in channels.items():
                if sources:
                    category_channels += 1
                    category_sources += len(sources)
            
            if category_channels > 0:
                print(f"  ğŸ“º {category}: {category_channels}é¢‘é“, {category_sources}æº")
                total_channels += category_channels
                total_sources += category_sources
        
        print("-"*50)
        print(f"ğŸ“Š æ€»è®¡: {total_channels}é¢‘é“, {total_sources}æº")
        
        # ç»Ÿè®¡æ— æºçš„é¢‘é“
        no_source_channels = []
        for category, channels in final_data.items():
            for channel, sources in channels.items():
                if not sources:
                    no_source_channels.append(f"{category}-{channel}")
        
        if no_source_channels:
            print(f"âš ï¸  æ— æºé¢‘é“: {len(no_source_channels)}ä¸ª")
            if len(no_source_channels) <= 5:
                for channel in no_source_channels:
                    print(f"    âŒ {channel}")

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_dir = Path(self.temp_dir)
            if temp_dir.exists():
                for file in temp_dir.iterdir():
                    if file.is_file():
                        try:
                            file.unlink()
                        except:
                            pass
        except:
            pass

    def run(self):
        """ä¸»è¿è¡Œå‡½æ•°"""
        print("=" * 50)
        print("ğŸ¬ IPTVæ™ºèƒ½ç®¡ç†å·¥å…· - æ ¸å¿ƒåŠŸèƒ½ç‰ˆ v2.2")
        print("ğŸ”§ æ™ºèƒ½æµ‹é€Ÿä¼˜åŒ– (FFmpeg:10ç§’æµ‹è¯•+10ç§’è¶…æ—¶)")
        print("=" * 50)
        
        start_time = time.time()
        
        try:
            # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶
            template_path = Path(self.template_file)
            if not template_path.exists():
                print("ğŸ“ æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹æ¨¡æ¿...")
                if self.create_demo_template():
                    print(f"\nğŸ’¡ æ¨¡æ¿æ–‡ä»¶å·²åˆ›å»ºï¼Œè¯·ç¼–è¾‘åé‡æ–°è¿è¡Œ:")
                    print(f"   ğŸ“„ {template_path.absolute()}")
                    input("æŒ‰å›è½¦é”®é€€å‡º...")
                return
            
            # 1. åŠ è½½æ¨¡æ¿
            print("\nğŸ“‹ æ­¥éª¤ 1/6: åŠ è½½é¢‘é“æ¨¡æ¿")
            template_categories = self.load_template()
            if not template_categories:
                return
            
            # 2. è·å–æºæ•°æ®
            print("\nğŸŒ æ­¥éª¤ 2/6: è·å–æºæ•°æ®")
            content = self.fetch_all_streams()
            if not content:
                print("âŒ æœªèƒ½è·å–ä»»ä½•æºæ•°æ®")
                return
            
            # 3. æ•´ç†æºæ•°æ®
            print("\nğŸ”§ æ­¥éª¤ 3/6: æ•´ç†æºæ•°æ®")
            sources_df = self.organize_streams(content)
            if sources_df.empty:
                print("âŒ æœªèƒ½è§£æå‡ºæœ‰æ•ˆçš„æµæ•°æ®")
                return
            
            # 4. è·å–æ‰€æœ‰æ¨¡æ¿é¢‘é“
            all_template_channels = []
            for channels in template_categories.values():
                all_template_channels.extend(channels)
            
            # 5. é¢‘é“åŒ¹é…
            print("\nğŸ¯ æ­¥éª¤ 4/6: é¢‘é“åŒ¹é…")
            filtered_df = self.filter_and_sort_sources(sources_df, all_template_channels)
            if filtered_df.empty:
                print("âŒ æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æ¨¡æ¿é¢‘é“")
                return
            
            # 6. æµ‹é€Ÿ
            print("\nâš¡ æ­¥éª¤ 5/6: æºæµ‹é€Ÿ")
            speed_tested_df = self.speed_test_sources(filtered_df)
            if speed_tested_df.empty:
                print("âŒ æ²¡æœ‰å¯ç”¨çš„æºé€šè¿‡æµ‹é€Ÿ")
                return
            
            # 7. ç”Ÿæˆæœ€ç»ˆæ•°æ®
            print("\nğŸ¨ æ­¥éª¤ 6/6: ç”Ÿæˆæ’­æ”¾åˆ—è¡¨")
            final_data = self.generate_final_data(speed_tested_df, template_categories)
            
            # 8. ä¿å­˜æ–‡ä»¶
            if not self.save_output_files(final_data):
                print("âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥")
                return
            
            # 9. æ‰“å°ç»Ÿè®¡
            self.print_statistics(final_data)
            
            end_time = time.time()
            elapsed_time = end_time - start_time
            
            print("\nğŸ‰ å¤„ç†å®Œæˆ!")
            print(f"â° æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
            print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶:")
            print(f"   ğŸ“„ {Path(self.output_txt).absolute()}")
            print(f"   ğŸ“„ {Path(self.output_m3u).absolute()}")
                
        except KeyboardInterrupt:
            print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        except Exception as e:
            print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        finally:
            self.cleanup()

def main():
    """ä¸»å‡½æ•°"""
    try:
        manager = IPTVManager()
        manager.run()
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
