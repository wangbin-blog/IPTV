#!/usr/bin/env python3
"""
ğŸ¬ IPTVæ™ºèƒ½ç®¡ç†å·¥å…· - GitHub Actions ä¼˜åŒ–ç‰ˆ v6.1
æµç¨‹ï¼šæ™ºèƒ½æŠ“å– â†’ ç²¾å‡†æµ‹é€Ÿ â†’ æ¨¡æ¿åŒ¹é… â†’ ç”Ÿæˆæ–‡ä»¶
ç‰¹ç‚¹ï¼šä¼˜åŒ–æŠ“å–ç­–ç•¥ + ç²¾å‡†æµ‹é€Ÿç®—æ³• + æ™ºèƒ½è¿‡æ»¤æœºåˆ¶ + å…¨é¢è´¨é‡æ§åˆ¶
"""

import requests
import pandas as pd
import re
import os
import time
import subprocess
import sys
import threading
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
from pathlib import Path
import shutil
from dataclasses import dataclass
from enum import Enum
from typing import List, Dict, Any, Optional, Tuple, Union, Callable
from contextlib import contextmanager
import signal


# ==================== æ ¸å¿ƒæ•°æ®ç±»å‹ ====================

class StreamType(Enum):
    """æµåª’ä½“ç±»å‹æšä¸¾"""
    M3U8 = "m3u8"
    TS = "ts"
    FLV = "flv"
    MP4 = "mp4"
    RTMP = "rtmp"
    RTSP = "rtsp"
    UNKNOWN = "unknown"


@dataclass
class StreamInfo:
    """æµä¿¡æ¯æ•°æ®ç±»"""
    program_name: str
    stream_url: str
    group: str = "é»˜è®¤åˆ†ç»„"
    original_name: str = ""
    match_score: int = 0
    accessible: bool = False
    speed: float = float('inf')
    stream_type: StreamType = StreamType.UNKNOWN
    last_tested: float = 0
    content_type: str = ""
    file_size: int = 0


@dataclass
class SpeedTestResult:
    """æµ‹é€Ÿç»“æœæ•°æ®ç±»"""
    url: str
    accessible: bool = False
    speed: float = float('inf')
    stream_type: StreamType = StreamType.UNKNOWN
    error_message: str = ""
    content_type: str = ""
    file_size: int = 0
    response_code: int = 0
    last_tested: float = 0


@dataclass
class ProcessingStats:
    """å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
    sources_fetched: int = 0
    streams_parsed: int = 0
    channels_matched: int = 0
    sources_tested: int = 0
    sources_available: int = 0
    errors_encountered: int = 0
    categories_processed: int = 0
    channels_with_sources: int = 0
    total_sources_found: int = 0
    quality_filtered: int = 0
    speed_filtered: int = 0


# ==================== é…ç½®ç®¡ç†ç³»ç»Ÿ ====================

class GitHubConfigManager:
    """GitHub Actions ä¸“ç”¨é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self):
        # æ–‡ä»¶é…ç½®
        self.template_file: str = "demo.txt"
        self.output_txt: str = "iptv.txt"
        self.output_m3u: str = "iptv.m3u"
        self.temp_dir: str = "temp"
        self.cache_dir: str = "cache"
        self.backup_dir: str = "backup"
        
        # GitHubç¯å¢ƒä¼˜åŒ–é…ç½®
        self.request_timeout: int = 12
        self.request_retries: int = 2
        self.max_workers: int = 8  # GitHub Actionsé™åˆ¶
        self.connection_pool_size: int = 10
        
        # æ™ºèƒ½æŠ“å–é…ç½®
        self.enable_smart_crawling: bool = True
        self.crawling_batch_size: int = 5
        self.source_priority: Dict[str, int] = {
            "github.com": 10,
            "raw.githubusercontent.com": 9,
            "gitee.com": 8,
            "mirror.ghproxy.com": 7
        }
        
        # æµ‹é€Ÿé…ç½® - GitHubç¯å¢ƒä¼˜åŒ–
        self.open_speed_test: bool = True
        self.speed_test_limit: int = 6  # å‡å°‘å¹¶å‘é¿å…é™åˆ¶
        self.speed_test_timeout: int = 8
        self.enable_smart_speed_test: bool = True
        self.speed_test_strategy: str = "conservative"  # GitHubç¯å¢ƒä½¿ç”¨ä¿å®ˆç­–ç•¥
        
        # è¿‡æ»¤é…ç½®
        self.open_filter_speed: bool = True
        self.min_speed: float = 0.5
        self.max_speed: float = 12.0
        self.enable_quality_filter: bool = True
        self.min_content_length: int = 1024
        self.max_content_length: int = 5242880  # 5MB
        
        # å†…å®¹ç±»å‹è¿‡æ»¤
        self.allowed_content_types: List[str] = [
            "video/", "audio/", "application/", "text/",
            "octet-stream", "x-mpegurl", "mpegurl"
        ]
        self.blocked_content_types: List[str] = [
            "text/html", "application/json", "text/plain"
        ]
        
        # åŸŸåè¿‡æ»¤
        self.blocked_domains: List[str] = [
            "example.com", "localhost", "127.0.0.1",
            "test.com", "dummy.com"
        ]
        
        # åŒ¹é…é…ç½®
        self.similarity_threshold: int = 50
        self.max_sources_per_channel: int = 5  # å‡å°‘æºæ•°é‡
        self.enable_fuzzy_matching: bool = True
        self.matching_confidence: float = 0.7
        
        # è´¨é‡æ§åˆ¶
        self.enable_quality_control: bool = True
        self.min_stream_size: int = 512
        self.max_url_length: int = 350
        
        # æ€§èƒ½ä¼˜åŒ–
        self.enable_caching: bool = True
        self.cache_ttl: int = 1800  # 30åˆ†é’Ÿç¼“å­˜
        self.enable_compression: bool = True
        
        # æ˜¾ç¤ºé…ç½® - GitHubç¯å¢ƒå‡å°‘è¾“å‡º
        self.progress_bar_width: int = 30
        self.show_detailed_stats: bool = True
        self.enable_real_time_stats: bool = False  # GitHub Actionsä¸­å…³é—­å®æ—¶ç»Ÿè®¡
        
        # ä¼˜åŒ–çš„æºURLåˆ—è¡¨ - é€‰æ‹©ç¨³å®šæ€§é«˜çš„æº
        self.source_urls: List[str] = [
            # é«˜ç¨³å®šæ€§æº
            "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/global.m3u",
            "https://iptv-org.github.io/iptv/index.nsfw.m3u",
            "https://raw.githubusercontent.com/iptv-org/iptv/master/streams/cn.m3u",
            
            # å¤‡ç”¨æº
            "https://mirror.ghproxy.com/https://raw.githubusercontent.com/zhanghongchen/iptv/main/ç›´æ’­.txt",
            "https://raw.githubusercontent.com/YanG-1989/m3u/main/Gather.m3u",
        ]
        
        # HTTPè¯·æ±‚å¤´é…ç½®
        self.headers: Dict[str, str] = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 GitHub-Actions-IPTV',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache'
        }


# ==================== è¿›åº¦æ˜¾ç¤ºç®¡ç†å™¨ ====================

class ProgressDisplay:
    """è¿›åº¦æ˜¾ç¤ºç®¡ç†å™¨ - GitHub Actionsä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        self.start_time: Optional[float] = None
        self.current_step: int = 0
        self.total_steps: int = 0
        self.step_names: List[str] = []
        self.step_start_time: Optional[float] = None
    
    def start_progress(self, step_names: List[str]) -> None:
        """å¼€å§‹è¿›åº¦è·Ÿè¸ª"""
        self.step_names = step_names
        self.total_steps = len(step_names)
        self.current_step = 0
        self.start_time = time.time()
        self._print_header()
    
    def next_step(self, message: str = "") -> None:
        """è¿›å…¥ä¸‹ä¸€æ­¥"""
        if self.step_start_time:
            step_time = time.time() - self.step_start_time
            logging.info(f"æ­¥éª¤ {self.current_step} è€—æ—¶: {step_time:.2f}ç§’")
        
        self.current_step += 1
        if self.current_step <= self.total_steps:
            step_name = self.step_names[self.current_step - 1]
            self.step_start_time = time.time()
            self._print_step(step_name, message)
    
    def update_substep(self, message: str, symbol: str = "ğŸ”¹") -> None:
        """æ›´æ–°å­æ­¥éª¤è¿›åº¦"""
        elapsed = time.time() - (self.start_time or time.time())
        print(f"  {symbol} [{elapsed:6.1f}s] {message}")
    
    def _print_header(self) -> None:
        """æ‰“å°è¿›åº¦å¤´"""
        print("\n" + "="*60)
        print("ğŸ¬ IPTVæ™ºèƒ½ç®¡ç†å·¥å…· - GitHub Actionsä¼˜åŒ–ç‰ˆ v6.1")
        print("ğŸ”§ æµç¨‹: æ™ºèƒ½æŠ“å– â†’ ç²¾å‡†æµ‹é€Ÿ â†’ æ¨¡æ¿åŒ¹é… â†’ ç”Ÿæˆæ–‡ä»¶")
        print("="*60)
    
    def _print_step(self, step_name: str, message: str) -> None:
        """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
        elapsed = time.time() - (self.start_time or time.time())
        print(f"\nğŸ“‹ æ­¥éª¤ {self.current_step}/{self.total_steps}: {step_name}")
        if message:
            print(f"   ğŸ“ {message}")
        print(f"   â° æ€»ç”¨æ—¶: {elapsed:.1f}ç§’")


# ==================== æ™ºèƒ½æµ‹é€Ÿå¼•æ“ ====================

class SmartSpeedTestEngine:
    """æ™ºèƒ½æµ‹é€Ÿå¼•æ“æ ¸å¿ƒç±» - GitHub Actionsä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, config: GitHubConfigManager):
        self.config = config
        self.session = self._create_session()
        self._stop_event = threading.Event()
        self._patterns = self._compile_patterns()
        self._cache: Dict[str, SpeedTestResult] = {}
        self._stats = {
            'total_tests': 0,
            'successful_tests': 0,
            'failed_tests': 0,
            'average_speed': 0.0
        }
    
    def _create_session(self) -> requests.Session:
        """åˆ›å»ºä¼˜åŒ–çš„HTTPä¼šè¯"""
        session = requests.Session()
        session.headers.update(self.config.headers)
        
        # ä¼˜åŒ–è¿æ¥é€‚é…å™¨
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=self.config.connection_pool_size,
            pool_maxsize=self.config.connection_pool_size,
            max_retries=2,
            pool_block=False
        )
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        
        return session
    
    def _compile_patterns(self) -> Dict[str, re.Pattern]:
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        return {
            'stream_protocol': re.compile(r'^(https?|rtmp|rtsp)://', re.IGNORECASE),
            'domain_extract': re.compile(r'://([^/]+)')
        }
    
    def stop(self) -> None:
        """åœæ­¢æµ‹é€Ÿ"""
        self._stop_event.set()
        self.session.close()
    
    def _detect_stream_type(self, url: str) -> StreamType:
        """æ™ºèƒ½æ£€æµ‹æµåª’ä½“ç±»å‹"""
        if not url:
            return StreamType.UNKNOWN
        
        url_lower = url.lower()
        
        # ç²¾ç¡®åŒ¹é…æµåª’ä½“ç±»å‹
        if '.m3u8' in url_lower or 'm3u8' in url_lower:
            return StreamType.M3U8
        elif '.ts' in url_lower or 'ts' in url_lower:
            return StreamType.TS
        elif '.flv' in url_lower or 'flv' in url_lower:
            return StreamType.FLV
        elif '.mp4' in url_lower or 'mp4' in url_lower:
            return StreamType.MP4
        elif url_lower.startswith('rtmp://'):
            return StreamType.RTMP
        elif url_lower.startswith('rtsp://'):
            return StreamType.RTSP
        else:
            # åŸºäºå†…å®¹ç±»å‹æ¨æ–­
            return StreamType.UNKNOWN
    
    def _is_blocked_domain(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºè¢«é˜»æ­¢çš„åŸŸå"""
        try:
            domain_match = self._patterns['domain_extract'].search(url)
            if domain_match:
                domain = domain_match.group(1).lower()
                for blocked in self.config.blocked_domains:
                    if blocked in domain:
                        return True
        except Exception:
            pass
        return False
    
    def _is_allowed_content_type(self, content_type: str) -> bool:
        """æ£€æŸ¥å†…å®¹ç±»å‹æ˜¯å¦å…è®¸"""
        if not content_type:
            return True
            
        content_type_lower = content_type.lower()
        
        # æ£€æŸ¥é˜»æ­¢çš„å†…å®¹ç±»å‹
        for blocked_type in self.config.blocked_content_types:
            if blocked_type in content_type_lower:
                return False
        
        # æ£€æŸ¥å…è®¸çš„å†…å®¹ç±»å‹
        for allowed_type in self.config.allowed_content_types:
            if allowed_type in content_type_lower:
                return True
        
        return False
    
    def _adaptive_speed_test(self, url: str) -> Tuple[bool, float, str, int]:
        """è‡ªé€‚åº”æµ‹é€Ÿç­–ç•¥"""
        try:
            start_time = time.time()
            
            # æ ¹æ®URLç±»å‹é€‰æ‹©æµ‹é€Ÿç­–ç•¥
            if any(proto in url.lower() for proto in ['.m3u8', '.ts', '.flv']):
                # æµåª’ä½“ä½¿ç”¨HEADè¯·æ±‚å¿«é€Ÿæ£€æµ‹
                response = self.session.head(
                    url, 
                    timeout=self.config.speed_test_timeout,
                    allow_redirects=True
                )
            else:
                # å…¶ä»–ç±»å‹ä½¿ç”¨GETè¯·æ±‚éƒ¨åˆ†å†…å®¹
                response = self.session.get(
                    url,
                    timeout=self.config.speed_test_timeout,
                    allow_redirects=True,
                    stream=True
                )
            
            end_time = time.time()
            response_time = end_time - start_time
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code in [200, 206, 302, 301, 307]:
                content_type = response.headers.get('Content-Type', '')
                content_length = int(response.headers.get('Content-Length', 0))
                
                # éªŒè¯å†…å®¹ç±»å‹
                if not self._is_allowed_content_type(content_type):
                    response.close()
                    return False, float('inf'), content_type, content_length
                
                response.close()
                return True, response_time, content_type, content_length
            else:
                response.close()
                return False, float('inf'), '', 0
                
        except requests.exceptions.Timeout:
            return False, float('inf'), '', 0
        except requests.exceptions.ConnectionError:
            return False, float('inf'), '', 0
        except requests.exceptions.RequestException as e:
            logging.debug(f"æµ‹é€Ÿè¯·æ±‚å¼‚å¸¸: {url} - {e}")
            return False, float('inf'), '', 0
        except Exception as e:
            logging.debug(f"æµ‹é€ŸæœªçŸ¥å¼‚å¸¸: {url} - {e}")
            return False, float('inf'), '', 0
    
    def test_single_url(self, url: str) -> SpeedTestResult:
        """æµ‹è¯•å•ä¸ªURL - æ™ºèƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        if self._stop_event.is_set():
            return SpeedTestResult(url=url, accessible=False)
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"test_{hash(url) & 0xFFFFFFFF}"
        if self.config.enable_caching and cache_key in self._cache:
            cached_result = self._cache[cache_key]
            if time.time() - cached_result.last_tested < self.config.cache_ttl:
                return cached_result
        
        result = SpeedTestResult(url=url)
        self._stats['total_tests'] += 1
        
        # æ£€æŸ¥è¢«é˜»æ­¢çš„åŸŸå
        if self._is_blocked_domain(url):
            result.accessible = False
            result.error_message = "åŸŸåè¢«é˜»æ­¢"
            return result
        
        try:
            # æ‰§è¡Œè‡ªé€‚åº”æµ‹é€Ÿ
            accessible, speed, content_type, file_size = self._adaptive_speed_test(url)
            
            result.accessible = accessible
            result.speed = speed
            result.content_type = content_type
            result.file_size = file_size
            result.stream_type = self._detect_stream_type(url)
            result.last_tested = time.time()
            
            if accessible:
                self._stats['successful_tests'] += 1
                # æ›´æ–°å¹³å‡é€Ÿåº¦
                total_speed = self._stats['average_speed'] * (self._stats['successful_tests'] - 1)
                self._stats['average_speed'] = (total_speed + speed) / self._stats['successful_tests']
            else:
                self._stats['failed_tests'] += 1
                result.error_message = "æµ‹é€Ÿå¤±è´¥"
                
        except Exception as e:
            result.accessible = False
            result.error_message = str(e)
            self._stats['failed_tests'] += 1
        
        # ç¼“å­˜ç»“æœ
        if self.config.enable_caching:
            self._cache[cache_key] = result
        
        return result
    
    def batch_speed_test(self, urls: List[str], 
                        progress_callback: Callable = None) -> Dict[str, SpeedTestResult]:
        """æ‰¹é‡æµ‹é€Ÿ - æ™ºèƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        if not self.config.open_speed_test:
            # å¦‚æœæµ‹é€Ÿå…³é—­ï¼Œè¿”å›æ‰€æœ‰URLä¸ºå¯è®¿é—®
            return {url: SpeedTestResult(url=url, accessible=True) for url in urls}
        
        self._stop_event.clear()
        results = {}
        
        logging.info(f"ğŸš€ å¼€å§‹æ‰¹é‡æµ‹é€Ÿï¼Œå…± {len(urls)} ä¸ªURLï¼Œå¹¶å‘æ•°: {self.config.speed_test_limit}")
        
        def test_with_callback(url: str) -> Tuple[str, SpeedTestResult]:
            if self._stop_event.is_set():
                return url, SpeedTestResult(url=url, accessible=False)
            
            result = self.test_single_url(url)
            if progress_callback:
                progress_callback(url, result)
            return url, result
        
        try:
            # æ™ºèƒ½åˆ†æ‰¹æµ‹é€Ÿ
            with ThreadPoolExecutor(max_workers=self.config.speed_test_limit) as executor:
                # GitHubç¯å¢ƒä½¿ç”¨ä¿å®ˆç­–ç•¥
                batch_size = 20
                
                total_urls = len(urls)
                
                for i in range(0, total_urls, batch_size):
                    if self._stop_event.is_set():
                        break
                        
                    batch_urls = urls[i:i + batch_size]
                    future_to_url = {
                        executor.submit(test_with_callback, url): url 
                        for url in batch_urls
                    }
                    
                    for future in as_completed(future_to_url):
                        if self._stop_event.is_set():
                            break
                        try:
                            url, result = future.result(timeout=self.config.speed_test_timeout + 10)
                            results[url] = result
                        except Exception as e:
                            url = future_to_url[future]
                            results[url] = SpeedTestResult(
                                url=url, 
                                accessible=False, 
                                error_message=str(e)
                            )
                        
        except Exception as e:
            logging.error(f"âŒ æ‰¹é‡æµ‹é€Ÿå¤±è´¥: {e}")
        
        # è¾“å‡ºæµ‹é€Ÿç»Ÿè®¡
        success_rate = (self._stats['successful_tests'] / self._stats['total_tests'] * 100) if self._stats['total_tests'] > 0 else 0
        logging.info(f"ğŸ“Š æµ‹é€Ÿç»Ÿè®¡: æˆåŠŸ {self._stats['successful_tests']}/{self._stats['total_tests']} ({success_rate:.1f}%)ï¼Œå¹³å‡é€Ÿåº¦: {self._stats['average_speed']:.2f}s")
        
        return results


# ==================== IPTVæ™ºèƒ½ç®¡ç†å™¨ ====================

class IPTVManager:
    """IPTVæ™ºèƒ½ç®¡ç†å·¥å…·æ ¸å¿ƒç±» - GitHub Actionsä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, config: GitHubConfigManager = None) -> None:
        # æ£€æŸ¥æ˜¯å¦åœ¨GitHub Actionsç¯å¢ƒä¸­
        if os.getenv('GITHUB_ACTIONS'):
            self.config: GitHubConfigManager = GitHubConfigManager()
            print("ğŸƒ æ£€æµ‹åˆ°GitHub Actionsç¯å¢ƒï¼Œä½¿ç”¨ä¼˜åŒ–é…ç½®")
        else:
            self.config: GitHubConfigManager = config or GitHubConfigManager()
            
        self.stats: ProcessingStats = ProcessingStats()
        self.progress: ProgressDisplay = ProgressDisplay()
        self.speed_engine: SmartSpeedTestEngine = SmartSpeedTestEngine(self.config)
        self._is_running: bool = True
        self._patterns: Dict[str, re.Pattern] = self._compile_patterns()
        self._setup_environment()
        self._setup_signal_handlers()
        
    def _setup_environment(self) -> None:
        """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
        try:
            directories = [self.config.temp_dir, self.config.cache_dir, self.config.backup_dir]
            for directory in directories:
                Path(directory).mkdir(exist_ok=True)
            logging.info("âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ")
        except Exception as e:
            logging.error(f"âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
            raise

    def _compile_patterns(self) -> Dict[str, re.Pattern]:
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        return {
            'extinf': re.compile(r'#EXTINF:.*?tvg-name="([^"]+)".*?,(.+)', re.IGNORECASE),
            'category': re.compile(r'^(.*?),#genre#$', re.IGNORECASE),
            'url': re.compile(r'https?://[^\s,]+', re.IGNORECASE),
            'tvg_name': re.compile(r'tvg-name="([^"]*)"', re.IGNORECASE),
            'tvg_id': re.compile(r'tvg-id="([^"]*)"', re.IGNORECASE),
            'group_title': re.compile(r'group-title="([^"]*)"', re.IGNORECASE),
            'extinf_content': re.compile(r',\s*(.+)$', re.IGNORECASE),
            'channel_code': re.compile(r'([A-Z]+)-?(\d+)', re.IGNORECASE),
            'quality_suffix': re.compile(r'\s+(HD|FHD|4K|8K|é«˜æ¸…|è¶…æ¸…|ç›´æ’­|LIVE|é¢‘é“|TV)', re.IGNORECASE),
            'brackets': re.compile(r'[\[\(\{].*?[\]\)\}]'),
            'whitespace': re.compile(r'\s+'),
            'special_chars': re.compile(r'[^\w\u4e00-\u9fa5\s-]'),
            'domain_extract': re.compile(r'://([^/:]+)')
        }

    def _setup_signal_handlers(self) -> None:
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            logging.info(f"ğŸ›‘ æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
            self._is_running = False
            self.cleanup()
            sys.exit(0)
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

    def _print_progress_bar(self, current: int, total: int, prefix: str = "", suffix: str = "") -> None:
        """æ‰“å°è¿›åº¦æ¡"""
        if total == 0:
            return
            
        percent = current / total
        filled_length = int(self.config.progress_bar_width * percent)
        bar = 'â–ˆ' * filled_length + 'â–‘' * (self.config.progress_bar_width - filled_length)
        percent_display = f"{percent:.1%}"
        
        print(f"\r{prefix} |{bar}| {current}/{total} {percent_display} {suffix}", end='', flush=True)
        
        if current == total:
            print()

    def validate_url(self, url: str) -> bool:
        """éªŒè¯URLæ ¼å¼å’Œå®‰å…¨æ€§ - å¢å¼ºç‰ˆæœ¬"""
        if not url or not isinstance(url, str) or len(url) > self.config.max_url_length:
            return False
        
        try:
            result = urlparse(url)
            if not all([result.scheme, result.netloc]):
                return False
            
            # æ£€æŸ¥åè®®
            if result.scheme not in ['http', 'https', 'rtmp', 'rtsp']:
                return False
            
            # æ£€æŸ¥è·¯å¾„å®‰å…¨æ€§
            if any(char in result.path for char in ['//', '\\', '../']):
                return False
            
            # æ£€æŸ¥è¢«é˜»æ­¢çš„åŸŸå
            domain = result.netloc.lower()
            for blocked in self.config.blocked_domains:
                if blocked in domain:
                    return False
            
            return True
            
        except Exception:
            return False

    def _get_url_priority(self, url: str) -> int:
        """è·å–URLä¼˜å…ˆçº§"""
        for domain, priority in self.config.source_priority.items():
            if domain in url:
                return priority
        return 5  # é»˜è®¤ä¼˜å…ˆçº§

    @contextmanager
    def _request_context(self, url: str, timeout: int = None):
        """è¯·æ±‚ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        timeout = timeout or self.config.request_timeout
        start_time = time.time()
        response = None
        try:
            response = self.speed_engine.session.get(
                url, 
                timeout=timeout, 
                stream=True, 
                allow_redirects=True
            )
            yield response
        finally:
            if response:
                response.close()
            elapsed = time.time() - start_time
            logging.debug(f"è¯·æ±‚ {url} è€—æ—¶: {elapsed:.2f}ç§’")

    def fetch_streams_from_url(self, url: str) -> Optional[str]:
        """ä»URLè·å–æµæ•°æ® - æ™ºèƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        if not self.validate_url(url):
            logging.debug(f"âŒ æ— æ•ˆçš„URL: {url}")
            return None
        
        # æ ¹æ®ä¼˜å…ˆçº§è°ƒæ•´è¶…æ—¶æ—¶é—´
        priority = self._get_url_priority(url)
        base_timeout = max(5, self.config.request_timeout - (priority - 5))
        
        for attempt in range(self.config.request_retries):
            if not self._is_running:
                return None
            try:
                # æ™ºèƒ½è¶…æ—¶è°ƒæ•´
                timeout = base_timeout + (attempt * 5)
                with self._request_context(url, timeout) as response:
                    if response.status_code == 200:
                        # æµå¼è¯»å–ï¼Œå†…å­˜ä¼˜åŒ–
                        content_chunks = []
                        total_size = 0
                        for chunk in response.iter_content(chunk_size=16384):  # å¢å¤§å—å¤§å°
                            if not self._is_running:
                                return None
                            content_chunks.append(chunk)
                            total_size += len(chunk)
                            # æ™ºèƒ½å¤§å°æ§åˆ¶
                            if total_size > self.config.max_content_length:
                                logging.info(f"ğŸ“¦ å†…å®¹è¿‡å¤§({total_size}å­—èŠ‚)ï¼Œæˆªæ–­å¤„ç†: {url}")
                                break
                        
                        content = b''.join(content_chunks).decode('utf-8', errors='ignore')
                        if len(content) >= self.config.min_stream_size:
                            self.stats.sources_fetched += 1
                            logging.debug(f"âœ… æˆåŠŸæŠ“å–: {url} ({len(content)}å­—èŠ‚)")
                            return content
                        else:
                            logging.debug(f"ğŸ“ å†…å®¹è¿‡å°: {url} ({len(content)}å­—èŠ‚)")
                            return None
                    elif response.status_code == 429:  # é¢‘ç‡é™åˆ¶
                        wait_time = (attempt + 1) * 10
                        logging.info(f"â³ é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’: {url}")
                        time.sleep(wait_time)
                        continue
                    elif response.status_code >= 500:  # æœåŠ¡å™¨é”™è¯¯
                        logging.warning(f"ğŸ”§ æœåŠ¡å™¨é”™è¯¯ {response.status_code}ï¼Œé‡è¯•: {url}")
                        time.sleep((attempt + 1) * 3)
                        continue
                    else:
                        logging.debug(f"âŒ HTTP {response.status_code}: {url}")
                        return None
            except requests.exceptions.Timeout:
                logging.debug(f"â° è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}): {url}")
                if attempt < self.config.request_retries - 1:
                    time.sleep((attempt + 1) * 2)
                continue
            except requests.exceptions.ConnectionError:
                logging.debug(f"ğŸ”Œ è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}): {url}")
                if attempt < self.config.request_retries - 1:
                    time.sleep((attempt + 1) * 3)
                continue
            except Exception as e:
                logging.debug(f"âŒ è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}): {url} - {e}")
                if attempt < self.config.request_retries - 1:
                    time.sleep((attempt + 1) * 2)
        return None

    def fetch_all_streams(self) -> str:
        """è·å–æ‰€æœ‰æºçš„æµæ•°æ® - æ™ºèƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        self.progress.update_substep("å¯åŠ¨æ™ºèƒ½å¤šæºæŠ“å–...", "ğŸŒ")
        
        if not self.config.source_urls:
            logging.error("âŒ æ²¡æœ‰é…ç½®æºURL")
            return ""
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºURL
        sorted_urls = sorted(
            self.config.source_urls,
            key=self._get_url_priority,
            reverse=True
        )
        
        all_streams: List[str] = []
        successful_sources = 0
        
        print("   æŠ“å–è¿›åº¦: ", end="", flush=True)
        
        try:
            # æ™ºèƒ½åˆ†æ‰¹æŠ“å–
            with ThreadPoolExecutor(max_workers=min(self.config.max_workers, len(sorted_urls))) as executor:
                # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å†…å­˜å³°å€¼
                batch_size = self.config.crawling_batch_size
                
                for batch_start in range(0, len(sorted_urls), batch_size):
                    if not self._is_running:
                        break
                        
                    batch_urls = sorted_urls[batch_start:batch_start + batch_size]
                    future_to_url = {
                        executor.submit(self.fetch_streams_from_url, url): url 
                        for url in batch_urls
                    }
                    
                    for future in as_completed(future_to_url):
                        if not self._is_running:
                            break
                        url = future_to_url[future]
                        try:
                            content = future.result(timeout=self.config.request_timeout + 20)
                            if content:
                                all_streams.append(content)
                                successful_sources += 1
                                print("âœ…", end="", flush=True)
                            else:
                                print("âŒ", end="", flush=True)
                        except Exception as e:
                            logging.debug(f"æŠ“å–å¤±è´¥: {url} - {e}")
                            print("ğŸ’¥", end="", flush=True)
                        
                        # å®æ—¶è¿›åº¦æ›´æ–°
                        current_total = batch_start + len(future_to_url)
                        self._print_progress_bar(
                            current_total, 
                            len(sorted_urls), 
                            "   æŠ“å–è¿›åº¦", 
                            f"{successful_sources}æˆåŠŸ"
                        )
        
        except Exception as e:
            logging.error(f"âŒ å¹¶å‘è·å–å¤±è´¥: {e}")
            return ""
        
        print()
        total_content = "\n".join(all_streams)
        
        # å†…å®¹å»é‡å’Œä¼˜åŒ–
        if self.config.enable_compression:
            lines = total_content.splitlines()
            unique_lines = list(dict.fromkeys(lines))  # ä¿æŒé¡ºåºçš„å»é‡
            total_content = "\n".join(unique_lines)
        
        self.progress.update_substep(
            f"æŠ“å–å®Œæˆ: {successful_sources}/{len(sorted_urls)} ä¸ªæº, " 
            f"æ€»æ•°æ®: {len(total_content)} å­—ç¬¦, "
            f"å»é‡å: {len(total_content.splitlines())} è¡Œ", 
            "âœ…"
        )
        
        return total_content

    def _extract_program_name(self, extinf_line: str) -> str:
        """ä»EXTINFè¡Œæå–èŠ‚ç›®åç§° - å¢å¼ºç‰ˆæœ¬"""
        if not extinf_line.startswith('#EXTINF'):
            return "æœªçŸ¥é¢‘é“"
        try:
            # ä¼˜å…ˆä½¿ç”¨tvg-name
            tvg_match = self._patterns['tvg_name'].search(extinf_line)
            if tvg_match and tvg_match.group(1).strip():
                return tvg_match.group(1).strip()
            
            # å…¶æ¬¡ä½¿ç”¨é€—å·åçš„å†…å®¹
            content_match = self._patterns['extinf_content'].search(extinf_line)
            if content_match and content_match.group(1).strip():
                name = content_match.group(1).strip()
                # æ™ºèƒ½æ¸…ç†åç§°
                name = self._patterns['brackets'].sub('', name)
                name = self._patterns['quality_suffix'].sub('', name)
                name = self._patterns['whitespace'].sub(' ', name).strip()
                return name if name and name != "æœªçŸ¥é¢‘é“" else "æœªçŸ¥é¢‘é“"
        except Exception as e:
            logging.debug(f"åç§°æå–å¤±è´¥: {extinf_line} - {e}")
        return "æœªçŸ¥é¢‘é“"

    def parse_m3u(self, content: str) -> List[StreamInfo]:
        """è§£æM3Uæ ¼å¼å†…å®¹ - ä¼˜åŒ–ç‰ˆæœ¬"""
        if not content:
            return []
        
        streams: List[StreamInfo] = []
        lines = content.splitlines()
        current_program: Optional[str] = None
        current_group = "é»˜è®¤åˆ†ç»„"
        
        i = 0
        while i < len(lines) and self._is_running:
            line = lines[i].strip()
            if not line:
                i += 1
                continue
                
            if line.startswith("#EXTINF"):
                current_program = self._extract_program_name(line)
                group_match = self._patterns['group_title'].search(line)
                current_group = group_match.group(1).strip() if group_match else "é»˜è®¤åˆ†ç»„"
                
                # æŸ¥æ‰¾å¯¹åº”çš„URL
                j = i + 1
                while j < len(lines):
                    next_line = lines[j].strip()
                    if next_line and not next_line.startswith('#'):
                        if self.validate_url(next_line):
                            streams.append(StreamInfo(
                                program_name=current_program,
                                stream_url=next_line,
                                group=current_group,
                                original_name=current_program
                            ))
                        i = j
                        break
                    j += 1
            elif line.startswith(('http://', 'https://', 'rtmp://', 'rtsp://')):
                # ç›´æ¥URLè¡Œ
                if self.validate_url(line):
                    streams.append(StreamInfo(
                        program_name="æœªçŸ¥é¢‘é“",
                        stream_url=line,
                        group="é»˜è®¤åˆ†ç»„",
                        original_name="æœªçŸ¥é¢‘é“"
                    ))
            i += 1
        return streams

    def parse_txt(self, content: str) -> List[StreamInfo]:
        """è§£æTXTæ ¼å¼å†…å®¹ - ä¼˜åŒ–ç‰ˆæœ¬"""
        if not content:
            return []
        
        streams: List[StreamInfo] = []
        
        for line_num, line in enumerate(content.splitlines(), 1):
            if not self._is_running:
                break
            line = line.strip()
            if not line or line.startswith('#') or '#genre#' in line:
                continue
            
            try:
                # æ™ºèƒ½åˆ†éš”ç¬¦æ£€æµ‹
                separators = [',', ' ', '\t', '|', '$', ';', 'ï¼š']
                for sep in separators:
                    if sep in line:
                        parts = line.split(sep, 1)
                        if len(parts) == 2:
                            program_name = parts[0].strip()
                            url_part = parts[1].strip()
                            url_match = self._patterns['url'].search(url_part)
                            if url_match and self.validate_url(url_match.group()):
                                streams.append(StreamInfo(
                                    program_name=program_name,
                                    stream_url=url_match.group(),
                                    group="é»˜è®¤åˆ†ç»„",
                                    original_name=program_name
                                ))
                                break
                        break
                else:
                    # æ²¡æœ‰åˆ†éš”ç¬¦ï¼Œç›´æ¥æŸ¥æ‰¾URL
                    url_match = self._patterns['url'].search(line)
                    if url_match and self.validate_url(url_match.group()):
                        program_name = line.replace(url_match.group(), '').strip()
                        streams.append(StreamInfo(
                            program_name=program_name or "æœªçŸ¥é¢‘é“",
                            stream_url=url_match.group(),
                            group="é»˜è®¤åˆ†ç»„",
                            original_name=program_name or "æœªçŸ¥é¢‘é“"
                        ))
            except Exception as e:
                logging.debug(f"è§£æè¡Œå¤±è´¥ {line_num}: {line} - {e}")
                continue
        return streams

    def organize_streams(self, content: str) -> pd.DataFrame:
        """æ•´ç†æµæ•°æ® - ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½è§£æ"""
        self.progress.update_substep("æ™ºèƒ½è§£ææµæ•°æ®...", "ğŸ”")
        
        if not content:
            logging.error("âŒ æ²¡æœ‰å†…å®¹å¯å¤„ç†")
            return pd.DataFrame()
            
        try:
            # æ ¹æ®å†…å®¹æ ¼å¼é€‰æ‹©è§£æå™¨
            if content.startswith("#EXTM3U"):
                streams = self.parse_m3u(content)
            else:
                streams = self.parse_txt(content)
            
            if not streams:
                logging.error("âŒ æœªèƒ½è§£æå‡ºä»»ä½•æµæ•°æ®")
                return pd.DataFrame()
                
            # è½¬æ¢ä¸ºDataFrame
            data = []
            for stream in streams:
                data.append({
                    'program_name': stream.program_name,
                    'stream_url': stream.stream_url,
                    'group': stream.group,
                    'original_name': stream.original_name,
                    'stream_type': stream.stream_type.value
                })
            
            df = pd.DataFrame(data)
            self.stats.streams_parsed = len(df)
            
            # æ™ºèƒ½æ•°æ®æ¸…ç†
            initial_count = len(df)
            
            # ç§»é™¤ç©ºå€¼
            df = df.dropna()
            
            # è¿‡æ»¤æ— æ•ˆåç§°å’ŒURL
            df = df[df['program_name'].str.len() > 0]
            df = df[df['stream_url'].str.len() > 0]
            
            # URLéªŒè¯
            df['url_valid'] = df['stream_url'].apply(self.validate_url)
            df = df[df['url_valid']].drop('url_valid', axis=1)
            
            # æ™ºèƒ½å»é‡
            df = df.drop_duplicates(subset=['program_name', 'stream_url'], keep='first')
            
            final_count = len(df)
            removed_count = initial_count - final_count
            
            self.progress.update_substep(
                f"è§£æå®Œæˆ: {initial_count} â†’ {final_count} ä¸ªæµ "
                f"(ç§»é™¤ {removed_count} ä¸ªæ— æ•ˆæ•°æ®)", 
                "âœ…"
            )
            
            return df
            
        except Exception as e:
            logging.error(f"âŒ æ•°æ®å¤„ç†é”™è¯¯: {e}")
            self.stats.errors_encountered += 1
            return pd.DataFrame()

    def speed_test_and_filter(self, sources_df: pd.DataFrame) -> pd.DataFrame:
        """æµ‹é€Ÿå’Œè¿‡æ»¤ - ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½æµ‹é€Ÿ"""
        self.progress.update_substep("å¯åŠ¨æ™ºèƒ½æµ‹é€Ÿ...", "â±ï¸")
        
        if sources_df.empty:
            logging.error("âŒ æ²¡æœ‰éœ€è¦æµ‹é€Ÿçš„æº")
            return pd.DataFrame()
            
        urls = sources_df['stream_url'].tolist()
        
        # è¿›åº¦å›è°ƒå‡½æ•°
        def progress_callback(url: str, result: SpeedTestResult):
            # å®æ—¶ç»Ÿè®¡æ›´æ–°
            pass
        
        # æ‰§è¡Œæ‰¹é‡æµ‹é€Ÿ
        results = self.speed_engine.batch_speed_test(urls, progress_callback)
        
        # å¤„ç†æµ‹é€Ÿç»“æœ
        speed_results = []
        accessible_count = 0
        
        print("   æµ‹é€Ÿè¿›åº¦: ", end="", flush=True)
        
        for i, (_, row) in enumerate(sources_df.iterrows()):
            if not self._is_running:
                break
                
            url = row['stream_url']
            result = results.get(url, SpeedTestResult(url=url, accessible=False))
            
            speed_results.append({
                'program_name': row['program_name'],
                'stream_url': url,
                'accessible': result.accessible,
                'speed': result.speed,
                'original_name': row.get('original_name', ''),
                'stream_type': result.stream_type.value,
                'content_type': result.content_type,
                'file_size': result.file_size
            })
            
            if result.accessible:
                accessible_count += 1
                # æ™ºèƒ½é€Ÿåº¦ç­‰çº§æ˜¾ç¤º
                if result.speed < 1.5: 
                    print("ğŸš€", end="", flush=True)  # æå¿«
                elif result.speed < 3: 
                    print("âš¡", end="", flush=True)  # å¿«é€Ÿ
                elif result.speed < 6: 
                    print("âœ…", end="", flush=True)  # å¯ç”¨
                elif result.speed < 10: 
                    print("ğŸ¢", end="", flush=True)  # æ…¢é€Ÿ
                else: 
                    print("ğŸ”´", end="", flush=True)  # è¶…æ…¢
            else:
                print("âŒ", end="", flush=True)  # ä¸å¯ç”¨
            
            # å®æ—¶è¿›åº¦æ›´æ–°
            if (i + 1) % 10 == 0 or (i + 1) == len(sources_df):
                self._print_progress_bar(i + 1, len(sources_df), "   æµ‹é€Ÿè¿›åº¦", f"{accessible_count}å¯ç”¨")
        
        print()
        
        try:
            result_df = pd.DataFrame(speed_results)
            
            # æ™ºèƒ½è¿‡æ»¤
            initial_count = len(result_df)
            accessible_df = result_df[result_df['accessible']].copy()
            
            if not accessible_df.empty:
                # åº”ç”¨æ™ºèƒ½é€Ÿç‡è¿‡æ»¤
                if self.config.open_filter_speed:
                    speed_filtered = accessible_df[
                        (accessible_df['speed'] >= self.config.min_speed) & 
                        (accessible_df['speed'] <= self.config.max_speed)
                    ]
                    speed_filtered_count = len(accessible_df) - len(speed_filtered)
                    self.stats.speed_filtered = speed_filtered_count
                    accessible_df = speed_filtered
                
                # åº”ç”¨è´¨é‡æ§åˆ¶è¿‡æ»¤
                if self.config.enable_quality_control:
                    quality_filtered = accessible_df[
                        (accessible_df['file_size'] >= self.config.min_content_length) & 
                        (accessible_df['file_size'] <= self.config.max_content_length)
                    ]
                    quality_filtered_count = len(accessible_df) - len(quality_filtered)
                    self.stats.quality_filtered = quality_filtered_count
                    accessible_df = quality_filtered
            
            self.stats.sources_tested = len(sources_df)
            self.stats.sources_available = len(accessible_df)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            avg_speed = accessible_df['speed'].mean() if not accessible_df.empty else 0
            total_filtered = initial_count - len(accessible_df)
            
            self.progress.update_substep(
                f"æµ‹é€Ÿå®Œæˆ: {len(accessible_df)}/{len(sources_df)} å¯ç”¨ "
                f"(å¹³å‡{avg_speed:.2f}ç§’, è¿‡æ»¤{total_filtered}ä¸ª)", 
                "âœ…"
            )
            
            return accessible_df
            
        except Exception as e:
            logging.error(f"âŒ å¤„ç†æµ‹é€Ÿç»“æœæ—¶å‡ºé”™: {e}")
            self.stats.errors_encountered += 1
            return pd.DataFrame()

    def load_template(self) -> Optional[Dict[str, List[str]]]:
        """åŠ è½½é¢‘é“æ¨¡æ¿æ–‡ä»¶"""
        template_file = Path(self.config.template_file)
        
        if not template_file.exists():
            logging.error(f"âŒ æ¨¡æ¿æ–‡ä»¶ {template_file} ä¸å­˜åœ¨")
            return None
            
        self.progress.update_substep("åŠ è½½æ¨¡æ¿æ–‡ä»¶...", "ğŸ“‹")
        categories: Dict[str, List[str]] = {}
        current_category: Optional[str] = None
        
        try:
            with open(template_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if not self._is_running:
                        break
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                        
                    category_match = self._patterns['category'].match(line)
                    if category_match:
                        current_category = category_match.group(1).strip()
                        if current_category:
                            categories[current_category] = []
                    elif current_category and line:
                        channel_name = line.split(',')[0].strip() if ',' in line else line.strip()
                        if channel_name:
                            categories[current_category].append(channel_name)
        
        except Exception as e:
            logging.error(f"âŒ è¯»å–æ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            return None
        
        if not categories:
            logging.error("âŒ æ¨¡æ¿æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„é¢‘é“åˆ†ç±»")
            return None
            
        total_channels = sum(len(channels) for channels in categories.values())
        self.stats.categories_processed = len(categories)
        self.progress.update_substep(f"åŠ è½½å®Œæˆ: {len(categories)} ä¸ªåˆ†ç±», {total_channels} ä¸ªé¢‘é“", "âœ…")
        
        return categories

    def clean_channel_name(self, name: str) -> str:
        """é¢‘é“åç§°æ¸…ç† - æ™ºèƒ½ç‰ˆæœ¬"""
        if not name:
            return ""
        try:
            cleaned = name.lower().strip()
            
            # ç§»é™¤è´¨é‡åç¼€ä½†ä¿ç•™æ›´å¤šåŸå§‹ä¿¡æ¯
            cleaned = self._patterns['quality_suffix'].sub(' ', cleaned)
            cleaned = self._patterns['brackets'].sub('', cleaned)
            
            # æ ‡å‡†åŒ–é¢‘é“ä»£ç 
            code_match = self._patterns['channel_code'].search(cleaned)
            if code_match:
                prefix, number = code_match.group(1).upper(), code_match.group(2)
                cleaned = f"{prefix} {number}"
            
            # æ™ºèƒ½ç‰¹æ®Šå­—ç¬¦å¤„ç†
            cleaned = self._patterns['special_chars'].sub(' ', cleaned)
            cleaned = self._patterns['whitespace'].sub(' ', cleaned).strip()
            
            return cleaned
        except Exception:
            return name.lower() if name else ""

    def similarity_score(self, str1: str, str2: str) -> int:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-100ï¼‰ - æ™ºèƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        if not str1 or not str2:
            return 0
        try:
            clean_str1, clean_str2 = self.clean_channel_name(str1), self.clean_channel_name(str2)
            if not clean_str1 or not clean_str2:
                return 0
            
            # å®Œå…¨åŒ¹é…
            if clean_str1 == clean_str2:
                return 100
            
            # åŒ…å«å…³ç³»
            if clean_str1 in clean_str2:
                return 90
            if clean_str2 in clean_str1:
                return 85
            
            # ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦
            def edit_distance_similarity(s1: str, s2: str) -> float:
                if len(s1) > len(s2):
                    s1, s2 = s2, s1
                if not s2:
                    return 0.0
                distances = range(len(s1) + 1)
                for i2, c2 in enumerate(s2):
                    distances_ = [i2 + 1]
                    for i1, c1 in enumerate(s1):
                        if c1 == c2:
                            distances_.append(distances[i1])
                        else:
                            distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))
                    distances = distances_
                max_len = max(len(s1), len(s2))
                return (1 - distances[-1] / max_len) * 100 if max_len > 0 else 0
            
            edit_score = edit_distance_similarity(clean_str1, clean_str2)
            
            # Jaccardç›¸ä¼¼åº¦
            set1, set2 = set(clean_str1), set(clean_str2)
            intersection, union = len(set1 & set2), len(set1 | set2)
            jaccard_similarity = (intersection / union) * 100 if union > 0 else 0
            
            # æ™ºèƒ½ç»„åˆåˆ†æ•°
            if len(clean_str1) > 3 and len(clean_str2) > 3:
                # é•¿å­—ç¬¦ä¸²æ›´ä¾èµ–ç¼–è¾‘è·ç¦»
                final_score = (edit_score * 0.7 + jaccard_similarity * 0.3)
            else:
                # çŸ­å­—ç¬¦ä¸²æ›´ä¾èµ–Jaccard
                final_score = (edit_score * 0.4 + jaccard_similarity * 0.6)
            
            return max(0, min(100, int(final_score)))
        except Exception:
            return 0

    def match_with_template(self, speed_tested_df: pd.DataFrame, template_categories: Dict[str, List[str]]) -> Dict[str, Any]:
        """æ¨¡æ¿åŒ¹é…å’Œæ’åº - ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½åŒ¹é…"""
        self.progress.update_substep("å¯åŠ¨æ™ºèƒ½é¢‘é“åŒ¹é…...", "ğŸ¯")
        
        if speed_tested_df.empty or not template_categories:
            logging.error("âŒ æµ‹é€Ÿæ•°æ®æˆ–æ¨¡æ¿åˆ†ç±»ä¸ºç©º")
            return {}
        
        final_data = {}
        total_sources, channels_with_sources = 0, 0
        
        print("   åŒ¹é…è¿›åº¦: ", end="", flush=True)
        
        total_channels = sum(len(channels) for channels in template_categories.values())
        processed_channels = 0
        
        # ä¸ºæ¯ä¸ªåˆ†ç±»å’Œé¢‘é“è¿›è¡Œæ™ºèƒ½åŒ¹é…
        for category, channels in template_categories.items():
            if not self._is_running:
                break
            final_data[category] = {}
            
            for channel in channels:
                if not self._is_running:
                    break
                    
                processed_channels += 1
                best_sources = []
                best_score = 0
                
                # ä¸ºæ¯ä¸ªé¢‘é“å¯»æ‰¾æœ€ä½³åŒ¹é…çš„æº
                for _, source_row in speed_tested_df.iterrows():
                    score = self.similarity_score(channel, source_row['program_name'])
                    if score > best_score and score >= self.config.similarity_threshold:
                        best_score = score
                
                # è·å–æ‰€æœ‰è¾¾åˆ°æœ€ä½³åˆ†æ•°çš„æº
                if best_score > 0:
                    matching_sources = []
                    for _, source_row in speed_tested_df.iterrows():
                        score = self.similarity_score(channel, source_row['program_name'])
                        if score == best_score:
                            matching_sources.append({
                                'stream_url': source_row['stream_url'],
                                'speed': source_row['speed'],
                                'match_score': score,
                                'original_name': source_row['program_name']
                            })
                    
                    # æ™ºèƒ½æ’åºå¹¶é€‰æ‹©å‰Nä¸ª
                    matching_sources.sort(key=lambda x: x['speed'])
                    best_sources = matching_sources[:self.config.max_sources_per_channel]
                
                if best_sources:
                    final_data[category][channel] = best_sources
                    source_count = len(best_sources)
                    total_sources += source_count
                    channels_with_sources += 1
                    
                    # æ™ºèƒ½åŒ¹é…è´¨é‡æ˜¾ç¤º
                    if best_score >= 90:
                        if source_count >= 5: print("ğŸ¯", end="", flush=True)
                        elif source_count >= 3: print("â­", end="", flush=True)
                        else: print("âœ…", end="", flush=True)
                    elif best_score >= 70:
                        if source_count >= 3: print("ğŸ”¶", end="", flush=True)
                        else: print("ğŸ‘", end="", flush=True)
                    elif best_score >= 50:
                        print("ğŸ”¹", end="", flush=True)
                    else:
                        print("â–ªï¸", end="", flush=True)
                else:
                    final_data[category][channel] = []
                    print("âŒ", end="", flush=True)
                
                # å®æ—¶è¿›åº¦æ›´æ–°
                if processed_channels % 10 == 0 or processed_channels == total_channels:
                    self._print_progress_bar(processed_channels, total_channels, "   åŒ¹é…è¿›åº¦", f"{channels_with_sources}æœ‰æº")
        
        print()
        
        self.stats.channels_matched = channels_with_sources
        self.stats.total_sources_found = total_sources
        
        coverage_rate = (channels_with_sources / total_channels * 100) if total_channels > 0 else 0
        avg_sources_per_channel = total_sources / channels_with_sources if channels_with_sources > 0 else 0
        
        self.progress.update_substep(
            f"åŒ¹é…å®Œæˆ: {channels_with_sources}/{total_channels} é¢‘é“æœ‰æº "
            f"({coverage_rate:.1f}%è¦†ç›–ç‡, å¹³å‡{avg_sources_per_channel:.1f}æº/é¢‘é“)", 
            "âœ…"
        )
        
        return final_data

    def save_output_files(self, final_data: Dict[str, Any]) -> bool:
        """ä¿å­˜è¾“å‡ºæ–‡ä»¶ - ç¬¬å››æ­¥ï¼šç”Ÿæˆ"""
        self.progress.update_substep("ä¿å­˜è¾“å‡ºæ–‡ä»¶...", "ğŸ’¾")
        
        if not final_data:
            logging.error("âŒ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return False
        
        success_count = 0
        
        # ä¿å­˜TXTæ ¼å¼
        try:
            with open(self.config.output_txt, 'w', encoding='utf-8') as f:
                f.write("# IPTVæ’­æ”¾åˆ—è¡¨ - ç”Ÿæˆæ—¶é—´: " + time.strftime("%Y-%m-%d %H:%M:%S") + "\n")
                f.write("# æµç¨‹: æ™ºèƒ½æŠ“å– â†’ ç²¾å‡†æµ‹é€Ÿ â†’ æ¨¡æ¿åŒ¹é… â†’ ç”Ÿæˆæ–‡ä»¶\n")
                f.write("# æ¯ä¸ªé¢‘é“æä¾›å¤šä¸ªå¤‡ç”¨æºï¼ŒæŒ‰é€Ÿåº¦æ’åº\n# æ ¼å¼: é¢‘é“åç§°,ç›´æ’­æµåœ°å€\n\n")
                
                for category, channels in final_data.items():
                    f.write(f"{category},#genre#\n")
                    for channel, sources in channels.items():
                        for source in sources:
                            f.write(f"{channel},{source['stream_url']}\n")
                    f.write("\n")
            
            success_count += 1
            file_size = os.path.getsize(self.config.output_txt)
            self.progress.update_substep(f"TXTæ–‡ä»¶å·²ä¿å­˜ ({file_size} å­—èŠ‚)", "âœ…")
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜TXTæ–‡ä»¶å¤±è´¥: {e}")
            self.stats.errors_encountered += 1
        
        # ä¿å­˜M3Uæ ¼å¼
        try:
            with open(self.config.output_m3u, 'w', encoding='utf-8') as f:
                f.write("#EXTM3U\n#PLAYLIST: IPTVæ™ºèƒ½åˆ—è¡¨\n")
                f.write("#GENERATED: " + time.strftime("%Y-%m-%d %H:%M:%S") + "\n")
                f.write("#PROCESS: æ™ºèƒ½æŠ“å–â†’ç²¾å‡†æµ‹é€Ÿâ†’æ¨¡æ¿åŒ¹é…â†’ç”Ÿæˆæ–‡ä»¶\n")
                
                for category, channels in final_data.items():
                    for channel, sources in channels.items():
                        for idx, source in enumerate(sources, 1):
                            # æ™ºèƒ½è´¨é‡æ ‡è¯†
                            quality_info = ""
                            if source['speed'] < 1.5:
                                quality_info = " [æé€Ÿ]"
                            elif source['speed'] < 3:
                                quality_info = " [å¿«é€Ÿ]"
                            elif source['speed'] < 6:
                                quality_info = " [ç¨³å®š]"
                            elif source['speed'] < 10:
                                quality_info = " [æ…¢é€Ÿ]"
                            
                            display_name = f"{channel}{quality_info}" if len(sources) == 1 else f"{channel} [æº{idx}]{quality_info}"
                            f.write(f'#EXTINF:-1 tvg-name="{channel}" group-title="{category}",{display_name}\n')
                            f.write(f"{source['stream_url']}\n")
            
            success_count += 1
            file_size = os.path.getsize(self.config.output_m3u)
            self.progress.update_substep(f"M3Uæ–‡ä»¶å·²ä¿å­˜ ({file_size} å­—èŠ‚)", "âœ…")
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜M3Uæ–‡ä»¶å¤±è´¥: {e}")
            self.stats.errors_encountered += 1
            
        return success_count == 2

    def print_detailed_statistics(self, final_data: Dict[str, Any]) -> None:
        """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        if not self.config.show_detailed_stats:
            return
            
        print("\n" + "="*60)
        print("ğŸ“ˆ è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š")
        print("="*60)
        
        if not final_data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯ç»Ÿè®¡")
            return
        
        total_channels, total_sources = 0, 0
        category_details = []
        
        # ç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„æƒ…å†µ
        for category, channels in final_data.items():
            category_channels, category_sources = 0, 0
            for channel, sources in channels.items():
                if sources:
                    category_channels += 1
                    category_sources += len(sources)
            
            if category_channels > 0:
                category_details.append((category, category_channels, category_sources))
                total_channels += category_channels
                total_sources += category_sources
        
        # æŒ‰é¢‘é“æ•°é‡æ’åº
        category_details.sort(key=lambda x: x[1], reverse=True)
        
        print("ğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
        for category, channel_count, source_count in category_details:
            avg_sources = source_count / channel_count if channel_count > 0 else 0
            coverage = channel_count / len(final_data[category]) * 100 if final_data[category] else 0
            print(f"  ğŸ“º {category:<12}: {channel_count:2d}é¢‘é“ ({coverage:5.1f}%) | {source_count:3d}æº (å¹³å‡{avg_sources:.1f}æº/é¢‘é“)")
        
        print("-"*60)
        total_template_channels = sum(len(channels) for channels in final_data.values())
        coverage_rate = (self.stats.channels_with_sources / total_template_channels * 100) if total_template_channels > 0 else 0
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  ğŸ¯ é¢‘é“è¦†ç›–ç‡: {self.stats.channels_with_sources}/{total_template_channels} ({coverage_rate:.1f}%)")
        print(f"  ğŸ”— æ€»æºæ•°é‡: {total_sources} (å¹³å‡{total_sources/total_channels:.1f}æº/é¢‘é“)" if total_channels > 0 else "  ğŸ”— æ€»æºæ•°é‡: 0")
        print(f"  ğŸ“ åˆ†ç±»æ•°é‡: {self.stats.categories_processed}")
        
        print("-"*60)
        print(f"âš™ï¸  å¤„ç†ç»Ÿè®¡:")
        print(f"  ğŸŒ æºæŠ“å–: {self.stats.sources_fetched}æˆåŠŸ")
        print(f"  ğŸ”§ æµè§£æ: {self.stats.streams_parsed}ä¸ªæµ")
        print(f"  ğŸ¯ é¢‘é“åŒ¹é…: {self.stats.channels_matched}ä¸ªé¢‘é“")
        print(f"  âš¡ æºæµ‹é€Ÿ: {self.stats.sources_tested}æµ‹è¯•, {self.stats.sources_available}å¯ç”¨")
        if self.stats.quality_filtered > 0:
            print(f"  ğŸ¯ è´¨é‡è¿‡æ»¤: {self.stats.quality_filtered}ä¸ª")
        if self.stats.speed_filtered > 0:
            print(f"  ğŸ¢ é€Ÿåº¦è¿‡æ»¤: {self.stats.speed_filtered}ä¸ª")
        if self.stats.errors_encountered > 0:
            print(f"  âš ï¸  é‡åˆ°é”™è¯¯: {self.stats.errors_encountered}ä¸ª")

    def _backup_existing_files(self) -> None:
        """å¤‡ä»½ç°æœ‰æ–‡ä»¶"""
        backup_dir = Path(self.config.backup_dir)
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        for file_name in [self.config.output_txt, self.config.output_m3u]:
            file_path = Path(file_name)
            if file_path.exists():
                backup_path = backup_dir / f"{file_path.stem}_{timestamp}{file_path.suffix}"
                try:
                    shutil.copy2(file_path, backup_path)
                    logging.info(f"ğŸ“¦ å·²å¤‡ä»½: {file_name}")
                except Exception as e:
                    logging.warning(f"âš ï¸ å¤‡ä»½æ–‡ä»¶ {file_name} å¤±è´¥: {e}")

    def create_demo_template(self) -> bool:
        """åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶"""
        demo_content = """# IPTVé¢‘é“æ¨¡æ¿æ–‡ä»¶
# æ ¼å¼: åˆ†ç±»åç§°,#genre#
#       é¢‘é“åç§°1
#       é¢‘é“åç§°2

å¤®è§†é¢‘é“,#genre#
CCTV-1
CCTV-2
CCTV-3
CCTV-4
CCTV-5
CCTV-5+
CCTV-6
CCTV-7
CCTV-8
CCTV-9
CCTV-10
CCTV-11
CCTV-12
CCTV-13
CCTV-14
CCTV-15

å«è§†é¢‘é“,#genre#
æ¹–å—å«è§†
æµ™æ±Ÿå«è§†
æ±Ÿè‹å«è§†
ä¸œæ–¹å«è§†
åŒ—äº¬å«è§†
å¤©æ´¥å«è§†
å±±ä¸œå«è§†
å¹¿ä¸œå«è§†
æ·±åœ³å«è§†
å®‰å¾½å«è§†

åœ°æ–¹é¢‘é“,#genre#
åŒ—äº¬ç§‘æ•™
åŒ—äº¬çºªå®
åŒ—äº¬ç”Ÿæ´»
åŒ—äº¬è´¢ç»
åŒ—äº¬æ–‡è‰º

é«˜æ¸…é¢‘é“,#genre#
CCTV-1é«˜æ¸…
CCTV-5é«˜æ¸…
æ¹–å—å«è§†é«˜æ¸…
æµ™æ±Ÿå«è§†é«˜æ¸…
æ±Ÿè‹å«è§†é«˜æ¸…
"""
        try:
            with open(self.config.template_file, 'w', encoding='utf-8') as f:
                f.write(demo_content)
            logging.info(f"âœ… å·²åˆ›å»ºç¤ºä¾‹æ¨¡æ¿æ–‡ä»¶: {self.config.template_file}")
            return True
        except Exception as e:
            logging.error(f"âŒ åˆ›å»ºæ¨¡æ¿æ–‡ä»¶å¤±è´¥: {e}")
            self.stats.errors_encountered += 1
            return False

    def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            if hasattr(self, 'speed_engine'):
                self.speed_engine.stop()
            temp_dir = Path(self.config.temp_dir)
            if temp_dir.exists():
                shutil.rmtree(temp_dir)
            logging.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logging.debug(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")

    def run(self) -> None:
        """ä¸»è¿è¡Œå‡½æ•° - æŒ‰ç…§ä¼˜åŒ–åçš„æµç¨‹æ‰§è¡Œ"""
        print("=" * 60)
        print("ğŸ¬ IPTVæ™ºèƒ½ç®¡ç†å·¥å…· - GitHub Actionsä¼˜åŒ–ç‰ˆ v6.1")
        print("ğŸ”§ æµç¨‹: æ™ºèƒ½æŠ“å– â†’ ç²¾å‡†æµ‹é€Ÿ â†’ æ¨¡æ¿åŒ¹é… â†’ ç”Ÿæˆæ–‡ä»¶")
        print("=" * 60)
        
        start_time = time.time()
        
        try:
            # å®šä¹‰ä¼˜åŒ–åçš„å¤„ç†æ­¥éª¤
            step_names = [
                "ç¯å¢ƒå‡†å¤‡å’Œå¤‡ä»½",
                "æ™ºèƒ½å¤šæºæŠ“å–", 
                "è§£æåŸå§‹æ•°æ®",
                "ç²¾å‡†æµ‹é€Ÿè¿‡æ»¤",
                "åŠ è½½é¢‘é“æ¨¡æ¿", 
                "æ™ºèƒ½åŒ¹é…æ’åº",
                "ç”Ÿæˆæ’­æ”¾åˆ—è¡¨",
                "ä¿å­˜è¾“å‡ºæ–‡ä»¶"
            ]
            self.progress.start_progress(step_names)
            
            # æ­¥éª¤1: ç¯å¢ƒå‡†å¤‡
            self.progress.next_step("åˆå§‹åŒ–ç¯å¢ƒå’Œå¤‡ä»½æ–‡ä»¶")
            self._backup_existing_files()
            
            # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶
            template_path = Path(self.config.template_file)
            if not template_path.exists():
                print("ğŸ“ æœªæ‰¾åˆ°æ¨¡æ¿æ–‡ä»¶ï¼Œåˆ›å»ºç¤ºä¾‹æ¨¡æ¿...")
                if self.create_demo_template():
                    print(f"\nğŸ’¡ æ¨¡æ¿æ–‡ä»¶å·²åˆ›å»º: {template_path.absolute()}")
                    print("ğŸ’¡ è¯·ç¼–è¾‘æ¨¡æ¿æ–‡ä»¶åé‡æ–°è¿è¡Œç¨‹åº")
                    return
            
            # æ­¥éª¤2: æ™ºèƒ½å¤šæºæŠ“å–
            self.progress.next_step("ä»å¤šä¸ªæºæŠ“å–æµæ•°æ®")
            content = self.fetch_all_streams()
            if not content:
                logging.error("âŒ æŠ“å–é˜¶æ®µå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return
            
            # æ­¥éª¤3: è§£æåŸå§‹æ•°æ®
            self.progress.next_step("è§£æå’Œæ¸…ç†åŸå§‹æµæ•°æ®")
            sources_df = self.organize_streams(content)
            if sources_df.empty:
                logging.error("âŒ è§£æé˜¶æ®µå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return
            
            # æ­¥éª¤4: ç²¾å‡†æµ‹é€Ÿå’Œè¿‡æ»¤
            self.progress.next_step("ç²¾å‡†æµ‹é€Ÿå’Œæ™ºèƒ½ç­›é€‰")
            speed_tested_df = self.speed_test_and_filter(sources_df)
            if speed_tested_df.empty:
                logging.error("âŒ æµ‹é€Ÿé˜¶æ®µå¤±è´¥ï¼Œæ²¡æœ‰å¯ç”¨çš„æº")
                return
            
            # æ­¥éª¤5: åŠ è½½é¢‘é“æ¨¡æ¿
            self.progress.next_step("åŠ è½½é¢‘é“æ¨¡æ¿é…ç½®")
            template_categories = self.load_template()
            if not template_categories:
                logging.error("âŒ æ¨¡æ¿åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return
            
            # æ­¥éª¤6: æ™ºèƒ½åŒ¹é…æ’åº
            self.progress.next_step("æ™ºèƒ½åŒ¹é…é¢‘é“å’Œæ’åº")
            final_data = self.match_with_template(speed_tested_df, template_categories)
            if not final_data:
                logging.error("âŒ åŒ¹é…é˜¶æ®µå¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆæ•°æ®")
                return
            
            # æ­¥éª¤7: ç”Ÿæˆæ’­æ”¾åˆ—è¡¨
            self.progress.next_step("ç”Ÿæˆæœ€ç»ˆæ’­æ”¾åˆ—è¡¨")
            # æ•°æ®å·²ç»åœ¨åŒ¹é…é˜¶æ®µç”Ÿæˆï¼Œè¿™é‡Œä¸»è¦æ˜¯å‡†å¤‡ä¿å­˜
            
            # æ­¥éª¤8: ä¿å­˜è¾“å‡ºæ–‡ä»¶
            self.progress.next_step("ä¿å­˜TXTå’ŒM3Uæ ¼å¼æ–‡ä»¶")
            if not self.save_output_files(final_data):
                logging.error("âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥")
                return
            
            # æ‰“å°è¯¦ç»†ç»Ÿè®¡
            self.print_detailed_statistics(final_data)
            
            end_time = time.time()
            elapsed_time = end_time - start_time
            
            print("\nğŸ‰ å¤„ç†å®Œæˆ!")
            print(f"â° æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
            print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶:")
            print(f"   ğŸ“„ {Path(self.config.output_txt).absolute()}")
            print(f"   ğŸ“„ {Path(self.config.output_m3u).absolute()}")
            print(f"ğŸ“Š æœ€ç»ˆç»“æœ: {self.stats.channels_with_sources}ä¸ªé¢‘é“æœ‰å¯ç”¨æº")
                
        except KeyboardInterrupt:
            print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
            self.stats.errors_encountered += 1
        except Exception as e:
            print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
            self.stats.errors_encountered += 1
            logging.exception("ç¨‹åºè¿è¡Œå¼‚å¸¸")
        finally:
            self.cleanup()
            
            if self.stats.errors_encountered > 0:
                logging.warning(f"âš ï¸ æœ¬æ¬¡è¿è¡Œé‡åˆ° {self.stats.errors_encountered} ä¸ªé”™è¯¯")


def main():
    """ä¸»å‡½æ•° - GitHub Actions ä¼˜åŒ–ç‰ˆ"""
    # ç®€åŒ–çš„æ—¥å¿—é…ç½®ï¼Œé€‚åˆGitHub Actions
    logging.basicConfig(
        level=logging.INFO,
        format='%(levelname)s: %(message)s',
        handlers=[logging.StreamHandler(sys.stdout)]
    )
    
    try:
        manager = IPTVManager()
        manager.run()
    except Exception as e:
        logging.error(f"ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
        # åœ¨GitHub Actionsä¸­ï¼Œéé›¶é€€å‡ºç ä¼šæ ‡è®°å·¥ä½œæµä¸ºå¤±è´¥
        sys.exit(1)


if __name__ == "__main__":
    main()
